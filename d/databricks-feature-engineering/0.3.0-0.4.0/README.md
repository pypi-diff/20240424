# Comparing `tmp/databricks_feature_engineering-0.3.0-py3-none-any.whl.zip` & `tmp/databricks_feature_engineering-0.4.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,156 +1,157 @@
-Zip file size: 243667 bytes, number of entries: 154
--rw-r--r--  2.0 unx      166 b- defN 23-Dec-21 01:09 databricks/__init__.py
--rw-r--r--  2.0 unx      166 b- defN 23-Dec-21 01:09 databricks/_feature_store_pkg_metadata/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/_feature_store_pkg_metadata/_core_client_pkg_metadata/__init__.py
--rw-r--r--  2.0 unx     2262 b- defN 24-Jan-03 23:53 databricks/feature_engineering/__init__.py
--rw-r--r--  2.0 unx    35813 b- defN 24-Feb-06 23:35 databricks/feature_engineering/client.py
--rw-r--r--  2.0 unx       87 b- defN 23-Dec-21 01:09 databricks/feature_engineering/training_set.py
--rw-r--r--  2.0 unx    22580 b- defN 23-Dec-21 01:09 databricks/feature_engineering/upgrade_client.py
--rw-r--r--  2.0 unx       74 b- defN 23-Dec-21 01:09 databricks/feature_engineering/version.py
--rw-r--r--  2.0 unx      285 b- defN 23-Dec-21 01:09 databricks/feature_engineering/entities/__init__.py
--rw-r--r--  2.0 unx      108 b- defN 23-Dec-21 01:09 databricks/feature_engineering/entities/feature_function.py
--rw-r--r--  2.0 unx      102 b- defN 23-Dec-21 01:09 databricks/feature_engineering/entities/feature_lookup.py
--rw-r--r--  2.0 unx      282 b- defN 23-Dec-21 01:09 databricks/feature_engineering/entities/feature_serving_endpoint.py
--rw-r--r--  2.0 unx      109 b- defN 23-Dec-21 01:09 databricks/feature_engineering/entities/feature_spec_info.py
--rw-r--r--  2.0 unx       99 b- defN 23-Dec-21 01:09 databricks/feature_engineering/entities/feature_table.py
--rw-r--r--  2.0 unx      356 b- defN 23-Dec-21 01:09 databricks/feature_engineering/online_store_spec/__init__.py
--rw-r--r--  2.0 unx     3760 b- defN 23-Dec-21 01:09 databricks/feature_engineering/utils/upgrade_utils.py
--rw-r--r--  2.0 unx     2648 b- defN 23-Dec-21 01:09 databricks/feature_store/__init__.py
--rw-r--r--  2.0 unx    46692 b- defN 24-Jan-04 20:58 databricks/feature_store/client.py
--rw-r--r--  2.0 unx     6319 b- defN 23-Dec-21 01:09 databricks/feature_store/decorators.py
--rw-r--r--  2.0 unx     2295 b- defN 24-Feb-02 22:42 databricks/feature_store/mlflow_model.py
--rw-r--r--  2.0 unx       87 b- defN 23-Dec-21 01:09 databricks/feature_store/training_set.py
--rw-r--r--  2.0 unx       74 b- defN 23-Dec-21 01:09 databricks/feature_store/version.py
--rw-r--r--  2.0 unx      291 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/__init__.py
--rw-r--r--  2.0 unx      145 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature.py
--rw-r--r--  2.0 unx      108 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature_function.py
--rw-r--r--  2.0 unx      102 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature_lookup.py
--rw-r--r--  2.0 unx      282 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature_serving_endpoint.py
--rw-r--r--  2.0 unx      170 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature_spec.py
--rw-r--r--  2.0 unx      109 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature_spec_info.py
--rw-r--r--  2.0 unx       99 b- defN 23-Dec-21 01:09 databricks/feature_store/entities/feature_table.py
--rw-r--r--  2.0 unx      356 b- defN 23-Dec-21 01:09 databricks/feature_store/online_store_spec/__init__.py
--rw-r--r--  2.0 unx      335 b- defN 23-Dec-21 01:09 databricks/feature_store/publish_engine/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/__init__.py
--rw-r--r--  2.0 unx      921 b- defN 24-Jan-31 21:09 databricks/ml_features/constants.py
--rw-r--r--  2.0 unx     5569 b- defN 23-Dec-21 01:09 databricks/ml_features/training_set.py
--rw-r--r--  2.0 unx       18 b- defN 24-Feb-28 22:20 databricks/ml_features/version.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_catalog_client/__init__.py
--rw-r--r--  2.0 unx    21431 b- defN 23-Dec-21 01:09 databricks/ml_features/_catalog_client/_catalog_client.py
--rw-r--r--  2.0 unx     5751 b- defN 24-Jan-12 23:44 databricks/ml_features/_catalog_client/_catalog_client_helper.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_compute_client/__init__.py
--rw-r--r--  2.0 unx    55022 b- defN 23-Dec-21 01:09 databricks/ml_features/_compute_client/_compute_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_databricks_client/__init__.py
--rw-r--r--  2.0 unx     2389 b- defN 23-Dec-21 01:09 databricks/ml_features/_databricks_client/_databricks_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_feature_serving_endpoint_client/__init__.py
--rw-r--r--  2.0 unx     8348 b- defN 24-Feb-23 19:23 databricks/ml_features/_feature_serving_endpoint_client/_feature_serving_endpoint_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_information_schema_spark_client/__init__.py
--rw-r--r--  2.0 unx     7625 b- defN 23-Dec-21 01:09 databricks/ml_features/_information_schema_spark_client/_information_schema_spark_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_online_store_publish_client/__init__.py
--rw-r--r--  2.0 unx     5344 b- defN 23-Dec-21 01:09 databricks/ml_features/_online_store_publish_client/_online_store_publish_client.py
--rw-r--r--  2.0 unx      912 b- defN 23-Dec-21 01:09 databricks/ml_features/_online_store_publish_client/_online_store_publish_client_factory.py
--rw-r--r--  2.0 unx     6135 b- defN 23-Dec-21 01:09 databricks/ml_features/_online_store_publish_client/_online_store_publish_nosql_client.py
--rw-r--r--  2.0 unx    13714 b- defN 23-Dec-21 01:09 databricks/ml_features/_online_store_publish_client/_online_store_publish_rdbms_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_publish_client/__init__.py
--rw-r--r--  2.0 unx    20034 b- defN 23-Dec-21 01:09 databricks/ml_features/_publish_client/_publish_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_spark_client/__init__.py
--rw-r--r--  2.0 unx    30117 b- defN 23-Dec-21 01:09 databricks/ml_features/_spark_client/_spark_client.py
--rw-r--r--  2.0 unx     2179 b- defN 23-Dec-21 01:09 databricks/ml_features/_spark_client/_spark_client_helper.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/_training_scoring_client/__init__.py
--rw-r--r--  2.0 unx    32102 b- defN 24-Feb-23 06:51 databricks/ml_features/_training_scoring_client/_training_scoring_client.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/api/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/api/proto/__init__.py
--rw-r--r--  2.0 unx    81316 b- defN 24-Feb-27 17:58 databricks/ml_features/api/proto/feature_catalog_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/__init__.py
--rw-r--r--  2.0 unx      905 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/_permission_level.py
--rw-r--r--  2.0 unx     1102 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/consumer.py
--rw-r--r--  2.0 unx     3417 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/data_type.py
--rw-r--r--  2.0 unx     1447 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/feature.py
--rw-r--r--  2.0 unx     2026 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/feature_function.py
--rw-r--r--  2.0 unx     8361 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/feature_lookup.py
--rw-r--r--  2.0 unx     6764 b- defN 24-Feb-23 19:23 databricks/ml_features/entities/feature_serving_endpoint.py
--rw-r--r--  2.0 unx       76 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/feature_spec.py
--rw-r--r--  2.0 unx     1561 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/feature_spec_info.py
--rw-r--r--  2.0 unx     4546 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/feature_table.py
--rw-r--r--  2.0 unx     1014 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/job.py
--rw-r--r--  2.0 unx     1201 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/key_spec.py
--rw-r--r--  2.0 unx     1196 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/notebook.py
--rw-r--r--  2.0 unx     3451 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/online_store_detailed.py
--rw-r--r--  2.0 unx     6908 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/online_store_metadata.py
--rw-r--r--  2.0 unx      520 b- defN 23-Dec-21 01:09 databricks/ml_features/entities/tag.py
--rw-r--r--  2.0 unx        1 b- defN 23-Dec-21 01:09 databricks/ml_features/local_models/__init__.py
--rw-r--r--  2.0 unx      545 b- defN 23-Dec-21 01:09 databricks/ml_features/local_models/databricks_identity_model.py
--rw-r--r--  2.0 unx      817 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/__init__.py
--rw-r--r--  2.0 unx    11369 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/amazon_dynamodb_online_store_spec.py
--rw-r--r--  2.0 unx     4664 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/amazon_rds_mysql_online_store_spec.py
--rw-r--r--  2.0 unx     6612 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/azure_cosmosdb_online_store_spec.py
--rw-r--r--  2.0 unx     4607 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/azure_mysql_online_store_spec.py
--rw-r--r--  2.0 unx     4668 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/azure_sql_server_online_store_spec.py
--rw-r--r--  2.0 unx     1513 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/online_store_properties.py
--rw-r--r--  2.0 unx    20549 b- defN 23-Dec-21 01:09 databricks/ml_features/online_store_spec/online_store_spec.py
--rw-r--r--  2.0 unx      656 b- defN 23-Dec-21 01:09 databricks/ml_features/publish_engine/__init__.py
--rw-r--r--  2.0 unx    17798 b- defN 23-Dec-21 21:48 databricks/ml_features/publish_engine/publish_cosmosdb_engine.py
--rw-r--r--  2.0 unx    11351 b- defN 23-Dec-21 01:09 databricks/ml_features/publish_engine/publish_dynamodb_engine.py
--rw-r--r--  2.0 unx     6038 b- defN 23-Dec-21 01:09 databricks/ml_features/publish_engine/publish_mysql_engine.py
--rw-r--r--  2.0 unx     4678 b- defN 23-Dec-21 01:09 databricks/ml_features/publish_engine/publish_sql_engine.py
--rw-r--r--  2.0 unx     8400 b- defN 23-Dec-21 01:09 databricks/ml_features/publish_engine/publish_sql_server_engine.py
--rw-r--r--  2.0 unx     7996 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/cosmosdb_type_utils.py
--rw-r--r--  2.0 unx     3888 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/cosmosdb_utils.py
--rw-r--r--  2.0 unx     7375 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/dynamodb_type_utils.py
--rw-r--r--  2.0 unx    11599 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/e2e_test_utils.py
--rw-r--r--  2.0 unx    13779 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/feature_lookup_utils.py
--rw-r--r--  2.0 unx     1588 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/feature_serving_endpoint_utils.py
--rw-r--r--  2.0 unx     1897 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/feature_utils.py
--rw-r--r--  2.0 unx     1207 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/headers.yaml
--rw-r--r--  2.0 unx     1609 b- defN 24-Jan-12 23:46 databricks/ml_features/utils/logging_utils.py
--rw-r--r--  2.0 unx     4445 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/on_demand_utils.py
--rw-r--r--  2.0 unx     1915 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/publish_utils.py
--rw-r--r--  2.0 unx    12872 b- defN 24-Feb-02 22:42 databricks/ml_features/utils/request_context.py
--rw-r--r--  2.0 unx    10989 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/rest_utils.py
--rw-r--r--  2.0 unx     4686 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/schema_utils.py
--rw-r--r--  2.0 unx     7587 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/signature_utils.py
--rw-r--r--  2.0 unx     6414 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/spark_listener.py
--rw-r--r--  2.0 unx      275 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/spark_test_utils.py
--rw-r--r--  2.0 unx      919 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/spark_utils.py
--rw-r--r--  2.0 unx     7656 b- defN 24-Jan-05 06:46 databricks/ml_features/utils/test_utils.py
--rw-r--r--  2.0 unx    23133 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/training_scoring_utils.py
--rw-r--r--  2.0 unx     9325 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/utils.py
--rw-r--r--  2.0 unx     3789 b- defN 23-Dec-21 01:09 databricks/ml_features/utils/validation_utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features_common/__init__.py
--rw-r--r--  2.0 unx     1715 b- defN 24-Feb-23 06:51 databricks/ml_features_common/mlflow_model_constants.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/__init__.py
--rw-r--r--  2.0 unx     1938 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/_feature_store_object.py
--rw-r--r--  2.0 unx     1489 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/_proto_enum_entity.py
--rw-r--r--  2.0 unx      454 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/cloud.py
--rw-r--r--  2.0 unx     4450 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/column_info.py
--rw-r--r--  2.0 unx     2572 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/feature_column_info.py
--rw-r--r--  2.0 unx    21270 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/feature_spec.py
--rw-r--r--  2.0 unx      785 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/feature_spec_constants.py
--rw-r--r--  2.0 unx     1565 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/feature_table_info.py
--rw-r--r--  2.0 unx     1735 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/feature_tables_for_serving.py
--rw-r--r--  2.0 unx      692 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/function_info.py
--rw-r--r--  2.0 unx     2002 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/on_demand_column_info.py
--rw-r--r--  2.0 unx     3730 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/online_feature_table.py
--rw-r--r--  2.0 unx     4445 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/online_store_for_serving.py
--rw-r--r--  2.0 unx      499 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/query_mode.py
--rw-r--r--  2.0 unx      874 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/source_data_column_info.py
--rw-r--r--  2.0 unx      669 b- defN 23-Dec-21 01:09 databricks/ml_features_common/entities/store_type.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features_common/protos/__init__.py
--rw-r--r--  2.0 unx     6398 b- defN 24-Feb-27 17:58 databricks/ml_features_common/protos/feature_spec_pb2.py
--rw-r--r--  2.0 unx    18522 b- defN 24-Feb-27 17:58 databricks/ml_features_common/protos/feature_store_serving_pb2.py
--rw-r--r--  2.0 unx        0 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/__init__.py
--rw-r--r--  2.0 unx     5410 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/converter_utils.py
--rw-r--r--  2.0 unx     5193 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/dynamodb_utils.py
--rw-r--r--  2.0 unx     2356 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/feature_spec_test_utils.py
--rw-r--r--  2.0 unx    11042 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/feature_spec_utils.py
--rw-r--r--  2.0 unx      374 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/test_utils_common.py
--rw-r--r--  2.0 unx     5400 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/topological_sort.py
--rw-r--r--  2.0 unx    10298 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/uc_utils.py
--rw-r--r--  2.0 unx     3802 b- defN 23-Dec-21 01:09 databricks/ml_features_common/utils/utils_common.py
--rw-r--r--  2.0 unx     2414 b- defN 24-Feb-28 22:28 databricks_feature_engineering-0.3.0.dist-info/LICENSE.md
--rw-r--r--  2.0 unx     4276 b- defN 24-Feb-28 22:28 databricks_feature_engineering-0.3.0.dist-info/METADATA
--rw-r--r--  2.0 unx      515 b- defN 24-Feb-28 22:28 databricks_feature_engineering-0.3.0.dist-info/NOTICE.md
--rw-r--r--  2.0 unx       92 b- defN 24-Feb-28 22:28 databricks_feature_engineering-0.3.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 24-Feb-28 22:28 databricks_feature_engineering-0.3.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx    16947 b- defN 24-Feb-28 22:28 databricks_feature_engineering-0.3.0.dist-info/RECORD
-154 files, 862926 bytes uncompressed, 215319 bytes compressed:  75.0%
+Zip file size: 246615 bytes, number of entries: 155
+-rw-r--r--  2.0 unx      166 b- defN 23-Oct-16 19:06 databricks/__init__.py
+-rw-r--r--  2.0 unx      166 b- defN 23-Nov-17 21:49 databricks/_feature_store_pkg_metadata/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-17 21:49 databricks/_feature_store_pkg_metadata/_core_client_pkg_metadata/__init__.py
+-rw-r--r--  2.0 unx     2262 b- defN 24-Jan-04 22:13 databricks/feature_engineering/__init__.py
+-rw-r--r--  2.0 unx    35868 b- defN 24-Apr-24 00:34 databricks/feature_engineering/client.py
+-rw-r--r--  2.0 unx       87 b- defN 23-Nov-29 00:14 databricks/feature_engineering/training_set.py
+-rw-r--r--  2.0 unx    22635 b- defN 24-Apr-16 23:08 databricks/feature_engineering/upgrade_client.py
+-rw-r--r--  2.0 unx       74 b- defN 23-Dec-02 18:11 databricks/feature_engineering/version.py
+-rw-r--r--  2.0 unx      285 b- defN 23-Dec-02 18:11 databricks/feature_engineering/entities/__init__.py
+-rw-r--r--  2.0 unx      108 b- defN 23-Nov-29 00:14 databricks/feature_engineering/entities/feature_function.py
+-rw-r--r--  2.0 unx      102 b- defN 23-Nov-29 00:14 databricks/feature_engineering/entities/feature_lookup.py
+-rw-r--r--  2.0 unx      282 b- defN 23-Dec-17 19:21 databricks/feature_engineering/entities/feature_serving_endpoint.py
+-rw-r--r--  2.0 unx      109 b- defN 23-Dec-17 19:21 databricks/feature_engineering/entities/feature_spec_info.py
+-rw-r--r--  2.0 unx       99 b- defN 23-Nov-29 00:14 databricks/feature_engineering/entities/feature_table.py
+-rw-r--r--  2.0 unx      356 b- defN 23-Nov-29 00:14 databricks/feature_engineering/online_store_spec/__init__.py
+-rw-r--r--  2.0 unx     3760 b- defN 23-Nov-29 00:14 databricks/feature_engineering/utils/upgrade_utils.py
+-rw-r--r--  2.0 unx     2648 b- defN 23-Dec-17 19:21 databricks/feature_store/__init__.py
+-rw-r--r--  2.0 unx    46747 b- defN 24-Apr-16 23:08 databricks/feature_store/client.py
+-rw-r--r--  2.0 unx     6319 b- defN 23-Nov-29 00:14 databricks/feature_store/decorators.py
+-rw-r--r--  2.0 unx     2295 b- defN 24-Apr-24 00:34 databricks/feature_store/mlflow_model.py
+-rw-r--r--  2.0 unx       87 b- defN 23-Nov-29 00:14 databricks/feature_store/training_set.py
+-rw-r--r--  2.0 unx       74 b- defN 23-Dec-02 18:11 databricks/feature_store/version.py
+-rw-r--r--  2.0 unx      291 b- defN 23-Nov-29 00:14 databricks/feature_store/entities/__init__.py
+-rw-r--r--  2.0 unx      145 b- defN 23-Nov-29 00:14 databricks/feature_store/entities/feature.py
+-rw-r--r--  2.0 unx      108 b- defN 23-Nov-29 00:14 databricks/feature_store/entities/feature_function.py
+-rw-r--r--  2.0 unx      102 b- defN 23-Nov-29 00:14 databricks/feature_store/entities/feature_lookup.py
+-rw-r--r--  2.0 unx      282 b- defN 23-Dec-17 19:21 databricks/feature_store/entities/feature_serving_endpoint.py
+-rw-r--r--  2.0 unx      170 b- defN 23-Nov-29 00:14 databricks/feature_store/entities/feature_spec.py
+-rw-r--r--  2.0 unx      109 b- defN 23-Dec-17 19:21 databricks/feature_store/entities/feature_spec_info.py
+-rw-r--r--  2.0 unx       99 b- defN 23-Nov-29 00:14 databricks/feature_store/entities/feature_table.py
+-rw-r--r--  2.0 unx      356 b- defN 23-Nov-29 00:14 databricks/feature_store/online_store_spec/__init__.py
+-rw-r--r--  2.0 unx      335 b- defN 23-Nov-29 00:14 databricks/feature_store/publish_engine/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/__init__.py
+-rw-r--r--  2.0 unx      921 b- defN 24-Apr-24 00:34 databricks/ml_features/constants.py
+-rw-r--r--  2.0 unx     1679 b- defN 24-Apr-22 20:35 databricks/ml_features/environment_variables.py
+-rw-r--r--  2.0 unx     5569 b- defN 24-Apr-24 00:34 databricks/ml_features/training_set.py
+-rw-r--r--  2.0 unx       18 b- defN 24-Apr-24 07:32 databricks/ml_features/version.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_catalog_client/__init__.py
+-rw-r--r--  2.0 unx    21431 b- defN 24-Jan-04 22:13 databricks/ml_features/_catalog_client/_catalog_client.py
+-rw-r--r--  2.0 unx     5751 b- defN 24-Jan-17 21:13 databricks/ml_features/_catalog_client/_catalog_client_helper.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_compute_client/__init__.py
+-rw-r--r--  2.0 unx    56876 b- defN 24-Apr-16 23:08 databricks/ml_features/_compute_client/_compute_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_databricks_client/__init__.py
+-rw-r--r--  2.0 unx     3210 b- defN 24-Apr-16 23:08 databricks/ml_features/_databricks_client/_databricks_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_feature_serving_endpoint_client/__init__.py
+-rw-r--r--  2.0 unx     8412 b- defN 24-Apr-18 21:13 databricks/ml_features/_feature_serving_endpoint_client/_feature_serving_endpoint_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_information_schema_spark_client/__init__.py
+-rw-r--r--  2.0 unx     7625 b- defN 23-Nov-29 00:14 databricks/ml_features/_information_schema_spark_client/_information_schema_spark_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_online_store_publish_client/__init__.py
+-rw-r--r--  2.0 unx     5344 b- defN 23-Nov-29 00:14 databricks/ml_features/_online_store_publish_client/_online_store_publish_client.py
+-rw-r--r--  2.0 unx      912 b- defN 23-Nov-29 00:14 databricks/ml_features/_online_store_publish_client/_online_store_publish_client_factory.py
+-rw-r--r--  2.0 unx     6201 b- defN 24-Apr-18 21:13 databricks/ml_features/_online_store_publish_client/_online_store_publish_nosql_client.py
+-rw-r--r--  2.0 unx    13779 b- defN 24-Apr-18 21:13 databricks/ml_features/_online_store_publish_client/_online_store_publish_rdbms_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_publish_client/__init__.py
+-rw-r--r--  2.0 unx    20175 b- defN 24-Mar-19 23:36 databricks/ml_features/_publish_client/_publish_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_spark_client/__init__.py
+-rw-r--r--  2.0 unx    30059 b- defN 24-Apr-18 21:13 databricks/ml_features/_spark_client/_spark_client.py
+-rw-r--r--  2.0 unx     2179 b- defN 23-Nov-29 00:14 databricks/ml_features/_spark_client/_spark_client_helper.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/_training_scoring_client/__init__.py
+-rw-r--r--  2.0 unx    32102 b- defN 24-Apr-24 00:34 databricks/ml_features/_training_scoring_client/_training_scoring_client.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/api/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/api/proto/__init__.py
+-rw-r--r--  2.0 unx    90757 b- defN 24-Apr-16 23:08 databricks/ml_features/api/proto/feature_catalog_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/__init__.py
+-rw-r--r--  2.0 unx      905 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/_permission_level.py
+-rw-r--r--  2.0 unx     1102 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/consumer.py
+-rw-r--r--  2.0 unx     3417 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/data_type.py
+-rw-r--r--  2.0 unx     1447 b- defN 23-Dec-02 18:11 databricks/ml_features/entities/feature.py
+-rw-r--r--  2.0 unx     2026 b- defN 23-Dec-17 19:21 databricks/ml_features/entities/feature_function.py
+-rw-r--r--  2.0 unx     8361 b- defN 23-Dec-17 19:21 databricks/ml_features/entities/feature_lookup.py
+-rw-r--r--  2.0 unx     6764 b- defN 24-Feb-26 18:04 databricks/ml_features/entities/feature_serving_endpoint.py
+-rw-r--r--  2.0 unx       76 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/feature_spec.py
+-rw-r--r--  2.0 unx     1561 b- defN 23-Dec-17 19:21 databricks/ml_features/entities/feature_spec_info.py
+-rw-r--r--  2.0 unx     4546 b- defN 23-Dec-17 19:21 databricks/ml_features/entities/feature_table.py
+-rw-r--r--  2.0 unx     1014 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/job.py
+-rw-r--r--  2.0 unx     1201 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/key_spec.py
+-rw-r--r--  2.0 unx     1196 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/notebook.py
+-rw-r--r--  2.0 unx     3451 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/online_store_detailed.py
+-rw-r--r--  2.0 unx     6908 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/online_store_metadata.py
+-rw-r--r--  2.0 unx      520 b- defN 23-Nov-29 00:14 databricks/ml_features/entities/tag.py
+-rw-r--r--  2.0 unx        1 b- defN 23-Nov-29 00:14 databricks/ml_features/local_models/__init__.py
+-rw-r--r--  2.0 unx      545 b- defN 23-Nov-29 00:14 databricks/ml_features/local_models/databricks_identity_model.py
+-rw-r--r--  2.0 unx      817 b- defN 23-Nov-29 00:14 databricks/ml_features/online_store_spec/__init__.py
+-rw-r--r--  2.0 unx    11369 b- defN 23-Dec-17 19:21 databricks/ml_features/online_store_spec/amazon_dynamodb_online_store_spec.py
+-rw-r--r--  2.0 unx     4664 b- defN 23-Dec-17 19:21 databricks/ml_features/online_store_spec/amazon_rds_mysql_online_store_spec.py
+-rw-r--r--  2.0 unx     6612 b- defN 23-Dec-17 19:21 databricks/ml_features/online_store_spec/azure_cosmosdb_online_store_spec.py
+-rw-r--r--  2.0 unx     4607 b- defN 23-Dec-17 19:21 databricks/ml_features/online_store_spec/azure_mysql_online_store_spec.py
+-rw-r--r--  2.0 unx     4668 b- defN 23-Dec-17 19:21 databricks/ml_features/online_store_spec/azure_sql_server_online_store_spec.py
+-rw-r--r--  2.0 unx     1513 b- defN 23-Nov-29 00:14 databricks/ml_features/online_store_spec/online_store_properties.py
+-rw-r--r--  2.0 unx    20549 b- defN 23-Dec-17 19:21 databricks/ml_features/online_store_spec/online_store_spec.py
+-rw-r--r--  2.0 unx      656 b- defN 23-Nov-29 00:14 databricks/ml_features/publish_engine/__init__.py
+-rw-r--r--  2.0 unx    17798 b- defN 24-Jan-04 22:13 databricks/ml_features/publish_engine/publish_cosmosdb_engine.py
+-rw-r--r--  2.0 unx    11351 b- defN 23-Nov-29 00:14 databricks/ml_features/publish_engine/publish_dynamodb_engine.py
+-rw-r--r--  2.0 unx     6038 b- defN 23-Nov-29 00:14 databricks/ml_features/publish_engine/publish_mysql_engine.py
+-rw-r--r--  2.0 unx     4678 b- defN 23-Nov-29 00:14 databricks/ml_features/publish_engine/publish_sql_engine.py
+-rw-r--r--  2.0 unx     8400 b- defN 23-Nov-29 00:14 databricks/ml_features/publish_engine/publish_sql_server_engine.py
+-rw-r--r--  2.0 unx     7996 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/cosmosdb_type_utils.py
+-rw-r--r--  2.0 unx     3888 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/cosmosdb_utils.py
+-rw-r--r--  2.0 unx     7375 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/dynamodb_type_utils.py
+-rw-r--r--  2.0 unx    11599 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/e2e_test_utils.py
+-rw-r--r--  2.0 unx    14602 b- defN 24-Apr-24 00:34 databricks/ml_features/utils/feature_lookup_utils.py
+-rw-r--r--  2.0 unx     1588 b- defN 23-Dec-17 19:21 databricks/ml_features/utils/feature_serving_endpoint_utils.py
+-rw-r--r--  2.0 unx     1897 b- defN 23-Dec-02 18:11 databricks/ml_features/utils/feature_utils.py
+-rw-r--r--  2.0 unx     1207 b- defN 23-Dec-17 19:21 databricks/ml_features/utils/headers.yaml
+-rw-r--r--  2.0 unx     1609 b- defN 24-Jan-17 21:13 databricks/ml_features/utils/logging_utils.py
+-rw-r--r--  2.0 unx     4445 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/on_demand_utils.py
+-rw-r--r--  2.0 unx     1915 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/publish_utils.py
+-rw-r--r--  2.0 unx    12872 b- defN 24-Feb-02 23:18 databricks/ml_features/utils/request_context.py
+-rw-r--r--  2.0 unx    10989 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/rest_utils.py
+-rw-r--r--  2.0 unx     4686 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/schema_utils.py
+-rw-r--r--  2.0 unx     7587 b- defN 24-Apr-18 22:58 databricks/ml_features/utils/signature_utils.py
+-rw-r--r--  2.0 unx     6414 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/spark_listener.py
+-rw-r--r--  2.0 unx      275 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/spark_test_utils.py
+-rw-r--r--  2.0 unx      919 b- defN 23-Nov-29 00:14 databricks/ml_features/utils/spark_utils.py
+-rw-r--r--  2.0 unx     7656 b- defN 24-Jan-10 19:59 databricks/ml_features/utils/test_utils.py
+-rw-r--r--  2.0 unx    23133 b- defN 24-Apr-18 22:58 databricks/ml_features/utils/training_scoring_utils.py
+-rw-r--r--  2.0 unx     9325 b- defN 23-Dec-02 18:11 databricks/ml_features/utils/utils.py
+-rw-r--r--  2.0 unx     3789 b- defN 23-Dec-17 19:21 databricks/ml_features/utils/validation_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-23 00:35 databricks/ml_features_common/__init__.py
+-rw-r--r--  2.0 unx     1715 b- defN 24-Feb-26 18:04 databricks/ml_features_common/mlflow_model_constants.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/__init__.py
+-rw-r--r--  2.0 unx     1938 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/_feature_store_object.py
+-rw-r--r--  2.0 unx     1489 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/_proto_enum_entity.py
+-rw-r--r--  2.0 unx      454 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/cloud.py
+-rw-r--r--  2.0 unx     4450 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/column_info.py
+-rw-r--r--  2.0 unx     2572 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/feature_column_info.py
+-rw-r--r--  2.0 unx    21270 b- defN 23-Nov-29 00:14 databricks/ml_features_common/entities/feature_spec.py
+-rw-r--r--  2.0 unx      785 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/feature_spec_constants.py
+-rw-r--r--  2.0 unx     1565 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/feature_table_info.py
+-rw-r--r--  2.0 unx     1735 b- defN 23-Nov-29 00:14 databricks/ml_features_common/entities/feature_tables_for_serving.py
+-rw-r--r--  2.0 unx      692 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/function_info.py
+-rw-r--r--  2.0 unx     2002 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/on_demand_column_info.py
+-rw-r--r--  2.0 unx     3730 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/online_feature_table.py
+-rw-r--r--  2.0 unx     4445 b- defN 23-Nov-30 17:39 databricks/ml_features_common/entities/online_store_for_serving.py
+-rw-r--r--  2.0 unx      499 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/query_mode.py
+-rw-r--r--  2.0 unx      874 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/source_data_column_info.py
+-rw-r--r--  2.0 unx      669 b- defN 23-Nov-23 00:35 databricks/ml_features_common/entities/store_type.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-23 00:35 databricks/ml_features_common/protos/__init__.py
+-rw-r--r--  2.0 unx     6398 b- defN 23-Dec-17 19:21 databricks/ml_features_common/protos/feature_spec_pb2.py
+-rw-r--r--  2.0 unx    18522 b- defN 23-Dec-17 19:21 databricks/ml_features_common/protos/feature_store_serving_pb2.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/__init__.py
+-rw-r--r--  2.0 unx     5410 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/converter_utils.py
+-rw-r--r--  2.0 unx     5193 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/dynamodb_utils.py
+-rw-r--r--  2.0 unx     2356 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/feature_spec_test_utils.py
+-rw-r--r--  2.0 unx    11042 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/feature_spec_utils.py
+-rw-r--r--  2.0 unx      374 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/test_utils_common.py
+-rw-r--r--  2.0 unx     5400 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/topological_sort.py
+-rw-r--r--  2.0 unx    10298 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/uc_utils.py
+-rw-r--r--  2.0 unx     3802 b- defN 23-Nov-23 00:35 databricks/ml_features_common/utils/utils_common.py
+-rw-r--r--  2.0 unx     2414 b- defN 24-Apr-24 07:33 databricks_feature_engineering-0.4.0.dist-info/LICENSE.md
+-rw-r--r--  2.0 unx     4242 b- defN 24-Apr-24 07:33 databricks_feature_engineering-0.4.0.dist-info/METADATA
+-rw-r--r--  2.0 unx      515 b- defN 24-Apr-24 07:33 databricks_feature_engineering-0.4.0.dist-info/NOTICE.md
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-24 07:33 databricks_feature_engineering-0.4.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-24 07:33 databricks_feature_engineering-0.4.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx    17051 b- defN 24-Apr-24 07:33 databricks_feature_engineering-0.4.0.dist-info/RECORD
+155 files, 878057 bytes uncompressed, 218097 bytes compressed:  75.2%
```

## zipnote {}

```diff
@@ -96,14 +96,17 @@
 
 Filename: databricks/ml_features/__init__.py
 Comment: 
 
 Filename: databricks/ml_features/constants.py
 Comment: 
 
+Filename: databricks/ml_features/environment_variables.py
+Comment: 
+
 Filename: databricks/ml_features/training_set.py
 Comment: 
 
 Filename: databricks/ml_features/version.py
 Comment: 
 
 Filename: databricks/ml_features/_catalog_client/__init__.py
@@ -438,26 +441,26 @@
 
 Filename: databricks/ml_features_common/utils/uc_utils.py
 Comment: 
 
 Filename: databricks/ml_features_common/utils/utils_common.py
 Comment: 
 
-Filename: databricks_feature_engineering-0.3.0.dist-info/LICENSE.md
+Filename: databricks_feature_engineering-0.4.0.dist-info/LICENSE.md
 Comment: 
 
-Filename: databricks_feature_engineering-0.3.0.dist-info/METADATA
+Filename: databricks_feature_engineering-0.4.0.dist-info/METADATA
 Comment: 
 
-Filename: databricks_feature_engineering-0.3.0.dist-info/NOTICE.md
+Filename: databricks_feature_engineering-0.4.0.dist-info/NOTICE.md
 Comment: 
 
-Filename: databricks_feature_engineering-0.3.0.dist-info/WHEEL
+Filename: databricks_feature_engineering-0.4.0.dist-info/WHEEL
 Comment: 
 
-Filename: databricks_feature_engineering-0.3.0.dist-info/top_level.txt
+Filename: databricks_feature_engineering-0.4.0.dist-info/top_level.txt
 Comment: 
 
-Filename: databricks_feature_engineering-0.3.0.dist-info/RECORD
+Filename: databricks_feature_engineering-0.4.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## databricks/feature_engineering/client.py

```diff
@@ -108,14 +108,15 @@
             self._spark_client
         )
         self._compute_client = ComputeClient(
             catalog_client=self._catalog_client,
             catalog_client_helper=self._catalog_client_helper,
             spark_client=self._spark_client,
             spark_client_helper=self._spark_client_helper,
+            databricks_client=self._databricks_client,
         )
         self._training_scoring_client = TrainingScoringClient(
             catalog_client=self._catalog_client,
             catalog_client_helper=self._catalog_client_helper,
             spark_client=self._spark_client,
             spark_client_helper=self._spark_client_helper,
             information_schema_spark_client=self._information_schema_spark_client,
```

## databricks/feature_engineering/upgrade_client.py

```diff
@@ -62,14 +62,15 @@
 
         self._spark_client_helper = SparkClientHelper(self._spark_client)
         self._compute_client = ComputeClient(
             catalog_client=self._catalog_client,
             catalog_client_helper=self._catalog_client_helper,
             spark_client=self._spark_client,
             spark_client_helper=self._spark_client_helper,
+            databricks_client=self._databricks_client,
         )
 
     def upgrade_workspace_table(
         self,
         *,
         source_workspace_table: str,
         target_uc_table: str,
```

## databricks/feature_store/client.py

```diff
@@ -150,14 +150,15 @@
         )
 
         self._compute_client = ComputeClient(
             catalog_client=self._catalog_client,
             catalog_client_helper=self._catalog_client_helper,
             spark_client=self._spark_client,
             spark_client_helper=self._spark_client_helper,
+            databricks_client=self._databricks_client,
         )
         self._training_scoring_client = TrainingScoringClient(
             catalog_client=self._catalog_client,
             catalog_client_helper=self._catalog_client_helper,
             spark_client=self._spark_client,
             spark_client_helper=self._spark_client_helper,
             information_schema_spark_client=self._information_schema_spark_client,
```

## databricks/ml_features/version.py

```diff
@@ -1 +1 @@
-VERSION = "0.3.0"
+VERSION = "0.4.0"
```

## databricks/ml_features/_compute_client/_compute_client.py

```diff
@@ -7,14 +7,17 @@
 from pyspark.sql.types import StructType
 from pyspark.sql.utils import AnalysisException
 
 from databricks.ml_features._catalog_client._catalog_client import CatalogClient
 from databricks.ml_features._catalog_client._catalog_client_helper import (
     CatalogClientHelper,
 )
+from databricks.ml_features._databricks_client._databricks_client import (
+    DatabricksClient,
+)
 from databricks.ml_features._spark_client._spark_client import SparkClient
 from databricks.ml_features._spark_client._spark_client_helper import SparkClientHelper
 from databricks.ml_features.api.proto.feature_catalog_pb2 import ProducerAction
 from databricks.ml_features.constants import (
     _DEFAULT_WRITE_STREAM_TRIGGER,
     _ERROR,
     _SOURCE_FORMAT_DELTA,
@@ -63,19 +66,21 @@
 
     def __init__(
         self,
         catalog_client: CatalogClient,
         catalog_client_helper: CatalogClientHelper,
         spark_client: SparkClient,
         spark_client_helper: SparkClientHelper,
+        databricks_client: DatabricksClient,
     ):
         self._catalog_client = catalog_client
         self._catalog_client_helper = catalog_client_helper
         self._spark_client = spark_client
         self._spark_client_helper = spark_client_helper
+        self._databricks_client = databricks_client
 
     def create_table(
         self,
         name: str,
         primary_keys: Union[str, List[str]],
         df: Optional[DataFrame],
         *,
@@ -175,16 +180,18 @@
         if timestamp_keys:
             ComputeClient._check_schema_has_columns(
                 table_schema, timestamp_keys_as_list, "timestamp keys"
             )
 
         # 1. Handle cases where the table exists in either Hive or the Catalog
         delta_table_exists = self._spark_client.table_exists(name)
-        catalog_table_exists = self._catalog_client.feature_table_exists(
-            name, req_context
+        catalog_table_exists = (
+            delta_table_exists
+            if is_uc_table
+            else self._catalog_client.feature_table_exists(name, req_context)
         )
 
         if delta_table_exists and not catalog_table_exists:
             raise ValueError(f"Data table {name} already exists. Use a different name.")
 
         if catalog_table_exists and not delta_table_exists:
             raise ValueError(
@@ -473,14 +480,16 @@
           This parameter is only supported when the argument ``df`` is a streaming :class:`DataFrame <pyspark.sql.DataFrame>`.
         :param trigger: If ``df.isStreaming``, ``trigger`` defines the timing of stream data
           processing, the dictionary will be unpacked and passed to :meth:`DataStreamWriter.trigger <pyspark.sql.streaming.DataStreamWriter.trigger>`
           as arguments. For example, ``trigger={'once': True}`` will result in a call to
           ``DataStreamWriter.trigger(once=True)``.
         :return: If ``df.isStreaming``, returns a PySpark :class:`StreaminQuery <pyspark.sql.streaming.StreamingQuery>`, :obj:`None` otherwise.
         """
+        is_uc_table = uc_utils.is_uc_entity(name)
+
         validation_utils.check_dataframe_type(df)
         mode_string = mode.strip().lower()
         if mode_string not in self._WRITE_MODES:
             supported_modes_list = ", ".join([f"'{m}'" for m in self._WRITE_MODES])
             raise ValueError(
                 f"Unsupported mode '{mode}'. Use one of {supported_modes_list}"
             )
@@ -492,22 +501,24 @@
             _logger.warning("Ignoring checkpoint_location, since df is not streaming.")
             checkpoint_location = None
 
         ComputeClient._check_schema_top_level_types_supported(df.schema)
         self._spark_client_helper.check_feature_table_exists(name)
         feature_table = self._catalog_client.get_feature_table(name, req_context)
 
-        # We know from the successful `get_feature_table call` above that the user has
-        # at least read permission. Otherwise backend will throw RESOURCE_DOES_NOT_EXIST exception.
-        # Since this is a write operation, we want to check whether the user has write permission
-        # on the feature table prior to other operations.
-        if not self._catalog_client.can_write_to_catalog(name, req_context):
-            raise PermissionError(
-                f"You do not have permission to write to feature table {name}."
-            )
+        if not is_uc_table:
+            # We know from the successful `get_feature_table call` above that the user has
+            # at least read permission. Otherwise backend will throw RESOURCE_DOES_NOT_EXIST exception.
+            # Since this is a write operation, we want to check whether the user has write permission
+            # on the feature table prior to other operations.
+            # We don't need this check for tables in UC as UC manages the permissions.
+            if not self._catalog_client.can_write_to_catalog(name, req_context):
+                raise PermissionError(
+                    f"You do not have permission to write to feature table {name}."
+                )
 
         # Validate: Internal state is consistent. Existing Delta schema should match Catalog schema.
         features = self._catalog_client.get_features(name, req_context)
         existing_schema = self._spark_client.get_feature_table_schema(name)
         if not schema_utils.catalog_matches_delta_schema(features, existing_schema):
             # If the existing Delta table does not match the Feature Catalog, the state is invalid
             # and we cannot write to the feature table. Error out.
@@ -564,117 +575,119 @@
             ComputeClient._check_unique_case_insensitive_schema(features, df.schema)
             # First update the Delta schema. Spark will handle any type changes, and throw on
             # incompatible types.
             self._update_delta_features(name, df.schema)
             # Now update the Catalog using *the types in the Delta table*. We do not use the types
             # in `df` here so we can defer schema merging logic to Spark.
             delta_schema = self._spark_client.get_feature_table_schema(name)
-            self._update_catalog_features_with_delta_schema(
-                name, feature_table, features, delta_schema, req_context
-            )
+            if not is_uc_table:
+                self._update_catalog_features_with_delta_schema(
+                    name, feature_table, features, delta_schema, req_context
+                )
         else:
             delta_schema = df.schema
 
-        # Exclude self-referential data sources. Feature table should exist.
-        feature_table_data_source = self._spark_client.get_delta_table_path(name)
-        # set(None) can produce exception, set default to empty list
-        excluded_paths = set(utils.as_list(feature_table_data_source, default=[]))
-        # filter the delta checkpoint file.
-        # regexp refer: delta-standalone/src/main/scala/io/delta/standalone/internal/util/FileNames.scala?L27
-        checkpoint_file_pattern = r"\d+\.checkpoint(\.\d+\.\d+)?\.parquet"
-
         # Write data to Delta table
         with SparkSourceListener() as spark_source_listener:
             return_value = self._spark_client.write_table(
                 name,
                 utils.sanitize_identifiers(feature_table.primary_keys),
                 utils.sanitize_identifiers(feature_table.timestamp_keys),
                 df,
                 mode_string,
                 checkpoint_location,
                 trigger,
             )
             subscribed_data_sources = spark_source_listener.get_data_sources()
 
-        tables = set()
-        paths = set()
-        for fmt, sources in subscribed_data_sources.items():
-            # filter out source that are an exact match to the excluded paths.
-            # ToDo(mparkhe): Currently Spark listener will not return subdirs as data sources,
-            #                but in future investigate a clean mechanism to deduplicate,
-            #                and eliminate redundant subdirs reported as (Delta) data sources.
-            #                eg: ["dbfs:/X.db/Y", "dbfs:/X.db/Y/_delta_log/checkpoint..."]
-            valid_sources = list(
+        if not is_uc_table:
+            # Exclude self-referential data sources. Feature table should exist.
+            feature_table_data_source = self._spark_client.get_delta_table_path(name)
+            # set(None) can produce exception, set default to empty list
+            excluded_paths = set(utils.as_list(feature_table_data_source, default=[]))
+            # filter the delta checkpoint file.
+            # regexp refer: delta-standalone/src/main/scala/io/delta/standalone/internal/util/FileNames.scala?L27
+            checkpoint_file_pattern = r"\d+\.checkpoint(\.\d+\.\d+)?\.parquet"
+
+            tables = set()
+            paths = set()
+            for fmt, sources in subscribed_data_sources.items():
+                # filter out source that are an exact match to the excluded paths.
+                # ToDo(mparkhe): Currently Spark listener will not return subdirs as data sources,
+                #                but in future investigate a clean mechanism to deduplicate,
+                #                and eliminate redundant subdirs reported as (Delta) data sources.
+                #                eg: ["dbfs:/X.db/Y", "dbfs:/X.db/Y/_delta_log/checkpoint..."]
+                valid_sources = list(
+                    filter(
+                        lambda source: all(
+                            [
+                                source not in excluded_paths,
+                                not re.match(
+                                    checkpoint_file_pattern, source.split("/")[-1]
+                                ),
+                            ]
+                        ),
+                        sources,
+                    )
+                )
+                if len(valid_sources) > 0:
+                    # We rely on the spark listener to determine whether a data source is a delta table
+                    # for now. However, spark listener categorize delta table by looking up the
+                    # leaf node in spark query plan whereas we categorize delta table by whether or not
+                    # it would show up in the `Data` tab. Inconsistency could happen if user reads a
+                    # delta directory as delta table through `spark.read.format("delta")`,
+                    # we should store such data source as a path rather than a delta table.
+                    if fmt == _SOURCE_FORMAT_DELTA:
+                        for path in valid_sources:
+                            # Convert table-paths to "db_name.table_name".
+                            # Note: If a table-path does not match the top level DBFS path
+                            #       it is preserved as is.
+                            converted_table = (
+                                self._spark_client.convert_to_table_format(path)
+                            )
+                            if converted_table == path:
+                                # Failed to convert table-path to "db_name.table_name",
+                                # record data source as a path
+                                paths.add(path)
+                            else:
+                                tables.add(converted_table)
+                                # Exclude DBFS paths for all the table data sources
+                                excluded_paths.add(path)
+                    else:
+                        paths.update(valid_sources)
+
+            # filter out paths match or are subdirectory (or files) under excluded paths
+            # Example: if excluded_paths = ["dbfs:/path/to/database.db/table]
+            #          also exclude sub-paths like "dbfs:/path/to/database.db/table/subpath"
+            #          but do not exclude "dbfs:/path/to/database.db/tablesubdir"
+            # ToDo(mparkhe): In future investigate a clean mechanism to eliminate subdirs
+            #                of path sources, if returned by Spark listener.
+            #                eg: ["dbfs:/X/Y", "dbfs:/X/Y/subdir"] => ["dbfs:/X/Y"]
+            valid_paths = list(
                 filter(
                     lambda source: all(
                         [
-                            source not in excluded_paths,
-                            not re.match(
-                                checkpoint_file_pattern, source.split("/")[-1]
-                            ),
+                            source != excluded_path
+                            and not source.startswith(utils.as_directory(excluded_path))
+                            for excluded_path in excluded_paths
                         ]
                     ),
-                    sources,
+                    paths,
                 )
             )
-            if len(valid_sources) > 0:
-                # We rely on the spark listener to determine whether a data source is a delta table
-                # for now. However, spark listener categorize delta table by looking up the
-                # leaf node in spark query plan whereas we categorize delta table by whether or not
-                # it would show up in the `Data` tab. Inconsistency could happen if user reads a
-                # delta directory as delta table through `spark.read.format("delta")`,
-                # we should store such data source as a path rather than a delta table.
-                if fmt == _SOURCE_FORMAT_DELTA:
-                    for path in valid_sources:
-                        # Convert table-paths to "db_name.table_name".
-                        # Note: If a table-path does not match the top level DBFS path
-                        #       it is preserved as is.
-                        converted_table = self._spark_client.convert_to_table_format(
-                            path
-                        )
-                        if converted_table == path:
-                            # Failed to convert table-path to "db_name.table_name",
-                            # record data source as a path
-                            paths.add(path)
-                        else:
-                            tables.add(converted_table)
-                            # Exclude DBFS paths for all the table data sources
-                            excluded_paths.add(path)
-                else:
-                    paths.update(valid_sources)
-
-        # filter out paths match or are subdirectory (or files) under excluded paths
-        # Example: if excluded_paths = ["dbfs:/path/to/database.db/table]
-        #          also exclude sub-paths like "dbfs:/path/to/database.db/table/subpath"
-        #          but do not exclude "dbfs:/path/to/database.db/tablesubdir"
-        # ToDo(mparkhe): In future investigate a clean mechanism to eliminate subdirs
-        #                of path sources, if returned by Spark listener.
-        #                eg: ["dbfs:/X/Y", "dbfs:/X/Y/subdir"] => ["dbfs:/X/Y"]
-        valid_paths = list(
-            filter(
-                lambda source: all(
-                    [
-                        source != excluded_path
-                        and not source.startswith(utils.as_directory(excluded_path))
-                        for excluded_path in excluded_paths
-                    ]
-                ),
-                paths,
-            )
-        )
 
-        # record data sources to feature catalog
-        if len(tables) > 0 or len(valid_paths) > 0:
-            self._catalog_client_helper.add_data_sources(
-                name=name,
-                tables=tables,
-                paths=valid_paths,
-                custom_sources=set(),  # No custom_sources in auto tracked data sources
-                req_context=req_context,
-            )
+            # record data sources to feature catalog
+            if len(tables) > 0 or len(valid_paths) > 0:
+                self._catalog_client_helper.add_data_sources(
+                    name=name,
+                    tables=tables,
+                    paths=valid_paths,
+                    custom_sources=set(),  # No custom_sources in auto tracked data sources
+                    req_context=req_context,
+                )
 
         # record producer to feature catalog, with additional instrumentation headers if the method name is write_table
         if (
             req_context.get_header(request_context.FEATURE_STORE_METHOD_NAME)
             == request_context.WRITE_TABLE
         ):
             add_producer_custom_headers = {
@@ -710,55 +723,64 @@
         Returns a full FeatureTable entity with tags attached.
          - include_producers has default True to avoid changing existing client behavior.
          - Includes the timestamp key a part of the primary key in the returned FeatureTable
 
         Warns if the catalog schema does not match the delta table schema.
         Avoid using this method when simpler metadata access (e.g. directly calling GetFeatureTable) will suffice.
         """
+        is_uc_table = uc_utils.is_uc_entity(name)
+
         self._spark_client_helper.check_feature_table_exists(name)
         feature_table = self._catalog_client.get_feature_table(
             name, req_context, include_producers=include_producers
         )
         features = self._catalog_client.get_features(name, req_context)
         df = self._spark_client.read_table(name)
         if not schema_utils.catalog_matches_delta_schema(features, df.schema):
             schema_utils.log_catalog_schema_not_match_delta_schema(
                 features, df.schema, level=_WARN
             )
-        tag_entities = self._catalog_client.get_feature_table_tags(
-            feature_table.table_id, req_context
-        )
-        tag_entities_dict = {
-            tag_entity.key: tag_entity.value for tag_entity in tag_entities
-        }
-        feature_table._tags = tag_entities_dict
+        if is_uc_table:
+            tags = self._databricks_client.get_uc_table_tags(name)
+            feature_table._tags = tags
+        else:
+            tag_entities = self._catalog_client.get_feature_table_tags(
+                feature_table.table_id, req_context
+            )
+            tag_entities_dict = {
+                tag_entity.key: tag_entity.value for tag_entity in tag_entities
+            }
+            feature_table._tags = tag_entities_dict
 
         # Make TK part of PK
         original_pk = feature_table.primary_keys
         feature_table.primary_keys = original_pk + [
             tk for tk in feature_table.timestamp_keys if tk not in original_pk
         ]
         return feature_table
 
     def drop_table(self, name: str, client_name: str) -> None:
+        is_uc_table = uc_utils.is_uc_entity(name)
         req_context = RequestContext(request_context.DROP_TABLE, client_name)
 
-        delta_table_exist = self._spark_client.table_exists(name)
-        feature_table_exists = self._catalog_client.feature_table_exists(
-            name, req_context
+        delta_table_exists = self._spark_client.table_exists(name)
+        feature_table_exists = (
+            delta_table_exists
+            if is_uc_table
+            else self._catalog_client.feature_table_exists(name, req_context)
         )
 
         # Handle cases where catalog data does not exist.
-        if not feature_table_exists and delta_table_exist:
+        if not feature_table_exists and delta_table_exists:
             raise ValueError(
                 f"Delta table '{name}' is not a feature table. Use spark API to drop the delta table. "
                 f"For more information on Spark API, "
                 f"see https://docs.databricks.com/sql/language-manual/sql-ref-syntax-ddl-drop-table.html."
             )
-        if not feature_table_exists and not delta_table_exist:
+        if not feature_table_exists and not delta_table_exists:
             raise ValueError(f"Feature table '{name}' does not exist.")
 
         feature_table = self._catalog_client.get_feature_table(name, req_context)
 
         # Delete the feature table and underlying delta table.
         # First perform a dry-run deletion of catalog data as the backend validates the API call.
         try:
@@ -800,41 +822,50 @@
             consumer_feature_table_map, req_context
         )
         return df
 
     def set_feature_table_tag(
         self, *, table_name: str, key: str, value: str, client_name: str
     ) -> None:
+        is_uc_table = uc_utils.is_uc_entity(table_name)
         # Tags for UC tables can be key-only so don't validate 'value'
-        if uc_utils.is_uc_entity(table_name):
+        if is_uc_table:
             utils.validate_params_non_empty(locals(), ["table_name", "key"])
         else:
             utils.validate_params_non_empty(locals(), ["table_name", "key", "value"])
         req_context = RequestContext(request_context.SET_FEATURE_TABLE_TAG, client_name)
         ft = self.get_table(table_name, req_context, include_producers=False)
-        self._catalog_client.set_feature_table_tags(
-            ft.table_id, {key: value}, req_context
-        )
+
+        if is_uc_table:
+            self._spark_client.set_table_tags(table_name, {key: value})
+        else:
+            self._catalog_client.set_feature_table_tags(
+                ft.table_id, {key: value}, req_context
+            )
 
     def delete_feature_table_tag(
         self, *, table_name: str, key: str, client_name: str
     ) -> None:
+        is_uc_table = uc_utils.is_uc_entity(table_name)
         utils.validate_params_non_empty(locals(), ["table_name", "key"])
         req_context = RequestContext(
             request_context.DELETE_FEATURE_TABLE_TAG, client_name
         )
         ft = self.get_table(table_name, req_context, include_producers=False)
         if key not in ft.tags:
             _logger.warning(
                 f'The tag "{key}" for feature table "{table_name}" was not found, so the delete operation has been skipped.'
             )
         else:
-            self._catalog_client.delete_feature_table_tags(
-                ft.table_id, [key], req_context
-            )
+            if is_uc_table:
+                self._spark_client.unset_table_tags(table_name, [key])
+            else:
+                self._catalog_client.delete_feature_table_tags(
+                    ft.table_id, [key], req_context
+                )
 
     def _check_catalog_matches_delta_metadata(
         self,
         name,
         table_schema,
         primary_keys_as_list,
         partition_cols_as_list,
@@ -975,14 +1006,15 @@
     ) -> FeatureTable:
         """
         Create the feature_table, features and tags.
 
         If any step fails, the exception handler cleans up the feature table from the feature catalog
         and propagates the exception to the caller for further handling.
         """
+        is_uc_table = uc_utils.is_uc_entity(name)
         feature_table = None
 
         try:
             # Additional instrumentation headers for create_feature_table
             req_context_method_name = req_context.get_header(
                 request_context.FEATURE_STORE_METHOD_NAME
             )
@@ -1021,25 +1053,32 @@
                 partition_key_spec=partition_key_specs,
                 primary_key_spec=primary_key_specs,
                 timestamp_key_spec=timestamp_key_specs,
                 description=description,
                 is_imported=is_imported,
                 req_context=create_feature_table_req_context,
             )
-            if len(feature_key_specs) > 0:
+            if len(feature_key_specs) > 0 and not is_uc_table:
                 self._catalog_client.create_features(
                     name, feature_key_specs, req_context
                 )
             if tags:
-                table_id = (
-                    self._catalog_client.get_feature_table(name, req_context).table_id
-                    if (uc_utils.is_uc_entity(name))
-                    else feature_table.table_id
-                )
-                self._catalog_client.set_feature_table_tags(table_id, tags, req_context)
+                if is_uc_table:
+                    self._spark_client.set_table_tags(name, tags)
+                else:
+                    table_id = (
+                        self._catalog_client.get_feature_table(
+                            name, req_context
+                        ).table_id
+                        if (uc_utils.is_uc_entity(name))
+                        else feature_table.table_id
+                    )
+                    self._catalog_client.set_feature_table_tags(
+                        table_id, tags, req_context
+                    )
             return feature_table
         except Exception as e:
             # Delete the newly created feature table in the catalog
             if feature_table:
                 self._catalog_client.delete_feature_table(name, req_context)
             raise e
```

## databricks/ml_features/_databricks_client/_databricks_client.py

```diff
@@ -1,7 +1,9 @@
+from typing import Dict
+
 from databricks.ml_features.utils.rest_utils import http_request, verify_rest_response
 
 _GET_JOB_ENDPOINT = "/api/2.0/jobs/get"
 
 
 class DatabricksClient:
     """
@@ -56,7 +58,27 @@
             self._get_host_creds(),
             url,
             method="GET",
         )
         verify_rest_response(response, url)
         if response.json()["securable_kind"] != "FUNCTION_FEATURE_SPEC":
             raise ValueError(f"{full_feature_spec_name} is not a FeatureSpec.")
+
+    def get_uc_table_tags(self, table_name: str) -> Dict[str, str]:
+        """
+        Get the tags for a UC table.
+        """
+        url = f"/api/2.0/unity-catalog/securable-tags/TABLE/{table_name}"
+        response = http_request(
+            self._get_host_creds(),
+            url,
+            method="GET",
+        )
+        verify_rest_response(response, url)
+        resp_json = response.json()
+        if "tag_assignments" in resp_json:
+            tag_assignments = resp_json["tag_assignments"]
+            if len(tag_assignments) > 0 and "tag_key_value_pairs" in tag_assignments[0]:
+                key_value_pairs = tag_assignments[0]["tag_key_value_pairs"]
+                tags = {tag["key"]: tag["value"] for tag in key_value_pairs}
+                return tags
+        return {}
```

## databricks/ml_features/_feature_serving_endpoint_client/_feature_serving_endpoint_client.py

```diff
@@ -43,18 +43,17 @@
 
         # TaskContext.get() is None on Spark drivers. This is the same check performed by
         # SparkContext._assert_on_driver(), which is called by SparkSession.getOrCreate().
         self._on_spark_driver = TaskContext.get() is None
 
         # Initialize a SparkSession only if on the driver.
         # _internal_spark should not be accessed directly, but through the _spark property.
+        # TODO [ML-40496]: Add back appName to spark initialization once spark connect team gives a proper long term solution
         self._internal_spark = (
-            SparkSession.builder.appName("feature_store.spark_client").getOrCreate()
-            if self._on_spark_driver
-            else None
+            SparkSession.builder.getOrCreate() if self._on_spark_driver else None
         )
         self._mlflow_client = MlflowClient()
         self._databricks_client = DatabricksClient(self._get_host_creds)
 
     @property
     def _spark(self):
         """
```

## databricks/ml_features/_online_store_publish_client/_online_store_publish_nosql_client.py

```diff
@@ -30,17 +30,16 @@
         return PublishCosmosDBEngine(online_store_spec, spark_session)
 
 
 class OnlineStorePublishNoSqlClient(OnlineStorePublishClient):
     def __init__(self, online_store: OnlineStoreSpec):
         if not is_nosql_spec(online_store):
             raise ValueError(f"Unexpected online store type {type(online_store)}")
-        spark_session = SparkSession.builder.appName(
-            "feature_store.nosql_client"
-        ).getOrCreate()
+        # TODO [ML-40496]: Add back appName to spark initialization once spark connect team gives a proper long term solution
+        spark_session = SparkSession.builder.getOrCreate()
         self.nosql_engine = generate_nosql_engine(online_store, spark_session)
 
     def get_or_create_online_table(self, df, primary_keys, timestamp_keys):
         cloud_provider_unique_id = self.nosql_engine.get_cloud_provider_unique_id()
         if not cloud_provider_unique_id:
             cloud_provider_unique_id = self.nosql_engine.create_empty_table(
                 df.schema, primary_keys, timestamp_keys
```

## databricks/ml_features/_online_store_publish_client/_online_store_publish_rdbms_client.py

```diff
@@ -64,18 +64,16 @@
 class OnlineStorePublishRdbmsClient(OnlineStorePublishClient):
     def __init__(self, online_store):
         if not is_rdbms_spec(online_store):
             raise ValueError(f"Unexpected online store type {type(online_store)}")
         self.database = online_store.database_name
         self.table_name = online_store.table_name
         self.online_store = online_store
-        self.spark_session = SparkSession.builder.appName(
-            "feature_store.rdbms_client"
-        ).getOrCreate()
-
+        # TODO [ML-40496]: Add back appName to spark initialization once spark connect team gives a proper long term solution
+        self.spark_session = SparkSession.builder.getOrCreate()
         self.sql_engine = generate_sql_engine(self.online_store, self.spark_session)
 
     def _online_table_exists(self, table_name):
         # TODO: Check if this works for a user without read access to table_name.
         result_set = self.sql_engine.get_online_tables(table_names=[table_name])
         return result_set.next()  # Returns false if there are no rows in the result set
```

## databricks/ml_features/_publish_client/_publish_client.py

```diff
@@ -23,14 +23,15 @@
 from databricks.ml_features.online_store_spec.online_store_spec import OnlineStoreSpec
 from databricks.ml_features.utils import request_context, schema_utils, utils
 from databricks.ml_features.utils.publish_utils import (
     update_online_store_spec_sticky_ttl,
 )
 from databricks.ml_features.utils.request_context import RequestContext
 from databricks.ml_features.utils.rest_utils import get_error_code
+from databricks.ml_features_common.utils import uc_utils
 
 _logger = logging.getLogger(__name__)
 
 
 class PublishClient:
     _PUBLISH_MODES = [OVERWRITE, MERGE]
 
@@ -430,17 +431,18 @@
             f"Published table {online_table.name} dropped from online store "
             "and removed from Databricks. "
         )
 
     def _verify_table_exists_in_delta_and_catalog(
         self, feature_table_name, req_context
     ):
+        is_uc_table = uc_utils.is_uc_entity(feature_table_name)
         # Check: feature table exists as a delta table
         self._spark_client_helper.check_feature_table_exists(feature_table_name)
 
         # Check: feature tables exists in the catalog and user contains READ permissions
-        if not self._catalog_client.feature_table_exists(
+        if not is_uc_table and not self._catalog_client.feature_table_exists(
             feature_table_name, req_context
         ):
             raise ValueError(
                 f"Feature table '{feature_table_name}' does not exist in the catalog."
             )
```

## databricks/ml_features/_spark_client/_spark_client.py

```diff
@@ -53,18 +53,17 @@
         """
         # TaskContext.get() is None on Spark drivers. This is the same check performed by
         # SparkContext._assert_on_driver(), which is called by SparkSession.getOrCreate().
         self._on_spark_driver = TaskContext.get() is None
 
         # Initialize a SparkSession only if on the driver.
         # _internal_spark should not be accessed directly, but through the _spark property.
+        # TODO [ML-40496]: Add back appName to spark initialization once spark connect team gives a proper long term solution
         self._internal_spark = (
-            SparkSession.builder.appName("feature_store.spark_client").getOrCreate()
-            if self._on_spark_driver
-            else None
+            SparkSession.builder.getOrCreate() if self._on_spark_driver else None
         )
 
     @property
     def _spark(self):
         """
         Property method to return the initialized SparkSession.
         Throws outside of the Spark driver as the SparkSession is not initialized.
@@ -119,21 +118,17 @@
         except AnalysisException:
             return False
 
     def table_exists(self, full_table_name):
         """
         Determines whether a table exists in this database.
         """
-        try:
-            df = self._spark.sql(
-                f"DESCRIBE TABLE {sanitize_multi_level_name(full_table_name)}"
-            )
-            return not df.isEmpty()
-        except AnalysisException:
-            return False
+        return self._spark.catalog.tableExists(
+            sanitize_multi_level_name(full_table_name)
+        )
 
     def set_column_comment(self, delta_table_name, column_name, comment):
         """
         Set a column's comment. If comment is None, the column's comment will be removed.
         """
         if comment is None:
             self._spark.sql(
```

## databricks/ml_features/api/proto/feature_catalog_pb2.py

```diff
@@ -16,15 +16,15 @@
 
 
 from mlflow.protos.scalapb import scalapb_pb2 as scalapb_dot_scalapb__pb2
 from mlflow.protos import databricks_pb2 as databricks__pb2
 from databricks.ml_features_common.protos import feature_store_serving_pb2 as feature__store__serving__pb2
 
 
-DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x15\x66\x65\x61ture_catalog.proto\x12\x0c\x66\x65\x61turestore\x1a\x15scalapb/scalapb.proto\x1a\x10\x64\x61tabricks.proto\x1a\x1b\x66\x65\x61ture_store_serving.proto\"\x96\x01\n\x0bHealthCheck\x12\x12\n\x03key\x18\x01 \x01(\t:\x05store\x12\x17\n\x05value\x18\x02 \x01(\t:\x08\x66\x65\x61tures\x1a-\n\x08Response\x12\x0e\n\x06result\x18\x01 \x01(\t\x12\x11\n\ttimestamp\x18\x02 \x01(\x03:+\xe2?(\n&com.databricks.rpc.RPC[$this.Response]\"\x9f\x03\n\x12\x43reateFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12+\n\x0cprimary_keys\x18\x02 \x03(\x0b\x32\x15.featurestore.KeySpec\x12-\n\x0epartition_keys\x18\x03 \x03(\x0b\x32\x15.featurestore.KeySpec\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x12\n\ntable_path\x18\x05 \x01(\t\x12-\n\x0etimestamp_keys\x18\x06 \x03(\x0b\x32\x15.featurestore.KeySpec\x12\x13\n\x0bis_imported\x18\x07 \x01(\x08\x12\x16\n\x07\x64ry_run\x18\x08 \x01(\x08:\x05\x66\x61lse\x12\'\n\x08\x66\x65\x61tures\x18\t \x03(\x0b\x32\x15.featurestore.KeySpec\x1a=\n\x08Response\x12\x31\n\rfeature_table\x18\x01 \x01(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xaa\x01\n\x12UpdateFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x1a=\n\x08Response\x12\x31\n\rfeature_table\x18\x01 \x01(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"z\n\x12\x44\x65leteFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x16\n\x07\x64ry_run\x18\x02 \x01(\x08:\x05\x66\x61lse\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"}\n\x0bUpgradeToUc\x12\x19\n\x11source_table_name\x18\x01 \x01(\t\x12\x19\n\x11target_table_name\x18\x02 \x01(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x8d\x01\n\x1cUpgradeWorkspaceFeatureTable\x12\x1c\n\x14workspace_table_name\x18\x01 \x01(\t\x12\x15\n\ruc_table_name\x18\x02 \x01(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xb4\x01\n\x0fGetFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12 \n\x11include_producers\x18\x02 \x01(\x08:\x05\x66\x61lse\x1a=\n\x08Response\x12\x31\n\rfeature_table\x18\x01 \x01(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xef\x05\n\x13SearchFeatureTables\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x17\n\x0bmax_results\x18\x02 \x01(\x03:\x02\x31\x30\x12\x12\n\npage_token\x18\x03 \x01(\t\x12\x30\n\rsearch_scopes\x18\x04 \x03(\x0e\x32\x19.featurestore.SearchScope\x12\x14\n\x0c\x63\x61talog_name\x18\x05 \x01(\t\x12\x1f\n\x04tags\x18\x06 \x03(\x0b\x32\x11.featurestore.Tag\x12\x1f\n\x10is_multi_catalog\x18\x07 \x01(\x08:\x05\x66\x61lse\x12\x15\n\rcatalog_names\x18\x08 \x03(\t\x12\x11\n\towner_ids\x18\t \x03(\t\x12?\n\nsort_order\x18\n \x01(\x0b\x32+.featurestore.SearchFeatureTables.SortOrder\x1a\x89\x01\n\tSortOrder\x12Q\n\x08\x63riteria\x18\x01 \x01(\x0e\x32\x38.featurestore.SearchFeatureTables.SortOrder.SortCriteria:\x05SCORE\")\n\x0cSortCriteria\x12\t\n\x05SCORE\x10\x01\x12\x0e\n\nPOPULARITY\x10\x02\x1a\xed\x01\n\x08Response\x12\x32\n\x0e\x66\x65\x61ture_tables\x18\x01 \x03(\x0b\x32\x1a.featurestore.FeatureTable\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\x12Q\n\x0chighlighting\x18\x03 \x03(\x0b\x32;.featurestore.SearchFeatureTables.Response.HighlightingInfo\x1a\x41\n\x10HighlightingInfo\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xc3\x01\n\x16GetFeatureTableSchemas\x12<\n\x13\x66\x65\x61ture_identifiers\x18\x01 \x03(\x0b\x32\x1f.featurestore.FeatureIdentifier\x1a=\n\x08Response\x12\x31\n\x07schemas\x18\x01 \x03(\x0b\x32 .featurestore.FeatureTableSchema:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\">\n\x11\x46\x65\x61tureIdentifier\x12\x12\n\ntable_name\x18\x01 \x01(\t\x12\x15\n\rfeature_names\x18\x02 \x03(\t\"\xac\x01\n\x12\x46\x65\x61tureTableSchema\x12\x12\n\ntable_name\x18\x01 \x01(\t\x12\'\n\x08\x66\x65\x61tures\x18\x02 \x03(\x0b\x32\x15.featurestore.KeySpec\x12*\n\x0b\x65ntity_keys\x18\x03 \x03(\x0b\x32\x15.featurestore.KeySpec\x12-\n\x0etimestamp_keys\x18\x04 \x03(\x0b\x32\x15.featurestore.KeySpec\"\x91\x01\n\x14GetFeatureTablesById\x12\x0b\n\x03ids\x18\x01 \x03(\t\x1a>\n\x08Response\x12\x32\n\x0e\x66\x65\x61ture_tables\x18\x01 \x03(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xe2\x01\n\x0e\x41\x64\x64\x44\x61taSources\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0e\n\x06tables\x18\x02 \x03(\t\x12\r\n\x05paths\x18\x03 \x03(\t\x12\x16\n\x0e\x63ustom_sources\x18\x04 \x03(\t\x12\x42\n\x10\x61ssociation_type\x18\x05 \x01(\x0e\x32\x1d.featurestore.AssociationType:\tAUTOMATIC\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"{\n\x11\x44\x65leteDataSources\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0f\n\x07sources\x18\x02 \x03(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xb7\x05\n\x13PublishFeatureTable\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x1a\n\x0conline_table\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12.\n\x05\x63loud\x18\x03 \x01(\x0e\x32\x19.featurestorecommon.CloudB\x04\xf8\x86\x19\x01\x12\x37\n\nstore_type\x18\x04 \x01(\x0e\x32\x1d.featurestorecommon.StoreTypeB\x04\xf8\x86\x19\x01\x12\x0c\n\x04host\x18\x05 \x01(\t\x12\x0c\n\x04port\x18\x06 \x01(\x05\x12\x1a\n\x12read_secret_prefix\x18\x07 \x01(\t\x12\x1b\n\x13write_secret_prefix\x18\x08 \x01(\t\x12;\n\x0emysql_metadata\x18\t \x01(\x0b\x32!.featurestorecommon.MySqlMetadataH\x00\x12\x44\n\x13sql_server_metadata\x18\n \x01(\x0b\x32%.featurestorecommon.SqlServerMetadataH\x00\x12\x41\n\x11\x64ynamodb_metadata\x18\x0b \x01(\x0b\x32$.featurestorecommon.DynamoDbMetadataH\x00\x12\x41\n\x11\x63osmosdb_metadata\x18\r \x01(\x0b\x32$.featurestorecommon.CosmosDbMetadataH\x00\x12\x10\n\x08\x66\x65\x61tures\x18\x0c \x03(\t\x1aI\n\x08Response\x12=\n\x0conline_store\x18\x01 \x01(\x0b\x32\'.featurestorecommon.OnlineStoreDetailed:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x15\n\x13\x61\x64\x64itional_metadata\"\xbb\x02\n\x11\x44\x65leteOnlineStore\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x1a\n\x0conline_table\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12.\n\x05\x63loud\x18\x03 \x01(\x0e\x32\x19.featurestorecommon.CloudB\x04\xf8\x86\x19\x01\x12\x37\n\nstore_type\x18\x04 \x01(\x0e\x32\x1d.featurestorecommon.StoreTypeB\x04\xf8\x86\x19\x01\x12\x13\n\ttable_arn\x18\x05 \x01(\tH\x00\x12\x17\n\rcontainer_uri\x18\x06 \x01(\tH\x00\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x1c\n\x1a\x63loud_provider_resource_id\"\xd4\x01\n\x0bGetFeatures\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x18\n\x0bmax_results\x18\x02 \x01(\x03:\x03\x35\x30\x30\x12\x12\n\npage_token\x18\x03 \x01(\t\x1aL\n\x08Response\x12\'\n\x08\x66\x65\x61tures\x18\x01 \x03(\x0b\x32\x15.featurestore.Feature\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x9f\x01\n\nGetFeature\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x12\n\x04name\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x1a\x32\n\x08Response\x12&\n\x07\x66\x65\x61ture\x18\x01 \x01(\x0b\x32\x15.featurestore.Feature:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x90\x01\n\x0e\x43reateFeatures\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\'\n\x08\x66\x65\x61tures\x18\x02 \x03(\x0b\x32\x15.featurestore.KeySpec\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xe5\x01\n\rUpdateFeature\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x12\n\x04name\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x11\n\tdata_type\x18\x03 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x19\n\x11\x64\x61ta_type_details\x18\x05 \x01(\t\x1a\x32\n\x08Response\x12&\n\x07\x66\x65\x61ture\x18\x01 \x01(\x0b\x32\x15.featurestore.Feature:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xac\x02\n\x0b\x41\x64\x64Producer\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12*\n\x08notebook\x18\x02 \x01(\x0b\x32\x16.featurestore.NotebookH\x00\x12$\n\x07job_run\x18\x03 \x01(\x0b\x32\x11.featurestore.JobH\x00\x12\x31\n\x0c\x64lt_pipeline\x18\x05 \x01(\x0b\x32\x19.featurestore.DltPipelineH\x00\x12\x35\n\x0fproducer_action\x18\x04 \x01(\x0e\x32\x1c.featurestore.ProducerAction\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\n\n\x08producer\"\x8a\x02\n\x0b\x41\x64\x64\x43onsumer\x12\x30\n\x08\x66\x65\x61tures\x18\x01 \x03(\x0b\x32\x1e.featurestore.ConsumedFeatures\x12*\n\x08notebook\x18\x02 \x01(\x0b\x32\x16.featurestore.NotebookH\x00\x12$\n\x07job_run\x18\x03 \x01(\x0b\x32\x11.featurestore.JobH\x00\x12\x31\n\x0c\x64lt_pipeline\x18\x04 \x01(\x0b\x32\x19.featurestore.DltPipelineH\x00\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\n\n\x08\x63onsumer\"\x90\x01\n\x0cGetConsumers\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x1a\x35\n\x08Response\x12)\n\tconsumers\x18\x01 \x03(\x0b\x32\x16.featurestore.Consumer:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x8b\x01\n\x1eGetFeatureStoreWidePermissions\x1a\x43\n\x08Response\x12\x37\n\x10permission_level\x18\x01 \x01(\x0e\x32\x1d.featurestore.PermissionLevel:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]\"\xf7\x02\n\x0eGetOnlineStore\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x1a\n\x0conline_table\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12.\n\x05\x63loud\x18\x03 \x01(\x0e\x32\x19.featurestorecommon.CloudB\x04\xf8\x86\x19\x01\x12\x37\n\nstore_type\x18\x04 \x01(\x0e\x32\x1d.featurestorecommon.StoreTypeB\x04\xf8\x86\x19\x01\x12\x13\n\ttable_arn\x18\x05 \x01(\tH\x00\x12\x17\n\rcontainer_uri\x18\x06 \x01(\tH\x00\x1aI\n\x08Response\x12=\n\x0conline_store\x18\x01 \x01(\x0b\x32\'.featurestorecommon.OnlineStoreDetailed:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x1c\n\x1a\x63loud_provider_resource_id\"\xde\x01\n\x17GetModelServingMetadata\x12\x42\n\x16\x66\x65\x61ture_table_features\x18\x01 \x03(\x0b\x32\".featurestore.FeatureTableFeatures\x1aQ\n\x08Response\x12\x45\n\x15online_feature_tables\x18\x01 \x03(\x0b\x32&.featurestorecommon.OnlineFeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xe7\x01\n GetBrickstoreOnlineTableMetadata\x12\x42\n\x16\x66\x65\x61ture_table_features\x18\x01 \x03(\x0b\x32\".featurestore.FeatureTableFeatures\x1aQ\n\x08Response\x12\x45\n\x15online_feature_tables\x18\x01 \x03(\x0b\x32&.featurestorecommon.OnlineFeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x90\x02\n\x16GetOnlineFeatureTables\x12\x42\n\x16\x66\x65\x61ture_table_features\x18\x01 \x03(\x0b\x32\".featurestore.FeatureTableFeatures\x12\x1a\n\x12include_brickstore\x18\x02 \x01(\x08\x12\x15\n\ris_v1_serving\x18\x03 \x01(\x08\x1aQ\n\x08Response\x12\x45\n\x15online_feature_tables\x18\x01 \x03(\x0b\x32&.featurestorecommon.OnlineFeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xa3\x01\n\x07SetTags\x12\x1a\n\x10\x66\x65\x61ture_table_id\x18\x01 \x01(\tH\x00\x12\x14\n\nfeature_id\x18\x02 \x01(\tH\x00\x12\x1f\n\x04tags\x18\x0b \x03(\x0b\x32\x11.featurestore.Tag\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x0b\n\tentity_id\"\xa3\x01\n\x07GetTags\x12\x1a\n\x10\x66\x65\x61ture_table_id\x18\x01 \x01(\tH\x00\x12\x14\n\nfeature_id\x18\x02 \x01(\tH\x00\x1a+\n\x08Response\x12\x1f\n\x04tags\x18\x01 \x03(\x0b\x32\x11.featurestore.Tag:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x0b\n\tentity_id\"\x93\x01\n\nDeleteTags\x12\x1a\n\x10\x66\x65\x61ture_table_id\x18\x01 \x01(\tH\x00\x12\x14\n\nfeature_id\x18\x02 \x01(\tH\x00\x12\x0c\n\x04keys\x18\x0b \x03(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x0b\n\tentity_id\"Q\n\x07KeySpec\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x17\n\tdata_type\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x19\n\x11\x64\x61ta_type_details\x18\x03 \x01(\t\"\x84\x05\n\x0c\x46\x65\x61tureTable\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x02 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x03 \x01(\x03\x12\x12\n\ncreator_id\x18\x04 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x05 \x01(\t\x12\x14\n\x0cprimary_keys\x18\x06 \x03(\t\x12\x16\n\x0epartition_keys\x18\x07 \x03(\t\x12\x10\n\x08\x66\x65\x61tures\x18\x08 \x03(\t\x12.\n\x0c\x64\x61ta_sources\x18\t \x03(\x0b\x32\x18.featurestore.DataSource\x12\x36\n\ronline_stores\x18\n \x03(\x0b\x32\x1f.featurestorecommon.OnlineStore\x12\x32\n\x12notebook_producers\x18\x0b \x03(\x0b\x32\x16.featurestore.Notebook\x12(\n\rjob_producers\x18\x0c \x03(\x0b\x32\x11.featurestore.Job\x12\x39\n\x16\x64lt_pipeline_producers\x18\x12 \x03(\x0b\x32\x19.featurestore.DltPipeline\x12\x1b\n\x13last_update_user_id\x18\r \x01(\t\x12\n\n\x02id\x18\x0e \x01(\t\x12\x37\n\x10permission_level\x18\x0f \x01(\x0e\x32\x1d.featurestore.PermissionLevel\x12\x16\n\x0etimestamp_keys\x18\x10 \x03(\t\x12\x13\n\x0bis_imported\x18\x11 \x01(\x08\x12\x1f\n\x04tags\x18\x13 \x03(\x0b\x32\x11.featurestore.Tag\x12\x10\n\x08owner_id\x18\x14 \x01(\t\"\x80\x02\n\x07\x46\x65\x61ture\x12\r\n\x05table\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12/\n\tdata_type\x18\x03 \x01(\x0e\x32\x1c.featurestorecommon.DataType\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x19\n\x11\x64\x61ta_type_details\x18\x05 \x01(\t\x12\n\n\x02id\x18\x06 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x07 \x01(\x03\x12\x12\n\ncreator_id\x18\x08 \x01(\t\x12\x1e\n\x16last_updated_timestamp\x18\t \x01(\x03\x12\x1b\n\x13last_update_user_id\x18\n \x01(\t\"@\n\nDataSource\x12\r\n\x05table\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x15\n\rcustom_source\x18\x03 \x01(\t\"0\n\x10\x43onsumedFeatures\x12\r\n\x05table\x18\x01 \x01(\t\x12\r\n\x05names\x18\x02 \x03(\t\"\x9a\x02\n\x08Notebook\x12\x13\n\x0bnotebook_id\x18\x01 \x01(\x03\x12\x13\n\x0brevision_id\x18\x02 \x01(\x03\x12\x1a\n\x0eworkspace_path\x18\x03 \x01(\tB\x02\x18\x01\x12\x1a\n\x12\x63reation_timestamp\x18\x04 \x01(\x03\x12\x12\n\ncreator_id\x18\x05 \x01(\t\x12\x1d\n\x15notebook_workspace_id\x18\x06 \x01(\x03\x12\"\n\x1a\x66\x65\x61ture_table_workspace_id\x18\x07 \x01(\x03\x12\x1e\n\x16notebook_workspace_url\x18\x08 \x01(\t\x12\x35\n\x0fproducer_action\x18\t \x01(\x0e\x32\x1c.featurestore.ProducerAction\"\xfb\x01\n\x03Job\x12\x0e\n\x06job_id\x18\x01 \x01(\x03\x12\x0e\n\x06run_id\x18\x02 \x01(\x03\x12\x14\n\x08job_name\x18\x03 \x01(\tB\x02\x18\x01\x12\x1a\n\x12\x63reation_timestamp\x18\x04 \x01(\x03\x12\x12\n\ncreator_id\x18\x05 \x01(\t\x12\x18\n\x10job_workspace_id\x18\x06 \x01(\x03\x12\"\n\x1a\x66\x65\x61ture_table_workspace_id\x18\x07 \x01(\x03\x12\x19\n\x11job_workspace_url\x18\x08 \x01(\t\x12\x35\n\x0fproducer_action\x18\t \x01(\x0e\x32\x1c.featurestore.ProducerAction\"\x9c\x01\n\x0b\x44ltPipeline\x12\x13\n\x0bpipeline_id\x18\x01 \x01(\t\x12\x11\n\tupdate_id\x18\x02 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x03 \x01(\x03\x12\x12\n\ncreator_id\x18\x04 \x01(\t\x12\x35\n\x0fproducer_action\x18\x05 \x01(\x0e\x32\x1c.featurestore.ProducerAction\"\xab\x01\n\x08\x43onsumer\x12\x10\n\x08\x66\x65\x61tures\x18\x01 \x03(\t\x12*\n\x08notebook\x18\x02 \x01(\x0b\x32\x16.featurestore.NotebookH\x00\x12$\n\x07job_run\x18\x03 \x01(\x0b\x32\x11.featurestore.JobH\x00\x12\x31\n\x0c\x64lt_pipeline\x18\x04 \x01(\x0b\x32\x19.featurestore.DltPipelineH\x00\x42\x08\n\x06\x65ntity\"D\n\x14\x46\x65\x61tureTableFeatures\x12\x1a\n\x12\x66\x65\x61ture_table_name\x18\x01 \x01(\t\x12\x10\n\x08\x66\x65\x61tures\x18\x02 \x03(\t\"!\n\x03Tag\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"\xa8\x01\n\x11\x43reateFeatureSpec\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x19\n\x11\x66\x65\x61ture_spec_yaml\x18\x02 \x01(\t\x1a\x44\n\x08Response\x12\x38\n\x11\x66\x65\x61ture_spec_info\x18\x01 \x01(\x0b\x32\x1d.featurestore.FeatureSpecInfo:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]\"O\n\x0f\x46\x65\x61tureSpecInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07\x63reator\x18\x02 \x01(\t\x12\x1d\n\x15\x63reation_timestamp_ms\x18\x03 \x01(\x03*r\n\x0fPermissionLevel\x12\x0e\n\nCAN_MANAGE\x10\x00\x12\x15\n\x11\x43\x41N_EDIT_METADATA\x10\x01\x12\x15\n\x11\x43\x41N_VIEW_METADATA\x10\x02\x12\x0e\n\nCAN_CREATE\x10\x03\x12\x11\n\rMANAGED_BY_UC\x10\x04*5\n\x0eProducerAction\x12\n\n\x06\x43REATE\x10\x00\x12\t\n\x05WRITE\x10\x01\x12\x0c\n\x08REGISTER\x10\x02*,\n\x0f\x41ssociationType\x12\r\n\tAUTOMATIC\x10\x00\x12\n\n\x06MANUAL\x10\x01*k\n\x0bSearchScope\x12\x12\n\x0e\x46\x45\x41TURE_TABLES\x10\x01\x12\x0c\n\x08\x46\x45\x41TURES\x10\x02\x12\x10\n\x0c\x44\x41TA_SOURCES\x10\x03\x12\x16\n\x12\x46\x45\x41TURE_TABLE_TAGS\x10\x04\x12\x10\n\x0c\x46\x45\x41TURE_TAGS\x10\x05\x32\xe3+\n\x13\x46\x65\x61tureStoreService\x12\xab\x01\n\x0bhealthCheck\x12\x19.featurestore.HealthCheck\x1a\".featurestore.HealthCheck.Response\"]\xf2\x86\x19Y\n(\n\x03GET\x12\x1b/feature-store/health-check\x1a\x04\x08\x02\x10\x00\x10\x03*+Health check for Feature Store service pod.\x12\xb4\x01\n\x12\x63reateFeatureTable\x12 .featurestore.CreateFeatureTable\x1a).featurestore.CreateFeatureTable.Response\"Q\xf2\x86\x19M\n2\n\x04POST\x12$/feature-store/feature-tables/create\x1a\x04\x08\x02\x10\x00\x10\x03*\x15\x43reate Feature Table.\x12\xb5\x01\n\x12updateFeatureTable\x12 .featurestore.UpdateFeatureTable\x1a).featurestore.UpdateFeatureTable.Response\"R\xf2\x86\x19N\n3\n\x05PATCH\x12$/feature-store/feature-tables/update\x1a\x04\x08\x02\x10\x00\x10\x03*\x15Update Feature Table.\x12\xb6\x01\n\x12\x64\x65leteFeatureTable\x12 .featurestore.DeleteFeatureTable\x1a).featurestore.DeleteFeatureTable.Response\"S\xf2\x86\x19O\n4\n\x06\x44\x45LETE\x12$/feature-store/feature-tables/delete\x1a\x04\x08\x02\x10\x00\x10\x03*\x15\x44\x65lete Feature Table.\x12\xae\x01\n\x0bupgradeToUc\x12\x19.featurestore.UpgradeToUc\x1a\".featurestore.UpgradeToUc.Response\"`\xf2\x86\x19\\\n9\n\x04POST\x12+/feature-store/feature-tables/upgrade-to-uc\x1a\x04\x08\x02\x10\x00\x10\x03*\x1dUpgrade workspace table to UC\x12\xf4\x01\n\x1cupgradeWorkspaceFeatureTable\x12*.featurestore.UpgradeWorkspaceFeatureTable\x1a\x33.featurestore.UpgradeWorkspaceFeatureTable.Response\"s\xf2\x86\x19o\nI\n\x04POST\x12;/feature-store/feature-tables/upgrade-workspace-table-to-uc\x1a\x04\x08\x02\x10\x00\x10\x03* Upgrade Workspace Feature Table.\x12\xa4\x01\n\x0fgetFeatureTable\x12\x1d.featurestore.GetFeatureTable\x1a&.featurestore.GetFeatureTable.Response\"J\xf2\x86\x19\x46\n.\n\x03GET\x12!/feature-store/feature-tables/get\x1a\x04\x08\x02\x10\x00\x10\x03*\x12Get Feature Table.\x12\xed\x01\n\x13searchFeatureTables\x12!.featurestore.SearchFeatureTables\x1a*.featurestore.SearchFeatureTables.Response\"\x86\x01\xf2\x86\x19\x81\x01\n2\n\x04POST\x12$/feature-store/feature-tables/search\x1a\x04\x08\x02\x10\x00\n1\n\x03GET\x12$/feature-store/feature-tables/search\x1a\x04\x08\x02\x10\x00\x10\x03*\x16Search Feature Tables.\x12\xc2\x01\n\x14getFeatureTablesById\x12\".featurestore.GetFeatureTablesById\x1a+.featurestore.GetFeatureTablesById.Response\"Y\xf2\x86\x19U\n6\n\x04POST\x12(/feature-store/feature-tables/get-by-ids\x1a\x04\x08\x02\x10\x00\x10\x03*\x19Get Feature Tables by ID.\x12\xd2\x01\n\x16getFeatureTableSchemas\x12$.featurestore.GetFeatureTableSchemas\x1a-.featurestore.GetFeatureTableSchemas.Response\"c\xf2\x86\x19_\n7\n\x04POST\x12)/feature-store/feature-tables/get-schemas\x1a\x04\x08\x02\x10\x00\x10\x03*\"Get the schemas for feature tables\x12\xc0\x01\n\x0e\x61\x64\x64\x44\x61taSources\x12\x1c.featurestore.AddDataSources\x1a%.featurestore.AddDataSources.Response\"i\xf2\x86\x19\x65\n<\n\x04POST\x12./feature-store/feature-tables/add-data-sources\x1a\x04\x08\x02\x10\x00\x10\x03*#Add Data Sources for Feature Table.\x12\xcf\x01\n\x11\x64\x65leteDataSources\x12\x1f.featurestore.DeleteDataSources\x1a(.featurestore.DeleteDataSources.Response\"o\xf2\x86\x19k\n?\n\x04POST\x12\x31/feature-store/feature-tables/delete-data-sources\x1a\x04\x08\x02\x10\x00\x10\x03*&Delete Data Sources for Feature Table.\x12\xb9\x01\n\x13publishFeatureTable\x12!.featurestore.PublishFeatureTable\x1a*.featurestore.PublishFeatureTable.Response\"S\xf2\x86\x19O\n3\n\x04POST\x12%/feature-store/feature-tables/publish\x1a\x04\x08\x02\x10\x00\x10\x03*\x16Publish Feature Table.\x12\xbf\x01\n\x11\x64\x65leteOnlineStore\x12\x1f.featurestore.DeleteOnlineStore\x1a(.featurestore.DeleteOnlineStore.Response\"_\xf2\x86\x19[\nA\n\x06\x44\x45LETE\x12\x31/feature-store/feature-tables/delete-online-store\x1a\x04\x08\x02\x10\x00\x10\x03*\x14\x44\x65lete Online Store.\x12\x8d\x01\n\x0bgetFeatures\x12\x19.featurestore.GetFeatures\x1a\".featurestore.GetFeatures.Response\"?\xf2\x86\x19;\n(\n\x03GET\x12\x1b/feature-store/features/get\x1a\x04\x08\x02\x10\x00\x10\x03*\rGet Features.\x12\x91\x01\n\ngetFeature\x12\x18.featurestore.GetFeature\x1a!.featurestore.GetFeature.Response\"F\xf2\x86\x19\x42\n0\n\x03GET\x12#/feature-store/features/get-by-name\x1a\x04\x08\x02\x10\x00\x10\x03*\x0cGet Feature.\x12\x9d\x01\n\x0e\x63reateFeatures\x12\x1c.featurestore.CreateFeatures\x1a%.featurestore.CreateFeatures.Response\"F\xf2\x86\x19\x42\n,\n\x04POST\x12\x1e/feature-store/features/create\x1a\x04\x08\x02\x10\x00\x10\x03*\x10\x43reate Features.\x12\x9a\x01\n\rupdateFeature\x12\x1b.featurestore.UpdateFeature\x1a$.featurestore.UpdateFeature.Response\"F\xf2\x86\x19\x42\n-\n\x05PATCH\x12\x1e/feature-store/features/update\x1a\x04\x08\x02\x10\x00\x10\x03*\x0fUpdate Feature.\x12\x9d\x01\n\x0b\x61\x64\x64Producer\x12\x19.featurestore.AddProducer\x1a\".featurestore.AddProducer.Response\"O\xf2\x86\x19K\n8\n\x04POST\x12*/feature-store/feature-tables/add-producer\x1a\x04\x08\x02\x10\x00\x10\x03*\rAdd Producer.\x12\x97\x01\n\x0b\x61\x64\x64\x43onsumer\x12\x19.featurestore.AddConsumer\x1a\".featurestore.AddConsumer.Response\"I\xf2\x86\x19\x45\n2\n\x04POST\x12$/feature-store/features/add-consumer\x1a\x04\x08\x02\x10\x00\x10\x03*\rAdd Consumer.\x12\xa1\x01\n\x0cgetConsumers\x12\x1a.featurestore.GetConsumers\x1a#.featurestore.GetConsumers.Response\"P\xf2\x86\x19L\n8\n\x03GET\x12+/feature-store/feature-tables/get-consumers\x1a\x04\x08\x02\x10\x00\x10\x03*\x0eGet Consumers.\x12\x9d\x02\n\x1egetFeatureStoreWidePermissions\x12,.featurestore.GetFeatureStoreWidePermissions\x1a\x35.featurestore.GetFeatureStoreWidePermissions.Response\"\x95\x01\xf2\x86\x19\x90\x01\nM\n\x03GET\x12@/feature-store/feature-tables/get-feature-store-wide-permissions\x1a\x04\x08\x02\x10\x00\x10\x03*=Get Feature Store Wide Permission Level for the Current User.\x12\xad\x01\n\x0egetOnlineStore\x12\x1c.featurestore.GetOnlineStore\x1a%.featurestore.GetOnlineStore.Response\"V\xf2\x86\x19R\n;\n\x03GET\x12./feature-store/feature-tables/get-online-store\x1a\x04\x08\x02\x10\x00\x10\x03*\x11Get Online Store.\x12\xce\x01\n\x17getModelServingMetadata\x12%.featurestore.GetModelServingMetadata\x1a..featurestore.GetModelServingMetadata.Response\"\\\xf2\x86\x19X\n7\n\x04POST\x12)/feature-store/model-serving/get-metadata\x1a\x04\x08\x02\x10\x00\x10\x03*\x1bGet Model Serving Metadata.\x12\x8b\x02\n getBrickstoreOnlineTableMetadata\x12..featurestore.GetBrickstoreOnlineTableMetadata\x1a\x37.featurestore.GetBrickstoreOnlineTableMetadata.Response\"~\xf2\x86\x19z\nO\n\x04POST\x12\x41/feature-store/model-serving/get-brickstore-online-table-metadata\x1a\x04\x08\x02\x10\x00\x10\x03*%Get Brickstore online table metadata.\x12\xe2\x01\n\x16getOnlineFeatureTables\x12$.featurestore.GetOnlineFeatureTables\x1a-.featurestore.GetOnlineFeatureTables.Response\"s\xf2\x86\x19o\nD\n\x04POST\x12\x36/feature-store/model-serving/get-online-feature-tables\x1a\x04\x08\x02\x10\x00\x10\x02*%Get Brickstore online table metadata.\x12z\n\x07setTags\x12\x15.featurestore.SetTags\x1a\x1e.featurestore.SetTags.Response\"8\xf2\x86\x19\x34\n%\n\x04POST\x12\x17/feature-store/tags/set\x1a\x04\x08\x02\x10\x00\x10\x03*\tSet Tags.\x12y\n\x07getTags\x12\x15.featurestore.GetTags\x1a\x1e.featurestore.GetTags.Response\"7\xf2\x86\x19\x33\n$\n\x03GET\x12\x17/feature-store/tags/get\x1a\x04\x08\x02\x10\x00\x10\x03*\tGet Tags.\x12\x8b\x01\n\ndeleteTags\x12\x18.featurestore.DeleteTags\x1a!.featurestore.DeleteTags.Response\"@\xf2\x86\x19<\n*\n\x06\x44\x45LETE\x12\x1a/feature-store/tags/delete\x1a\x04\x08\x02\x10\x00\x10\x03*\x0c\x44\x65lete Tags.\x12\xb1\x01\n\x11\x63reateFeatureSpec\x12\x1f.featurestore.CreateFeatureSpec\x1a(.featurestore.CreateFeatureSpec.Response\"Q\xf2\x86\x19M\n0\n\x04POST\x12\"/feature-store/feature-spec/create\x1a\x04\x08\x02\x10\x00\x10\x03*\x17\x43reates a Feature Spec.B\x9c\x01\n%com.databricks.api.proto.featurestore\x90\x01\x01\xa0\x01\x01\xe2?l\x10\x01\x1a/com.databricks.featurestore.api.FeatureStoreRPC\x1a\x37\x63om.databricks.featurestore.api.FeatureStoreRoutableRPC')
+DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x15\x66\x65\x61ture_catalog.proto\x12\x0c\x66\x65\x61turestore\x1a\x15scalapb/scalapb.proto\x1a\x10\x64\x61tabricks.proto\x1a\x1b\x66\x65\x61ture_store_serving.proto\"\x96\x01\n\x0bHealthCheck\x12\x12\n\x03key\x18\x01 \x01(\t:\x05store\x12\x17\n\x05value\x18\x02 \x01(\t:\x08\x66\x65\x61tures\x1a-\n\x08Response\x12\x0e\n\x06result\x18\x01 \x01(\t\x12\x11\n\ttimestamp\x18\x02 \x01(\x03:+\xe2?(\n&com.databricks.rpc.RPC[$this.Response]\"\x9f\x03\n\x12\x43reateFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12+\n\x0cprimary_keys\x18\x02 \x03(\x0b\x32\x15.featurestore.KeySpec\x12-\n\x0epartition_keys\x18\x03 \x03(\x0b\x32\x15.featurestore.KeySpec\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x12\n\ntable_path\x18\x05 \x01(\t\x12-\n\x0etimestamp_keys\x18\x06 \x03(\x0b\x32\x15.featurestore.KeySpec\x12\x13\n\x0bis_imported\x18\x07 \x01(\x08\x12\x16\n\x07\x64ry_run\x18\x08 \x01(\x08:\x05\x66\x61lse\x12\'\n\x08\x66\x65\x61tures\x18\t \x03(\x0b\x32\x15.featurestore.KeySpec\x1a=\n\x08Response\x12\x31\n\rfeature_table\x18\x01 \x01(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xaa\x01\n\x12UpdateFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x13\n\x0b\x64\x65scription\x18\x02 \x01(\t\x1a=\n\x08Response\x12\x31\n\rfeature_table\x18\x01 \x01(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"z\n\x12\x44\x65leteFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x16\n\x07\x64ry_run\x18\x02 \x01(\x08:\x05\x66\x61lse\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"}\n\x0bUpgradeToUc\x12\x19\n\x11source_table_name\x18\x01 \x01(\t\x12\x19\n\x11target_table_name\x18\x02 \x01(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x8d\x01\n\x1cUpgradeWorkspaceFeatureTable\x12\x1c\n\x14workspace_table_name\x18\x01 \x01(\t\x12\x15\n\ruc_table_name\x18\x02 \x01(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xb4\x01\n\x0fGetFeatureTable\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12 \n\x11include_producers\x18\x02 \x01(\x08:\x05\x66\x61lse\x1a=\n\x08Response\x12\x31\n\rfeature_table\x18\x01 \x01(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xef\x05\n\x13SearchFeatureTables\x12\x0c\n\x04text\x18\x01 \x01(\t\x12\x17\n\x0bmax_results\x18\x02 \x01(\x03:\x02\x31\x30\x12\x12\n\npage_token\x18\x03 \x01(\t\x12\x30\n\rsearch_scopes\x18\x04 \x03(\x0e\x32\x19.featurestore.SearchScope\x12\x14\n\x0c\x63\x61talog_name\x18\x05 \x01(\t\x12\x1f\n\x04tags\x18\x06 \x03(\x0b\x32\x11.featurestore.Tag\x12\x1f\n\x10is_multi_catalog\x18\x07 \x01(\x08:\x05\x66\x61lse\x12\x15\n\rcatalog_names\x18\x08 \x03(\t\x12\x11\n\towner_ids\x18\t \x03(\t\x12?\n\nsort_order\x18\n \x01(\x0b\x32+.featurestore.SearchFeatureTables.SortOrder\x1a\x89\x01\n\tSortOrder\x12Q\n\x08\x63riteria\x18\x01 \x01(\x0e\x32\x38.featurestore.SearchFeatureTables.SortOrder.SortCriteria:\x05SCORE\")\n\x0cSortCriteria\x12\t\n\x05SCORE\x10\x01\x12\x0e\n\nPOPULARITY\x10\x02\x1a\xed\x01\n\x08Response\x12\x32\n\x0e\x66\x65\x61ture_tables\x18\x01 \x03(\x0b\x32\x1a.featurestore.FeatureTable\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t\x12Q\n\x0chighlighting\x18\x03 \x03(\x0b\x32;.featurestore.SearchFeatureTables.Response.HighlightingInfo\x1a\x41\n\x10HighlightingInfo\x12\n\n\x02id\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x03 \x01(\t:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xc3\x01\n\x16GetFeatureTableSchemas\x12<\n\x13\x66\x65\x61ture_identifiers\x18\x01 \x03(\x0b\x32\x1f.featurestore.FeatureIdentifier\x1a=\n\x08Response\x12\x31\n\x07schemas\x18\x01 \x03(\x0b\x32 .featurestore.FeatureTableSchema:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\">\n\x11\x46\x65\x61tureIdentifier\x12\x12\n\ntable_name\x18\x01 \x01(\t\x12\x15\n\rfeature_names\x18\x02 \x03(\t\"\xac\x01\n\x12\x46\x65\x61tureTableSchema\x12\x12\n\ntable_name\x18\x01 \x01(\t\x12\'\n\x08\x66\x65\x61tures\x18\x02 \x03(\x0b\x32\x15.featurestore.KeySpec\x12*\n\x0b\x65ntity_keys\x18\x03 \x03(\x0b\x32\x15.featurestore.KeySpec\x12-\n\x0etimestamp_keys\x18\x04 \x03(\x0b\x32\x15.featurestore.KeySpec\"\x91\x01\n\x14GetFeatureTablesById\x12\x0b\n\x03ids\x18\x01 \x03(\t\x1a>\n\x08Response\x12\x32\n\x0e\x66\x65\x61ture_tables\x18\x01 \x03(\x0b\x32\x1a.featurestore.FeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xe2\x01\n\x0e\x41\x64\x64\x44\x61taSources\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0e\n\x06tables\x18\x02 \x03(\t\x12\r\n\x05paths\x18\x03 \x03(\t\x12\x16\n\x0e\x63ustom_sources\x18\x04 \x03(\t\x12\x42\n\x10\x61ssociation_type\x18\x05 \x01(\x0e\x32\x1d.featurestore.AssociationType:\tAUTOMATIC\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"{\n\x11\x44\x65leteDataSources\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x0f\n\x07sources\x18\x02 \x03(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xb7\x05\n\x13PublishFeatureTable\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x1a\n\x0conline_table\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12.\n\x05\x63loud\x18\x03 \x01(\x0e\x32\x19.featurestorecommon.CloudB\x04\xf8\x86\x19\x01\x12\x37\n\nstore_type\x18\x04 \x01(\x0e\x32\x1d.featurestorecommon.StoreTypeB\x04\xf8\x86\x19\x01\x12\x0c\n\x04host\x18\x05 \x01(\t\x12\x0c\n\x04port\x18\x06 \x01(\x05\x12\x1a\n\x12read_secret_prefix\x18\x07 \x01(\t\x12\x1b\n\x13write_secret_prefix\x18\x08 \x01(\t\x12;\n\x0emysql_metadata\x18\t \x01(\x0b\x32!.featurestorecommon.MySqlMetadataH\x00\x12\x44\n\x13sql_server_metadata\x18\n \x01(\x0b\x32%.featurestorecommon.SqlServerMetadataH\x00\x12\x41\n\x11\x64ynamodb_metadata\x18\x0b \x01(\x0b\x32$.featurestorecommon.DynamoDbMetadataH\x00\x12\x41\n\x11\x63osmosdb_metadata\x18\r \x01(\x0b\x32$.featurestorecommon.CosmosDbMetadataH\x00\x12\x10\n\x08\x66\x65\x61tures\x18\x0c \x03(\t\x1aI\n\x08Response\x12=\n\x0conline_store\x18\x01 \x01(\x0b\x32\'.featurestorecommon.OnlineStoreDetailed:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x15\n\x13\x61\x64\x64itional_metadata\"\xbb\x02\n\x11\x44\x65leteOnlineStore\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x1a\n\x0conline_table\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12.\n\x05\x63loud\x18\x03 \x01(\x0e\x32\x19.featurestorecommon.CloudB\x04\xf8\x86\x19\x01\x12\x37\n\nstore_type\x18\x04 \x01(\x0e\x32\x1d.featurestorecommon.StoreTypeB\x04\xf8\x86\x19\x01\x12\x13\n\ttable_arn\x18\x05 \x01(\tH\x00\x12\x17\n\rcontainer_uri\x18\x06 \x01(\tH\x00\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x1c\n\x1a\x63loud_provider_resource_id\"\xd4\x01\n\x0bGetFeatures\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x18\n\x0bmax_results\x18\x02 \x01(\x03:\x03\x35\x30\x30\x12\x12\n\npage_token\x18\x03 \x01(\t\x1aL\n\x08Response\x12\'\n\x08\x66\x65\x61tures\x18\x01 \x03(\x0b\x32\x15.featurestore.Feature\x12\x17\n\x0fnext_page_token\x18\x02 \x01(\t:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x9f\x01\n\nGetFeature\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x12\n\x04name\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x1a\x32\n\x08Response\x12&\n\x07\x66\x65\x61ture\x18\x01 \x01(\x0b\x32\x15.featurestore.Feature:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x90\x01\n\x0e\x43reateFeatures\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\'\n\x08\x66\x65\x61tures\x18\x02 \x03(\x0b\x32\x15.featurestore.KeySpec\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xe5\x01\n\rUpdateFeature\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x12\n\x04name\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x11\n\tdata_type\x18\x03 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x19\n\x11\x64\x61ta_type_details\x18\x05 \x01(\t\x1a\x32\n\x08Response\x12&\n\x07\x66\x65\x61ture\x18\x01 \x01(\x0b\x32\x15.featurestore.Feature:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xac\x02\n\x0b\x41\x64\x64Producer\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12*\n\x08notebook\x18\x02 \x01(\x0b\x32\x16.featurestore.NotebookH\x00\x12$\n\x07job_run\x18\x03 \x01(\x0b\x32\x11.featurestore.JobH\x00\x12\x31\n\x0c\x64lt_pipeline\x18\x05 \x01(\x0b\x32\x19.featurestore.DltPipelineH\x00\x12\x35\n\x0fproducer_action\x18\x04 \x01(\x0e\x32\x1c.featurestore.ProducerAction\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\n\n\x08producer\"\x8a\x02\n\x0b\x41\x64\x64\x43onsumer\x12\x30\n\x08\x66\x65\x61tures\x18\x01 \x03(\x0b\x32\x1e.featurestore.ConsumedFeatures\x12*\n\x08notebook\x18\x02 \x01(\x0b\x32\x16.featurestore.NotebookH\x00\x12$\n\x07job_run\x18\x03 \x01(\x0b\x32\x11.featurestore.JobH\x00\x12\x31\n\x0c\x64lt_pipeline\x18\x04 \x01(\x0b\x32\x19.featurestore.DltPipelineH\x00\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\n\n\x08\x63onsumer\"\x90\x01\n\x0cGetConsumers\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x1a\x35\n\x08Response\x12)\n\tconsumers\x18\x01 \x03(\x0b\x32\x16.featurestore.Consumer:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x8b\x01\n\x1eGetFeatureStoreWidePermissions\x1a\x43\n\x08Response\x12\x37\n\x10permission_level\x18\x01 \x01(\x0e\x32\x1d.featurestore.PermissionLevel:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]\"\xf7\x02\n\x0eGetOnlineStore\x12\x1b\n\rfeature_table\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x1a\n\x0conline_table\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12.\n\x05\x63loud\x18\x03 \x01(\x0e\x32\x19.featurestorecommon.CloudB\x04\xf8\x86\x19\x01\x12\x37\n\nstore_type\x18\x04 \x01(\x0e\x32\x1d.featurestorecommon.StoreTypeB\x04\xf8\x86\x19\x01\x12\x13\n\ttable_arn\x18\x05 \x01(\tH\x00\x12\x17\n\rcontainer_uri\x18\x06 \x01(\tH\x00\x1aI\n\x08Response\x12=\n\x0conline_store\x18\x01 \x01(\x0b\x32\'.featurestorecommon.OnlineStoreDetailed:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x1c\n\x1a\x63loud_provider_resource_id\"\xde\x01\n\x17GetModelServingMetadata\x12\x42\n\x16\x66\x65\x61ture_table_features\x18\x01 \x03(\x0b\x32\".featurestore.FeatureTableFeatures\x1aQ\n\x08Response\x12\x45\n\x15online_feature_tables\x18\x01 \x03(\x0b\x32&.featurestorecommon.OnlineFeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xe7\x01\n GetBrickstoreOnlineTableMetadata\x12\x42\n\x16\x66\x65\x61ture_table_features\x18\x01 \x03(\x0b\x32\".featurestore.FeatureTableFeatures\x1aQ\n\x08Response\x12\x45\n\x15online_feature_tables\x18\x01 \x03(\x0b\x32&.featurestorecommon.OnlineFeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\x90\x02\n\x16GetOnlineFeatureTables\x12\x42\n\x16\x66\x65\x61ture_table_features\x18\x01 \x03(\x0b\x32\".featurestore.FeatureTableFeatures\x12\x1a\n\x12include_brickstore\x18\x02 \x01(\x08\x12\x15\n\ris_v1_serving\x18\x03 \x01(\x08\x1aQ\n\x08Response\x12\x45\n\x15online_feature_tables\x18\x01 \x03(\x0b\x32&.featurestorecommon.OnlineFeatureTable:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]\"\xa3\x01\n\x07SetTags\x12\x1a\n\x10\x66\x65\x61ture_table_id\x18\x01 \x01(\tH\x00\x12\x14\n\nfeature_id\x18\x02 \x01(\tH\x00\x12\x1f\n\x04tags\x18\x0b \x03(\x0b\x32\x11.featurestore.Tag\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x0b\n\tentity_id\"\xa3\x01\n\x07GetTags\x12\x1a\n\x10\x66\x65\x61ture_table_id\x18\x01 \x01(\tH\x00\x12\x14\n\nfeature_id\x18\x02 \x01(\tH\x00\x1a+\n\x08Response\x12\x1f\n\x04tags\x18\x01 \x03(\x0b\x32\x11.featurestore.Tag:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x0b\n\tentity_id\"\x93\x01\n\nDeleteTags\x12\x1a\n\x10\x66\x65\x61ture_table_id\x18\x01 \x01(\tH\x00\x12\x14\n\nfeature_id\x18\x02 \x01(\tH\x00\x12\x0c\n\x04keys\x18\x0b \x03(\t\x1a\n\n\x08Response:,\xe2?)\n\'FeatureStoreRoutableRPC[$this.Response]B\x0b\n\tentity_id\"Q\n\x07KeySpec\x12\x12\n\x04name\x18\x01 \x01(\tB\x04\xf8\x86\x19\x01\x12\x17\n\tdata_type\x18\x02 \x01(\tB\x04\xf8\x86\x19\x01\x12\x19\n\x11\x64\x61ta_type_details\x18\x03 \x01(\t\"\x84\x05\n\x0c\x46\x65\x61tureTable\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x02 \x01(\x03\x12\x1e\n\x16last_updated_timestamp\x18\x03 \x01(\x03\x12\x12\n\ncreator_id\x18\x04 \x01(\t\x12\x13\n\x0b\x64\x65scription\x18\x05 \x01(\t\x12\x14\n\x0cprimary_keys\x18\x06 \x03(\t\x12\x16\n\x0epartition_keys\x18\x07 \x03(\t\x12\x10\n\x08\x66\x65\x61tures\x18\x08 \x03(\t\x12.\n\x0c\x64\x61ta_sources\x18\t \x03(\x0b\x32\x18.featurestore.DataSource\x12\x36\n\ronline_stores\x18\n \x03(\x0b\x32\x1f.featurestorecommon.OnlineStore\x12\x32\n\x12notebook_producers\x18\x0b \x03(\x0b\x32\x16.featurestore.Notebook\x12(\n\rjob_producers\x18\x0c \x03(\x0b\x32\x11.featurestore.Job\x12\x39\n\x16\x64lt_pipeline_producers\x18\x12 \x03(\x0b\x32\x19.featurestore.DltPipeline\x12\x1b\n\x13last_update_user_id\x18\r \x01(\t\x12\n\n\x02id\x18\x0e \x01(\t\x12\x37\n\x10permission_level\x18\x0f \x01(\x0e\x32\x1d.featurestore.PermissionLevel\x12\x16\n\x0etimestamp_keys\x18\x10 \x03(\t\x12\x13\n\x0bis_imported\x18\x11 \x01(\x08\x12\x1f\n\x04tags\x18\x13 \x03(\x0b\x32\x11.featurestore.Tag\x12\x10\n\x08owner_id\x18\x14 \x01(\t\"\x80\x02\n\x07\x46\x65\x61ture\x12\r\n\x05table\x18\x01 \x01(\t\x12\x0c\n\x04name\x18\x02 \x01(\t\x12/\n\tdata_type\x18\x03 \x01(\x0e\x32\x1c.featurestorecommon.DataType\x12\x13\n\x0b\x64\x65scription\x18\x04 \x01(\t\x12\x19\n\x11\x64\x61ta_type_details\x18\x05 \x01(\t\x12\n\n\x02id\x18\x06 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x07 \x01(\x03\x12\x12\n\ncreator_id\x18\x08 \x01(\t\x12\x1e\n\x16last_updated_timestamp\x18\t \x01(\x03\x12\x1b\n\x13last_update_user_id\x18\n \x01(\t\"@\n\nDataSource\x12\r\n\x05table\x18\x01 \x01(\t\x12\x0c\n\x04path\x18\x02 \x01(\t\x12\x15\n\rcustom_source\x18\x03 \x01(\t\"0\n\x10\x43onsumedFeatures\x12\r\n\x05table\x18\x01 \x01(\t\x12\r\n\x05names\x18\x02 \x03(\t\"\x9a\x02\n\x08Notebook\x12\x13\n\x0bnotebook_id\x18\x01 \x01(\x03\x12\x13\n\x0brevision_id\x18\x02 \x01(\x03\x12\x1a\n\x0eworkspace_path\x18\x03 \x01(\tB\x02\x18\x01\x12\x1a\n\x12\x63reation_timestamp\x18\x04 \x01(\x03\x12\x12\n\ncreator_id\x18\x05 \x01(\t\x12\x1d\n\x15notebook_workspace_id\x18\x06 \x01(\x03\x12\"\n\x1a\x66\x65\x61ture_table_workspace_id\x18\x07 \x01(\x03\x12\x1e\n\x16notebook_workspace_url\x18\x08 \x01(\t\x12\x35\n\x0fproducer_action\x18\t \x01(\x0e\x32\x1c.featurestore.ProducerAction\"\xfb\x01\n\x03Job\x12\x0e\n\x06job_id\x18\x01 \x01(\x03\x12\x0e\n\x06run_id\x18\x02 \x01(\x03\x12\x14\n\x08job_name\x18\x03 \x01(\tB\x02\x18\x01\x12\x1a\n\x12\x63reation_timestamp\x18\x04 \x01(\x03\x12\x12\n\ncreator_id\x18\x05 \x01(\t\x12\x18\n\x10job_workspace_id\x18\x06 \x01(\x03\x12\"\n\x1a\x66\x65\x61ture_table_workspace_id\x18\x07 \x01(\x03\x12\x19\n\x11job_workspace_url\x18\x08 \x01(\t\x12\x35\n\x0fproducer_action\x18\t \x01(\x0e\x32\x1c.featurestore.ProducerAction\"\x9c\x01\n\x0b\x44ltPipeline\x12\x13\n\x0bpipeline_id\x18\x01 \x01(\t\x12\x11\n\tupdate_id\x18\x02 \x01(\t\x12\x1a\n\x12\x63reation_timestamp\x18\x03 \x01(\x03\x12\x12\n\ncreator_id\x18\x04 \x01(\t\x12\x35\n\x0fproducer_action\x18\x05 \x01(\x0e\x32\x1c.featurestore.ProducerAction\"\xab\x01\n\x08\x43onsumer\x12\x10\n\x08\x66\x65\x61tures\x18\x01 \x03(\t\x12*\n\x08notebook\x18\x02 \x01(\x0b\x32\x16.featurestore.NotebookH\x00\x12$\n\x07job_run\x18\x03 \x01(\x0b\x32\x11.featurestore.JobH\x00\x12\x31\n\x0c\x64lt_pipeline\x18\x04 \x01(\x0b\x32\x19.featurestore.DltPipelineH\x00\x42\x08\n\x06\x65ntity\"D\n\x14\x46\x65\x61tureTableFeatures\x12\x1a\n\x12\x66\x65\x61ture_table_name\x18\x01 \x01(\t\x12\x10\n\x08\x66\x65\x61tures\x18\x02 \x03(\t\"!\n\x03Tag\x12\x0b\n\x03key\x18\x01 \x01(\t\x12\r\n\x05value\x18\x02 \x01(\t\"\xf1\x01\n\x11\x43reateFeatureSpec\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x1f\n\x11\x66\x65\x61ture_spec_yaml\x18\x02 \x01(\tB\x04\xf0\x86\x19\x03\x12(\n\x08\x66\x65\x61tures\x18\x03 \x03(\x0b\x32\x16.featurestore.Features\x12\x17\n\x0f\x65xclude_columns\x18\x04 \x03(\t\x1a\x44\n\x08Response\x12\x38\n\x11\x66\x65\x61ture_spec_info\x18\x01 \x01(\x0b\x32\x1d.featurestore.FeatureSpecInfo:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]\"b\n\x11UpdateFeatureSpec\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\r\n\x05owner\x18\x02 \x01(\t\x1a\n\n\x08Response:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]\"S\n\x11\x44\x65leteFeatureSpec\x12\x0c\n\x04name\x18\x01 \x01(\t\x1a\n\n\x08Response:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]\"O\n\x0f\x46\x65\x61tureSpecInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07\x63reator\x18\x02 \x01(\t\x12\x1d\n\x15\x63reation_timestamp_ms\x18\x03 \x01(\x03\"\x87\x01\n\x08\x46\x65\x61tures\x12\x35\n\x0e\x66\x65\x61ture_lookup\x18\x01 \x01(\x0b\x32\x1b.featurestore.FeatureLookupH\x00\x12\x39\n\x10\x66\x65\x61ture_function\x18\x02 \x01(\x0b\x32\x1d.featurestore.FeatureFunctionH\x00\x42\t\n\x07\x66\x65\x61ture\"\xc9\x01\n\rFeatureLookup\x12\x12\n\ntable_name\x18\x01 \x01(\t\x12\x13\n\x0blookup_keys\x18\x02 \x03(\t\x12\x15\n\rfeature_names\x18\x03 \x03(\t\x12\x32\n\x0erename_outputs\x18\x04 \x03(\x0b\x32\x1a.featurestore.RenameOutput\x12\x1d\n\x15timestamp_lookup_keys\x18\x05 \x03(\t\x12%\n\x17lookback_window_seconds\x18\x06 \x01(\x01\x42\x04\xf0\x86\x19\x03\"l\n\x0f\x46\x65\x61tureFunction\x12\x10\n\x08udf_name\x18\x01 \x01(\t\x12\x32\n\x0einput_bindings\x18\x02 \x03(\x0b\x32\x1a.featurestore.InputBinding\x12\x13\n\x0boutput_name\x18\x03 \x01(\t\"9\n\x0cRenameOutput\x12\x14\n\x0c\x66\x65\x61ture_name\x18\x01 \x01(\t\x12\x13\n\x0boutput_name\x18\x02 \x03(\t\"B\n\x0cInputBinding\x12\x16\n\x0eparameter_name\x18\x01 \x01(\t\x12\x1a\n\x12\x62ound_feature_name\x18\x02 \x01(\t\"\xdb\x01\n\x17GenerateFeatureSpecYaml\x12(\n\x08\x66\x65\x61tures\x18\x01 \x03(\x0b\x32\x16.featurestore.Features\x12\x17\n\x0f\x65xclude_columns\x18\x02 \x03(\t\x12\x15\n\rinput_columns\x18\x03 \x03(\t\x12\x19\n\x11\x66\x65\x61ture_spec_yaml\x18\x04 \x01(\t\x1a%\n\x08Response\x12\x19\n\x11\x66\x65\x61ture_spec_yaml\x18\x01 \x01(\t:$\xe2?!\n\x1f\x46\x65\x61tureStoreRPC[$this.Response]*r\n\x0fPermissionLevel\x12\x0e\n\nCAN_MANAGE\x10\x00\x12\x15\n\x11\x43\x41N_EDIT_METADATA\x10\x01\x12\x15\n\x11\x43\x41N_VIEW_METADATA\x10\x02\x12\x0e\n\nCAN_CREATE\x10\x03\x12\x11\n\rMANAGED_BY_UC\x10\x04*5\n\x0eProducerAction\x12\n\n\x06\x43REATE\x10\x00\x12\t\n\x05WRITE\x10\x01\x12\x0c\n\x08REGISTER\x10\x02*,\n\x0f\x41ssociationType\x12\r\n\tAUTOMATIC\x10\x00\x12\n\n\x06MANUAL\x10\x01*k\n\x0bSearchScope\x12\x12\n\x0e\x46\x45\x41TURE_TABLES\x10\x01\x12\x0c\n\x08\x46\x45\x41TURES\x10\x02\x12\x10\n\x0c\x44\x41TA_SOURCES\x10\x03\x12\x16\n\x12\x46\x45\x41TURE_TABLE_TAGS\x10\x04\x12\x10\n\x0c\x46\x45\x41TURE_TAGS\x10\x05\x32\xa2\x30\n\x13\x46\x65\x61tureStoreService\x12\xab\x01\n\x0bhealthCheck\x12\x19.featurestore.HealthCheck\x1a\".featurestore.HealthCheck.Response\"]\xf2\x86\x19Y\n(\n\x03GET\x12\x1b/feature-store/health-check\x1a\x04\x08\x02\x10\x00\x10\x03*+Health check for Feature Store service pod.\x12\xb4\x01\n\x12\x63reateFeatureTable\x12 .featurestore.CreateFeatureTable\x1a).featurestore.CreateFeatureTable.Response\"Q\xf2\x86\x19M\n2\n\x04POST\x12$/feature-store/feature-tables/create\x1a\x04\x08\x02\x10\x00\x10\x03*\x15\x43reate Feature Table.\x12\xb5\x01\n\x12updateFeatureTable\x12 .featurestore.UpdateFeatureTable\x1a).featurestore.UpdateFeatureTable.Response\"R\xf2\x86\x19N\n3\n\x05PATCH\x12$/feature-store/feature-tables/update\x1a\x04\x08\x02\x10\x00\x10\x03*\x15Update Feature Table.\x12\xb6\x01\n\x12\x64\x65leteFeatureTable\x12 .featurestore.DeleteFeatureTable\x1a).featurestore.DeleteFeatureTable.Response\"S\xf2\x86\x19O\n4\n\x06\x44\x45LETE\x12$/feature-store/feature-tables/delete\x1a\x04\x08\x02\x10\x00\x10\x03*\x15\x44\x65lete Feature Table.\x12\xae\x01\n\x0bupgradeToUc\x12\x19.featurestore.UpgradeToUc\x1a\".featurestore.UpgradeToUc.Response\"`\xf2\x86\x19\\\n9\n\x04POST\x12+/feature-store/feature-tables/upgrade-to-uc\x1a\x04\x08\x02\x10\x00\x10\x03*\x1dUpgrade workspace table to UC\x12\xf4\x01\n\x1cupgradeWorkspaceFeatureTable\x12*.featurestore.UpgradeWorkspaceFeatureTable\x1a\x33.featurestore.UpgradeWorkspaceFeatureTable.Response\"s\xf2\x86\x19o\nI\n\x04POST\x12;/feature-store/feature-tables/upgrade-workspace-table-to-uc\x1a\x04\x08\x02\x10\x00\x10\x03* Upgrade Workspace Feature Table.\x12\xa4\x01\n\x0fgetFeatureTable\x12\x1d.featurestore.GetFeatureTable\x1a&.featurestore.GetFeatureTable.Response\"J\xf2\x86\x19\x46\n.\n\x03GET\x12!/feature-store/feature-tables/get\x1a\x04\x08\x02\x10\x00\x10\x03*\x12Get Feature Table.\x12\xed\x01\n\x13searchFeatureTables\x12!.featurestore.SearchFeatureTables\x1a*.featurestore.SearchFeatureTables.Response\"\x86\x01\xf2\x86\x19\x81\x01\n2\n\x04POST\x12$/feature-store/feature-tables/search\x1a\x04\x08\x02\x10\x00\n1\n\x03GET\x12$/feature-store/feature-tables/search\x1a\x04\x08\x02\x10\x00\x10\x03*\x16Search Feature Tables.\x12\xc2\x01\n\x14getFeatureTablesById\x12\".featurestore.GetFeatureTablesById\x1a+.featurestore.GetFeatureTablesById.Response\"Y\xf2\x86\x19U\n6\n\x04POST\x12(/feature-store/feature-tables/get-by-ids\x1a\x04\x08\x02\x10\x00\x10\x03*\x19Get Feature Tables by ID.\x12\xd2\x01\n\x16getFeatureTableSchemas\x12$.featurestore.GetFeatureTableSchemas\x1a-.featurestore.GetFeatureTableSchemas.Response\"c\xf2\x86\x19_\n7\n\x04POST\x12)/feature-store/feature-tables/get-schemas\x1a\x04\x08\x02\x10\x00\x10\x03*\"Get the schemas for feature tables\x12\xc0\x01\n\x0e\x61\x64\x64\x44\x61taSources\x12\x1c.featurestore.AddDataSources\x1a%.featurestore.AddDataSources.Response\"i\xf2\x86\x19\x65\n<\n\x04POST\x12./feature-store/feature-tables/add-data-sources\x1a\x04\x08\x02\x10\x00\x10\x03*#Add Data Sources for Feature Table.\x12\xcf\x01\n\x11\x64\x65leteDataSources\x12\x1f.featurestore.DeleteDataSources\x1a(.featurestore.DeleteDataSources.Response\"o\xf2\x86\x19k\n?\n\x04POST\x12\x31/feature-store/feature-tables/delete-data-sources\x1a\x04\x08\x02\x10\x00\x10\x03*&Delete Data Sources for Feature Table.\x12\xb9\x01\n\x13publishFeatureTable\x12!.featurestore.PublishFeatureTable\x1a*.featurestore.PublishFeatureTable.Response\"S\xf2\x86\x19O\n3\n\x04POST\x12%/feature-store/feature-tables/publish\x1a\x04\x08\x02\x10\x00\x10\x03*\x16Publish Feature Table.\x12\xbf\x01\n\x11\x64\x65leteOnlineStore\x12\x1f.featurestore.DeleteOnlineStore\x1a(.featurestore.DeleteOnlineStore.Response\"_\xf2\x86\x19[\nA\n\x06\x44\x45LETE\x12\x31/feature-store/feature-tables/delete-online-store\x1a\x04\x08\x02\x10\x00\x10\x03*\x14\x44\x65lete Online Store.\x12\x8d\x01\n\x0bgetFeatures\x12\x19.featurestore.GetFeatures\x1a\".featurestore.GetFeatures.Response\"?\xf2\x86\x19;\n(\n\x03GET\x12\x1b/feature-store/features/get\x1a\x04\x08\x02\x10\x00\x10\x03*\rGet Features.\x12\x91\x01\n\ngetFeature\x12\x18.featurestore.GetFeature\x1a!.featurestore.GetFeature.Response\"F\xf2\x86\x19\x42\n0\n\x03GET\x12#/feature-store/features/get-by-name\x1a\x04\x08\x02\x10\x00\x10\x03*\x0cGet Feature.\x12\x9d\x01\n\x0e\x63reateFeatures\x12\x1c.featurestore.CreateFeatures\x1a%.featurestore.CreateFeatures.Response\"F\xf2\x86\x19\x42\n,\n\x04POST\x12\x1e/feature-store/features/create\x1a\x04\x08\x02\x10\x00\x10\x03*\x10\x43reate Features.\x12\x9a\x01\n\rupdateFeature\x12\x1b.featurestore.UpdateFeature\x1a$.featurestore.UpdateFeature.Response\"F\xf2\x86\x19\x42\n-\n\x05PATCH\x12\x1e/feature-store/features/update\x1a\x04\x08\x02\x10\x00\x10\x03*\x0fUpdate Feature.\x12\x9d\x01\n\x0b\x61\x64\x64Producer\x12\x19.featurestore.AddProducer\x1a\".featurestore.AddProducer.Response\"O\xf2\x86\x19K\n8\n\x04POST\x12*/feature-store/feature-tables/add-producer\x1a\x04\x08\x02\x10\x00\x10\x03*\rAdd Producer.\x12\x97\x01\n\x0b\x61\x64\x64\x43onsumer\x12\x19.featurestore.AddConsumer\x1a\".featurestore.AddConsumer.Response\"I\xf2\x86\x19\x45\n2\n\x04POST\x12$/feature-store/features/add-consumer\x1a\x04\x08\x02\x10\x00\x10\x03*\rAdd Consumer.\x12\xa1\x01\n\x0cgetConsumers\x12\x1a.featurestore.GetConsumers\x1a#.featurestore.GetConsumers.Response\"P\xf2\x86\x19L\n8\n\x03GET\x12+/feature-store/feature-tables/get-consumers\x1a\x04\x08\x02\x10\x00\x10\x03*\x0eGet Consumers.\x12\x9d\x02\n\x1egetFeatureStoreWidePermissions\x12,.featurestore.GetFeatureStoreWidePermissions\x1a\x35.featurestore.GetFeatureStoreWidePermissions.Response\"\x95\x01\xf2\x86\x19\x90\x01\nM\n\x03GET\x12@/feature-store/feature-tables/get-feature-store-wide-permissions\x1a\x04\x08\x02\x10\x00\x10\x03*=Get Feature Store Wide Permission Level for the Current User.\x12\xad\x01\n\x0egetOnlineStore\x12\x1c.featurestore.GetOnlineStore\x1a%.featurestore.GetOnlineStore.Response\"V\xf2\x86\x19R\n;\n\x03GET\x12./feature-store/feature-tables/get-online-store\x1a\x04\x08\x02\x10\x00\x10\x03*\x11Get Online Store.\x12\xce\x01\n\x17getModelServingMetadata\x12%.featurestore.GetModelServingMetadata\x1a..featurestore.GetModelServingMetadata.Response\"\\\xf2\x86\x19X\n7\n\x04POST\x12)/feature-store/model-serving/get-metadata\x1a\x04\x08\x02\x10\x00\x10\x03*\x1bGet Model Serving Metadata.\x12\x8b\x02\n getBrickstoreOnlineTableMetadata\x12..featurestore.GetBrickstoreOnlineTableMetadata\x1a\x37.featurestore.GetBrickstoreOnlineTableMetadata.Response\"~\xf2\x86\x19z\nO\n\x04POST\x12\x41/feature-store/model-serving/get-brickstore-online-table-metadata\x1a\x04\x08\x02\x10\x00\x10\x03*%Get Brickstore online table metadata.\x12\xe2\x01\n\x16getOnlineFeatureTables\x12$.featurestore.GetOnlineFeatureTables\x1a-.featurestore.GetOnlineFeatureTables.Response\"s\xf2\x86\x19o\nD\n\x04POST\x12\x36/feature-store/model-serving/get-online-feature-tables\x1a\x04\x08\x02\x10\x00\x10\x02*%Get Brickstore online table metadata.\x12z\n\x07setTags\x12\x15.featurestore.SetTags\x1a\x1e.featurestore.SetTags.Response\"8\xf2\x86\x19\x34\n%\n\x04POST\x12\x17/feature-store/tags/set\x1a\x04\x08\x02\x10\x00\x10\x03*\tSet Tags.\x12y\n\x07getTags\x12\x15.featurestore.GetTags\x1a\x1e.featurestore.GetTags.Response\"7\xf2\x86\x19\x33\n$\n\x03GET\x12\x17/feature-store/tags/get\x1a\x04\x08\x02\x10\x00\x10\x03*\tGet Tags.\x12\x8b\x01\n\ndeleteTags\x12\x18.featurestore.DeleteTags\x1a!.featurestore.DeleteTags.Response\"@\xf2\x86\x19<\n*\n\x06\x44\x45LETE\x12\x1a/feature-store/tags/delete\x1a\x04\x08\x02\x10\x00\x10\x03*\x0c\x44\x65lete Tags.\x12\xb1\x01\n\x11\x63reateFeatureSpec\x12\x1f.featurestore.CreateFeatureSpec\x1a(.featurestore.CreateFeatureSpec.Response\"Q\xf2\x86\x19M\n0\n\x04POST\x12\"/feature-store/feature-spec/create\x1a\x04\x08\x02\x10\x00\x10\x03*\x17\x43reates a Feature Spec.\x12\xb2\x01\n\x11updateFeatureSpec\x12\x1f.featurestore.UpdateFeatureSpec\x1a(.featurestore.UpdateFeatureSpec.Response\"R\xf2\x86\x19N\n1\n\x05PATCH\x12\"/feature-store/feature-spec/update\x1a\x04\x08\x02\x10\x00\x10\x03*\x17Updates a Feature Spec.\x12\xb3\x01\n\x11\x64\x65leteFeatureSpec\x12\x1f.featurestore.DeleteFeatureSpec\x1a(.featurestore.DeleteFeatureSpec.Response\"S\xf2\x86\x19O\n2\n\x06\x44\x45LETE\x12\"/feature-store/feature-spec/delete\x1a\x04\x08\x02\x10\x00\x10\x03*\x17\x44\x65letes a Feature Spec.\x12\xd1\x01\n\x17generateFeatureSpecYaml\x12%.featurestore.GenerateFeatureSpecYaml\x1a..featurestore.GenerateFeatureSpecYaml.Response\"_\xf2\x86\x19[\n7\n\x04POST\x12)/feature-store/feature-spec/generate-yaml\x1a\x04\x08\x02\x10\x00\x10\x03*\x1eGenerates a Feature Spec YAML.B\x9c\x01\n%com.databricks.api.proto.featurestore\x90\x01\x01\xa0\x01\x01\xe2?l\x10\x01\x1a/com.databricks.featurestore.api.FeatureStoreRPC\x1a\x37\x63om.databricks.featurestore.api.FeatureStoreRoutableRPC')
 
 _PERMISSIONLEVEL = DESCRIPTOR.enum_types_by_name['PermissionLevel']
 PermissionLevel = enum_type_wrapper.EnumTypeWrapper(_PERMISSIONLEVEL)
 _PRODUCERACTION = DESCRIPTOR.enum_types_by_name['ProducerAction']
 ProducerAction = enum_type_wrapper.EnumTypeWrapper(_PRODUCERACTION)
 _ASSOCIATIONTYPE = DESCRIPTOR.enum_types_by_name['AssociationType']
 AssociationType = enum_type_wrapper.EnumTypeWrapper(_ASSOCIATIONTYPE)
@@ -118,15 +118,26 @@
 _JOB = DESCRIPTOR.message_types_by_name['Job']
 _DLTPIPELINE = DESCRIPTOR.message_types_by_name['DltPipeline']
 _CONSUMER = DESCRIPTOR.message_types_by_name['Consumer']
 _FEATURETABLEFEATURES = DESCRIPTOR.message_types_by_name['FeatureTableFeatures']
 _TAG = DESCRIPTOR.message_types_by_name['Tag']
 _CREATEFEATURESPEC = DESCRIPTOR.message_types_by_name['CreateFeatureSpec']
 _CREATEFEATURESPEC_RESPONSE = _CREATEFEATURESPEC.nested_types_by_name['Response']
+_UPDATEFEATURESPEC = DESCRIPTOR.message_types_by_name['UpdateFeatureSpec']
+_UPDATEFEATURESPEC_RESPONSE = _UPDATEFEATURESPEC.nested_types_by_name['Response']
+_DELETEFEATURESPEC = DESCRIPTOR.message_types_by_name['DeleteFeatureSpec']
+_DELETEFEATURESPEC_RESPONSE = _DELETEFEATURESPEC.nested_types_by_name['Response']
 _FEATURESPECINFO = DESCRIPTOR.message_types_by_name['FeatureSpecInfo']
+_FEATURES = DESCRIPTOR.message_types_by_name['Features']
+_FEATURELOOKUP = DESCRIPTOR.message_types_by_name['FeatureLookup']
+_FEATUREFUNCTION = DESCRIPTOR.message_types_by_name['FeatureFunction']
+_RENAMEOUTPUT = DESCRIPTOR.message_types_by_name['RenameOutput']
+_INPUTBINDING = DESCRIPTOR.message_types_by_name['InputBinding']
+_GENERATEFEATURESPECYAML = DESCRIPTOR.message_types_by_name['GenerateFeatureSpecYaml']
+_GENERATEFEATURESPECYAML_RESPONSE = _GENERATEFEATURESPECYAML.nested_types_by_name['Response']
 _SEARCHFEATURETABLES_SORTORDER_SORTCRITERIA = _SEARCHFEATURETABLES_SORTORDER.enum_types_by_name['SortCriteria']
 HealthCheck = _reflection.GeneratedProtocolMessageType('HealthCheck', (_message.Message,), {
 
   'Response' : _reflection.GeneratedProtocolMessageType('Response', (_message.Message,), {
     'DESCRIPTOR' : _HEALTHCHECK_RESPONSE,
     '__module__' : 'feature_catalog_pb2'
     # @@protoc_insertion_point(class_scope:featurestore.HealthCheck.Response)
@@ -677,21 +688,101 @@
   'DESCRIPTOR' : _CREATEFEATURESPEC,
   '__module__' : 'feature_catalog_pb2'
   # @@protoc_insertion_point(class_scope:featurestore.CreateFeatureSpec)
   })
 _sym_db.RegisterMessage(CreateFeatureSpec)
 _sym_db.RegisterMessage(CreateFeatureSpec.Response)
 
+UpdateFeatureSpec = _reflection.GeneratedProtocolMessageType('UpdateFeatureSpec', (_message.Message,), {
+
+  'Response' : _reflection.GeneratedProtocolMessageType('Response', (_message.Message,), {
+    'DESCRIPTOR' : _UPDATEFEATURESPEC_RESPONSE,
+    '__module__' : 'feature_catalog_pb2'
+    # @@protoc_insertion_point(class_scope:featurestore.UpdateFeatureSpec.Response)
+    })
+  ,
+  'DESCRIPTOR' : _UPDATEFEATURESPEC,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.UpdateFeatureSpec)
+  })
+_sym_db.RegisterMessage(UpdateFeatureSpec)
+_sym_db.RegisterMessage(UpdateFeatureSpec.Response)
+
+DeleteFeatureSpec = _reflection.GeneratedProtocolMessageType('DeleteFeatureSpec', (_message.Message,), {
+
+  'Response' : _reflection.GeneratedProtocolMessageType('Response', (_message.Message,), {
+    'DESCRIPTOR' : _DELETEFEATURESPEC_RESPONSE,
+    '__module__' : 'feature_catalog_pb2'
+    # @@protoc_insertion_point(class_scope:featurestore.DeleteFeatureSpec.Response)
+    })
+  ,
+  'DESCRIPTOR' : _DELETEFEATURESPEC,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.DeleteFeatureSpec)
+  })
+_sym_db.RegisterMessage(DeleteFeatureSpec)
+_sym_db.RegisterMessage(DeleteFeatureSpec.Response)
+
 FeatureSpecInfo = _reflection.GeneratedProtocolMessageType('FeatureSpecInfo', (_message.Message,), {
   'DESCRIPTOR' : _FEATURESPECINFO,
   '__module__' : 'feature_catalog_pb2'
   # @@protoc_insertion_point(class_scope:featurestore.FeatureSpecInfo)
   })
 _sym_db.RegisterMessage(FeatureSpecInfo)
 
+Features = _reflection.GeneratedProtocolMessageType('Features', (_message.Message,), {
+  'DESCRIPTOR' : _FEATURES,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.Features)
+  })
+_sym_db.RegisterMessage(Features)
+
+FeatureLookup = _reflection.GeneratedProtocolMessageType('FeatureLookup', (_message.Message,), {
+  'DESCRIPTOR' : _FEATURELOOKUP,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.FeatureLookup)
+  })
+_sym_db.RegisterMessage(FeatureLookup)
+
+FeatureFunction = _reflection.GeneratedProtocolMessageType('FeatureFunction', (_message.Message,), {
+  'DESCRIPTOR' : _FEATUREFUNCTION,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.FeatureFunction)
+  })
+_sym_db.RegisterMessage(FeatureFunction)
+
+RenameOutput = _reflection.GeneratedProtocolMessageType('RenameOutput', (_message.Message,), {
+  'DESCRIPTOR' : _RENAMEOUTPUT,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.RenameOutput)
+  })
+_sym_db.RegisterMessage(RenameOutput)
+
+InputBinding = _reflection.GeneratedProtocolMessageType('InputBinding', (_message.Message,), {
+  'DESCRIPTOR' : _INPUTBINDING,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.InputBinding)
+  })
+_sym_db.RegisterMessage(InputBinding)
+
+GenerateFeatureSpecYaml = _reflection.GeneratedProtocolMessageType('GenerateFeatureSpecYaml', (_message.Message,), {
+
+  'Response' : _reflection.GeneratedProtocolMessageType('Response', (_message.Message,), {
+    'DESCRIPTOR' : _GENERATEFEATURESPECYAML_RESPONSE,
+    '__module__' : 'feature_catalog_pb2'
+    # @@protoc_insertion_point(class_scope:featurestore.GenerateFeatureSpecYaml.Response)
+    })
+  ,
+  'DESCRIPTOR' : _GENERATEFEATURESPECYAML,
+  '__module__' : 'feature_catalog_pb2'
+  # @@protoc_insertion_point(class_scope:featurestore.GenerateFeatureSpecYaml)
+  })
+_sym_db.RegisterMessage(GenerateFeatureSpecYaml)
+_sym_db.RegisterMessage(GenerateFeatureSpecYaml.Response)
+
 _FEATURESTORESERVICE = DESCRIPTOR.services_by_name['FeatureStoreService']
 if _descriptor._USE_C_DESCRIPTORS == False:
 
   DESCRIPTOR._options = None
   DESCRIPTOR._serialized_options = b'\n%com.databricks.api.proto.featurestore\220\001\001\240\001\001\342?l\020\001\032/com.databricks.featurestore.api.FeatureStoreRPC\0327com.databricks.featurestore.api.FeatureStoreRoutableRPC'
   _HEALTHCHECK._options = None
   _HEALTHCHECK._serialized_options = b'\342?(\n&com.databricks.rpc.RPC[$this.Response]'
@@ -807,16 +898,26 @@
   _KEYSPEC.fields_by_name['name']._serialized_options = b'\370\206\031\001'
   _KEYSPEC.fields_by_name['data_type']._options = None
   _KEYSPEC.fields_by_name['data_type']._serialized_options = b'\370\206\031\001'
   _NOTEBOOK.fields_by_name['workspace_path']._options = None
   _NOTEBOOK.fields_by_name['workspace_path']._serialized_options = b'\030\001'
   _JOB.fields_by_name['job_name']._options = None
   _JOB.fields_by_name['job_name']._serialized_options = b'\030\001'
+  _CREATEFEATURESPEC.fields_by_name['feature_spec_yaml']._options = None
+  _CREATEFEATURESPEC.fields_by_name['feature_spec_yaml']._serialized_options = b'\360\206\031\003'
   _CREATEFEATURESPEC._options = None
   _CREATEFEATURESPEC._serialized_options = b'\342?!\n\037FeatureStoreRPC[$this.Response]'
+  _UPDATEFEATURESPEC._options = None
+  _UPDATEFEATURESPEC._serialized_options = b'\342?!\n\037FeatureStoreRPC[$this.Response]'
+  _DELETEFEATURESPEC._options = None
+  _DELETEFEATURESPEC._serialized_options = b'\342?!\n\037FeatureStoreRPC[$this.Response]'
+  _FEATURELOOKUP.fields_by_name['lookback_window_seconds']._options = None
+  _FEATURELOOKUP.fields_by_name['lookback_window_seconds']._serialized_options = b'\360\206\031\003'
+  _GENERATEFEATURESPECYAML._options = None
+  _GENERATEFEATURESPECYAML._serialized_options = b'\342?!\n\037FeatureStoreRPC[$this.Response]'
   _FEATURESTORESERVICE.methods_by_name['healthCheck']._options = None
   _FEATURESTORESERVICE.methods_by_name['healthCheck']._serialized_options = b'\362\206\031Y\n(\n\003GET\022\033/feature-store/health-check\032\004\010\002\020\000\020\003*+Health check for Feature Store service pod.'
   _FEATURESTORESERVICE.methods_by_name['createFeatureTable']._options = None
   _FEATURESTORESERVICE.methods_by_name['createFeatureTable']._serialized_options = b'\362\206\031M\n2\n\004POST\022$/feature-store/feature-tables/create\032\004\010\002\020\000\020\003*\025Create Feature Table.'
   _FEATURESTORESERVICE.methods_by_name['updateFeatureTable']._options = None
   _FEATURESTORESERVICE.methods_by_name['updateFeatureTable']._serialized_options = b'\362\206\031N\n3\n\005PATCH\022$/feature-store/feature-tables/update\032\004\010\002\020\000\020\003*\025Update Feature Table.'
   _FEATURESTORESERVICE.methods_by_name['deleteFeatureTable']._options = None
@@ -869,22 +970,28 @@
   _FEATURESTORESERVICE.methods_by_name['setTags']._serialized_options = b'\362\206\0314\n%\n\004POST\022\027/feature-store/tags/set\032\004\010\002\020\000\020\003*\tSet Tags.'
   _FEATURESTORESERVICE.methods_by_name['getTags']._options = None
   _FEATURESTORESERVICE.methods_by_name['getTags']._serialized_options = b'\362\206\0313\n$\n\003GET\022\027/feature-store/tags/get\032\004\010\002\020\000\020\003*\tGet Tags.'
   _FEATURESTORESERVICE.methods_by_name['deleteTags']._options = None
   _FEATURESTORESERVICE.methods_by_name['deleteTags']._serialized_options = b'\362\206\031<\n*\n\006DELETE\022\032/feature-store/tags/delete\032\004\010\002\020\000\020\003*\014Delete Tags.'
   _FEATURESTORESERVICE.methods_by_name['createFeatureSpec']._options = None
   _FEATURESTORESERVICE.methods_by_name['createFeatureSpec']._serialized_options = b'\362\206\031M\n0\n\004POST\022\"/feature-store/feature-spec/create\032\004\010\002\020\000\020\003*\027Creates a Feature Spec.'
-  _PERMISSIONLEVEL._serialized_start=9685
-  _PERMISSIONLEVEL._serialized_end=9799
-  _PRODUCERACTION._serialized_start=9801
-  _PRODUCERACTION._serialized_end=9854
-  _ASSOCIATIONTYPE._serialized_start=9856
-  _ASSOCIATIONTYPE._serialized_end=9900
-  _SEARCHSCOPE._serialized_start=9902
-  _SEARCHSCOPE._serialized_end=10009
+  _FEATURESTORESERVICE.methods_by_name['updateFeatureSpec']._options = None
+  _FEATURESTORESERVICE.methods_by_name['updateFeatureSpec']._serialized_options = b'\362\206\031N\n1\n\005PATCH\022\"/feature-store/feature-spec/update\032\004\010\002\020\000\020\003*\027Updates a Feature Spec.'
+  _FEATURESTORESERVICE.methods_by_name['deleteFeatureSpec']._options = None
+  _FEATURESTORESERVICE.methods_by_name['deleteFeatureSpec']._serialized_options = b'\362\206\031O\n2\n\006DELETE\022\"/feature-store/feature-spec/delete\032\004\010\002\020\000\020\003*\027Deletes a Feature Spec.'
+  _FEATURESTORESERVICE.methods_by_name['generateFeatureSpecYaml']._options = None
+  _FEATURESTORESERVICE.methods_by_name['generateFeatureSpecYaml']._serialized_options = b'\362\206\031[\n7\n\004POST\022)/feature-store/feature-spec/generate-yaml\032\004\010\002\020\000\020\003*\036Generates a Feature Spec YAML.'
+  _PERMISSIONLEVEL._serialized_start=10744
+  _PERMISSIONLEVEL._serialized_end=10858
+  _PRODUCERACTION._serialized_start=10860
+  _PRODUCERACTION._serialized_end=10913
+  _ASSOCIATIONTYPE._serialized_start=10915
+  _ASSOCIATIONTYPE._serialized_end=10959
+  _SEARCHSCOPE._serialized_start=10961
+  _SEARCHSCOPE._serialized_end=11068
   _HEALTHCHECK._serialized_start=110
   _HEALTHCHECK._serialized_end=260
   _HEALTHCHECK_RESPONSE._serialized_start=170
   _HEALTHCHECK_RESPONSE._serialized_end=215
   _CREATEFEATURETABLE._serialized_start=263
   _CREATEFEATURETABLE._serialized_end=678
   _CREATEFEATURETABLE_RESPONSE._serialized_start=571
@@ -1026,21 +1133,43 @@
   _CONSUMER._serialized_start=9155
   _CONSUMER._serialized_end=9326
   _FEATURETABLEFEATURES._serialized_start=9328
   _FEATURETABLEFEATURES._serialized_end=9396
   _TAG._serialized_start=9398
   _TAG._serialized_end=9431
   _CREATEFEATURESPEC._serialized_start=9434
-  _CREATEFEATURESPEC._serialized_end=9602
-  _CREATEFEATURESPEC_RESPONSE._serialized_start=9496
-  _CREATEFEATURESPEC_RESPONSE._serialized_end=9564
-  _FEATURESPECINFO._serialized_start=9604
-  _FEATURESPECINFO._serialized_end=9683
-  _FEATURESTORESERVICE._serialized_start=10012
-  _FEATURESTORESERVICE._serialized_end=15615
+  _CREATEFEATURESPEC._serialized_end=9675
+  _CREATEFEATURESPEC_RESPONSE._serialized_start=9569
+  _CREATEFEATURESPEC_RESPONSE._serialized_end=9637
+  _UPDATEFEATURESPEC._serialized_start=9677
+  _UPDATEFEATURESPEC._serialized_end=9775
+  _UPDATEFEATURESPEC_RESPONSE._serialized_start=170
+  _UPDATEFEATURESPEC_RESPONSE._serialized_end=180
+  _DELETEFEATURESPEC._serialized_start=9777
+  _DELETEFEATURESPEC._serialized_end=9860
+  _DELETEFEATURESPEC_RESPONSE._serialized_start=170
+  _DELETEFEATURESPEC_RESPONSE._serialized_end=180
+  _FEATURESPECINFO._serialized_start=9862
+  _FEATURESPECINFO._serialized_end=9941
+  _FEATURES._serialized_start=9944
+  _FEATURES._serialized_end=10079
+  _FEATURELOOKUP._serialized_start=10082
+  _FEATURELOOKUP._serialized_end=10283
+  _FEATUREFUNCTION._serialized_start=10285
+  _FEATUREFUNCTION._serialized_end=10393
+  _RENAMEOUTPUT._serialized_start=10395
+  _RENAMEOUTPUT._serialized_end=10452
+  _INPUTBINDING._serialized_start=10454
+  _INPUTBINDING._serialized_end=10520
+  _GENERATEFEATURESPECYAML._serialized_start=10523
+  _GENERATEFEATURESPECYAML._serialized_end=10742
+  _GENERATEFEATURESPECYAML_RESPONSE._serialized_start=10667
+  _GENERATEFEATURESPECYAML_RESPONSE._serialized_end=10704
+  _FEATURESTORESERVICE._serialized_start=11071
+  _FEATURESTORESERVICE._serialized_end=17249
 FeatureStoreService = service_reflection.GeneratedServiceType('FeatureStoreService', (_service.Service,), dict(
   DESCRIPTOR = _FEATURESTORESERVICE,
   __module__ = 'feature_catalog_pb2'
   ))
 
 FeatureStoreService_Stub = service_reflection.GeneratedServiceStubType('FeatureStoreService_Stub', (FeatureStoreService,), dict(
   DESCRIPTOR = _FEATURESTORESERVICE,
```

## databricks/ml_features/utils/feature_lookup_utils.py

```diff
@@ -294,24 +294,41 @@
 
     for join_data_key, feature_to_output_name in table_join_data.items():
 
         feature_table_metadata = feature_table_metadata_map[join_data_key.feature_table]
         feature_table_data = feature_table_data_map[join_data_key.feature_table]
 
         if join_data_key.timestamp_lookup_key:
-            df = _spark_asof_join_features(
-                df=df,
-                df_lookup_keys=join_data_key.lookup_key,
-                df_timestamp_lookup_key=join_data_key.timestamp_lookup_key[0],
-                feature_table_data=feature_table_data,
-                feature_table_keys=feature_table_metadata.primary_keys,
-                feature_table_timestamp_key=feature_table_metadata.timestamp_keys[0],
-                feature_to_output_name=feature_to_output_name,
-                lookback_window_seconds=join_data_key.lookback_window,
-            )
+            # If lookback window is set to 0, then perform exact join instead of asof join to get perf benefits.
+            if (
+                join_data_key.lookback_window is not None
+                and join_data_key.lookback_window == 0
+            ):
+                df = _spark_join_features(
+                    df=df,
+                    df_keys=join_data_key.lookup_key
+                    + join_data_key.timestamp_lookup_key,
+                    feature_table_data=feature_table_data,
+                    feature_table_keys=feature_table_metadata.primary_keys
+                    + feature_table_metadata.timestamp_keys,
+                    feature_to_output_name=feature_to_output_name,
+                )
+            else:
+                df = _spark_asof_join_features(
+                    df=df,
+                    df_lookup_keys=join_data_key.lookup_key,
+                    df_timestamp_lookup_key=join_data_key.timestamp_lookup_key[0],
+                    feature_table_data=feature_table_data,
+                    feature_table_keys=feature_table_metadata.primary_keys,
+                    feature_table_timestamp_key=feature_table_metadata.timestamp_keys[
+                        0
+                    ],
+                    feature_to_output_name=feature_to_output_name,
+                    lookback_window_seconds=join_data_key.lookback_window,
+                )
         else:
             df = _spark_join_features(
                 df=df,
                 df_keys=join_data_key.lookup_key,
                 feature_table_data=feature_table_data,
                 feature_table_keys=feature_table_metadata.primary_keys,
                 feature_to_output_name=feature_to_output_name,
```

## Comparing `databricks_feature_engineering-0.3.0.dist-info/LICENSE.md` & `databricks_feature_engineering-0.4.0.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `databricks_feature_engineering-0.3.0.dist-info/METADATA` & `databricks_feature_engineering-0.4.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,20 @@
 Metadata-Version: 2.1
 Name: databricks-feature-engineering
-Version: 0.3.0
+Version: 0.4.0
 Summary: Databricks Feature Engineering Client
 Author-email: Databricks <feedback@databricks.com>
 License: Databricks Proprietary License
 Keywords: databricks,feature engineering,feature store
 Classifier: Programming Language :: Python :: 3
 Requires-Python: >=3.8.10
 Description-Content-Type: text/markdown
 License-File: LICENSE.md
 License-File: NOTICE.md
-Requires-Dist: mlflow-skinny[databricks] <3,>=2.10.0
-Requires-Dist: pyspark <4,>=3.1.2
+Requires-Dist: mlflow-skinny[databricks] <3,>=2.11.0
 Requires-Dist: pyyaml <7,>=6
 Requires-Dist: boto3 <2,>=1.16.7
 Requires-Dist: dbl-tempo <1,>=0.1.26
 Requires-Dist: azure-cosmos ==4.3.1
 Requires-Dist: numpy <2,>=1.19.2
 Requires-Dist: protobuf <5,>=3.12.0
 Requires-Dist: flask <3,>=1.1.2
```

## Comparing `databricks_feature_engineering-0.3.0.dist-info/NOTICE.md` & `databricks_feature_engineering-0.4.0.dist-info/NOTICE.md`

 * *Files identical despite different names*

## Comparing `databricks_feature_engineering-0.3.0.dist-info/RECORD` & `databricks_feature_engineering-0.4.0.dist-info/RECORD`

 * *Files 3% similar despite different names*

```diff
@@ -1,25 +1,25 @@
 databricks/__init__.py,sha256=7noYNogLhE-jGNuipxgQO3nXz7rbV0kkvxJmTsDtgV4,166
 databricks/_feature_store_pkg_metadata/__init__.py,sha256=7noYNogLhE-jGNuipxgQO3nXz7rbV0kkvxJmTsDtgV4,166
 databricks/_feature_store_pkg_metadata/_core_client_pkg_metadata/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/feature_engineering/__init__.py,sha256=1GUxAz9FZwNhoEqxtwlOh8pYzE5Zl3xl9VaDFccjMGA,2262
-databricks/feature_engineering/client.py,sha256=hKAbiE_89rir1ZsqgHmqrnZKUEJgle7PNgfbvp6nzn8,35813
+databricks/feature_engineering/client.py,sha256=-JwS-B7FcddVjdTPGL08771lTpT90VBfjfCQYEQq9OY,35868
 databricks/feature_engineering/training_set.py,sha256=uWU5ENZsgauJdM5hi7OxfWjpMKF5aP4-hHQvLJ0QAUs,87
-databricks/feature_engineering/upgrade_client.py,sha256=QZDQUAGXyd4jOZd_Vv0D48kcDJ0Smm12c25JzHNxLTA,22580
+databricks/feature_engineering/upgrade_client.py,sha256=hztoUr2uv2C2Fin8m_TX4X-SERQC2XZWbSPYw_dGaSo,22635
 databricks/feature_engineering/version.py,sha256=KCGRwYNkAHQEwpf3l_etBJVqnPwMF-QmhWx9no6fBJA,74
 databricks/feature_engineering/entities/__init__.py,sha256=SCXOzkIf2SS35l9x_qBrPzJZNNTU_lfUE2EtgLVlZpk,285
 databricks/feature_engineering/entities/feature_function.py,sha256=CumIwXmxguOTUkksLHi5mlMTIWrnvkWSas4wACshL8Y,108
 databricks/feature_engineering/entities/feature_lookup.py,sha256=N88BIMe_vmPrvUG8qN_WUp_VsgjtQRNx2QOUNZNyB0E,102
 databricks/feature_engineering/entities/feature_serving_endpoint.py,sha256=ZgGSeHe-b-FxChEGrwH-mbz5Sj21eN5qE2rQykbyJcY,282
 databricks/feature_engineering/entities/feature_spec_info.py,sha256=IU3qQxnFozBZZ8V2PY6dlA1VFx-GYXULn_mFdC3qf84,109
 databricks/feature_engineering/entities/feature_table.py,sha256=iMzdsJfifQGx-PYTa531W7n66t2Sc4Unix7eTOHXm7U,99
 databricks/feature_engineering/online_store_spec/__init__.py,sha256=XxfqqzY-5z3lbFiLYEeucIBo-Gw5hYCRis2tuzTZfwc,356
 databricks/feature_engineering/utils/upgrade_utils.py,sha256=80noCDE0Kz6e7i2nPBMlesP9xXUOuLus2ZroLR9lHaM,3760
 databricks/feature_store/__init__.py,sha256=DlRzknhWOGcrd2LF18tXe_AdUJYkQ5BWUd3YYaNf0nU,2648
-databricks/feature_store/client.py,sha256=gYZTBIMaGJ-Fszqma07jzrMqQFZ6nQx1R_Qg0E9sjl4,46692
+databricks/feature_store/client.py,sha256=EUrrM5yCA0hLTqAwRMWn8AxyW9fvCFGVuj116bZA8UE,46747
 databricks/feature_store/decorators.py,sha256=nT8itb3LESjQavpZXwi3bElhj-vo8PabiXNtnaCRiog,6319
 databricks/feature_store/mlflow_model.py,sha256=my_JP00l4h7Pqys_RFCEjkRfRm86LprDu4ZRr26FKhY,2295
 databricks/feature_store/training_set.py,sha256=uWU5ENZsgauJdM5hi7OxfWjpMKF5aP4-hHQvLJ0QAUs,87
 databricks/feature_store/version.py,sha256=KCGRwYNkAHQEwpf3l_etBJVqnPwMF-QmhWx9no6fBJA,74
 databricks/feature_store/entities/__init__.py,sha256=_2Mpj4U6-e8O9JI3Qvy3T48o04Z9AKNpLr8T4FwIl_U,291
 databricks/feature_store/entities/feature.py,sha256=_Mn4U1ac5blQBphDb0_azoLpEu0GQYgVrcDhztvm89Y,145
 databricks/feature_store/entities/feature_function.py,sha256=CumIwXmxguOTUkksLHi5mlMTIWrnvkWSas4wACshL8Y,108
@@ -28,42 +28,43 @@
 databricks/feature_store/entities/feature_spec.py,sha256=d5cuizzUW_3Eg63GfvOOv6-kUXYG2n1ThF2eaEumllU,170
 databricks/feature_store/entities/feature_spec_info.py,sha256=IU3qQxnFozBZZ8V2PY6dlA1VFx-GYXULn_mFdC3qf84,109
 databricks/feature_store/entities/feature_table.py,sha256=iMzdsJfifQGx-PYTa531W7n66t2Sc4Unix7eTOHXm7U,99
 databricks/feature_store/online_store_spec/__init__.py,sha256=XxfqqzY-5z3lbFiLYEeucIBo-Gw5hYCRis2tuzTZfwc,356
 databricks/feature_store/publish_engine/__init__.py,sha256=i0aQuaI4H1JXSCwri9TSA0USGCsOg4MtCXnsw1KsoRU,335
 databricks/ml_features/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/constants.py,sha256=2QJVr34Rqew3rDHVkhy1CBUtIjat4dEmT4it-smd2VA,921
+databricks/ml_features/environment_variables.py,sha256=ZEFml5H9MQuzBKM074mUrFYu-Sga4Knmxqiwpke2WGc,1679
 databricks/ml_features/training_set.py,sha256=fsdx38jaz5Y65w0t2z_0VJ1f3VMDFRqEIGyh9FuWyf0,5569
-databricks/ml_features/version.py,sha256=OgfvlOui_Z4FwAja2bTJgiUkMeuAXZ561wYewaEr6SQ,18
+databricks/ml_features/version.py,sha256=PS0k6-Ci30dE_Nsmj4Ud5HkeeS0C778G78NsBdlUuyg,18
 databricks/ml_features/_catalog_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/_catalog_client/_catalog_client.py,sha256=a_cBWHRnvMnbzXUSsnq9Yf9i8iHOuMb1KCrffJ5SPIo,21431
 databricks/ml_features/_catalog_client/_catalog_client_helper.py,sha256=EK4_RHJ1tvuJ9_plzl9fSnqyALUMAltdZm1lrDddHe0,5751
 databricks/ml_features/_compute_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/ml_features/_compute_client/_compute_client.py,sha256=tm_7hZclUZ9U_bszPuzoNWXLIY7ZSrEqN64yZkhpJlU,55022
+databricks/ml_features/_compute_client/_compute_client.py,sha256=HKo7yIUok2h42GKaRPHS0_PoU7vp4ZTgnDHJVKMoOZI,56876
 databricks/ml_features/_databricks_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/ml_features/_databricks_client/_databricks_client.py,sha256=2CMhdgzshln9HbacKtwIj31CJlL6iDaITawDN70Xiqg,2389
+databricks/ml_features/_databricks_client/_databricks_client.py,sha256=Kq0KRxqghT47BSy2BehU7OhKSYx-xMohZ0R5xJcZGXI,3210
 databricks/ml_features/_feature_serving_endpoint_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/ml_features/_feature_serving_endpoint_client/_feature_serving_endpoint_client.py,sha256=Ya72W5ankZukXSErMaYkaRVXrkOLsDasbVwEyaJjf0c,8348
+databricks/ml_features/_feature_serving_endpoint_client/_feature_serving_endpoint_client.py,sha256=NVGJfxQbjwokxM_z1tZORhBKu9CFn9DdfTc4ge1b6t4,8412
 databricks/ml_features/_information_schema_spark_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/_information_schema_spark_client/_information_schema_spark_client.py,sha256=SU7itP9F9hJTqP2ExOK21VD1w42-jv6LR10PLyUQ-TU,7625
 databricks/ml_features/_online_store_publish_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/_online_store_publish_client/_online_store_publish_client.py,sha256=Umqpe7gKsJ57ONK8BEavcmGX0GUAjXuevx_avxR6aog,5344
 databricks/ml_features/_online_store_publish_client/_online_store_publish_client_factory.py,sha256=H_Iuqm_VOvaPS1Y6_qtOKHJKRjFwXtuODP89Hy5XxfY,912
-databricks/ml_features/_online_store_publish_client/_online_store_publish_nosql_client.py,sha256=DcL19HiYmQnoY3YqGxjnk9ITfhkcBKEGZ_oxMRLHfXE,6135
-databricks/ml_features/_online_store_publish_client/_online_store_publish_rdbms_client.py,sha256=xLMMRkXrg94Rw3s0DsaW9R0V5alHD2TLmog0IET2mMc,13714
+databricks/ml_features/_online_store_publish_client/_online_store_publish_nosql_client.py,sha256=l1bq924d3gIgZyTDqAAxnWt3rMwL82f00RWIxhFRFeU,6201
+databricks/ml_features/_online_store_publish_client/_online_store_publish_rdbms_client.py,sha256=_qImHw0diuRcbP1b-1f9hP_qL3Hz2dHJkvxALHU-JmI,13779
 databricks/ml_features/_publish_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/ml_features/_publish_client/_publish_client.py,sha256=UVJJL86tUmS78d00DLzetn8a9zIaXNckFBW8BuI8XRg,20034
+databricks/ml_features/_publish_client/_publish_client.py,sha256=m9E88OMyCbGTZ0Tb_ijmBTKByz5EMM4c3RVP0VT7bcQ,20175
 databricks/ml_features/_spark_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/ml_features/_spark_client/_spark_client.py,sha256=q96E3-Pec3MEVFkmaXp36iG2eaJWWTe7Q4nOdXgYn1M,30117
+databricks/ml_features/_spark_client/_spark_client.py,sha256=WEhxLlC_0Q0TE9SGyBKqnmAAHhP5AGfL4mE7nln4j60,30059
 databricks/ml_features/_spark_client/_spark_client_helper.py,sha256=E3bGcE48N0dDMAL1mMo_1ReRBBgd3sNM3RB-4Opo1CY,2179
 databricks/ml_features/_training_scoring_client/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/_training_scoring_client/_training_scoring_client.py,sha256=Qp50HJ68vTQXyMPs6YbItc_EtY8Y2p8ztPzXmXEOa64,32102
 databricks/ml_features/api/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/api/proto/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-databricks/ml_features/api/proto/feature_catalog_pb2.py,sha256=Hz8BbFIKbCSz5I-w7_EVU2NnPxHbL9MMKulx_RhQIQs,81316
+databricks/ml_features/api/proto/feature_catalog_pb2.py,sha256=t8x72u9lk7tN7EaHgy2FSp9x4KfYrhg5BgOF4FGBsVs,90757
 databricks/ml_features/entities/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 databricks/ml_features/entities/_permission_level.py,sha256=tSq-JBAWubCqEkcq0qDLLKqjmWVbhGckZbNp8PXzJp4,905
 databricks/ml_features/entities/consumer.py,sha256=wwVjYBo2Bk0c5r4zddEYMAxkZe5wcZ8Htkvs-9QSZEo,1102
 databricks/ml_features/entities/data_type.py,sha256=BN2Ev9Kyr-vwm206RkwM_tCFay2g-sT6bK_HGng-_Gk,3417
 databricks/ml_features/entities/feature.py,sha256=lxUuZ9y-soLxSQAeANkqBa8D63YCi6u9bVQ7WxJ8PCg,1447
 databricks/ml_features/entities/feature_function.py,sha256=cMQVM5SnZ_HCYUI7fd-Y-yXb7MaAeE1UI8bvOebFhJ0,2026
 databricks/ml_features/entities/feature_lookup.py,sha256=v7_hLLpL6luv9Ur0yhDJdEwwfk0rb-edxkh2HnC_Ntg,8361
@@ -93,15 +94,15 @@
 databricks/ml_features/publish_engine/publish_mysql_engine.py,sha256=OBh9LwTJQPsFUjy3VXV1CXzlmx32Ej6USjWVeR7k798,6038
 databricks/ml_features/publish_engine/publish_sql_engine.py,sha256=cIWvEd1JwVKi0QOiOijiyE3nW5SnloVRRRS3l8D_F_8,4678
 databricks/ml_features/publish_engine/publish_sql_server_engine.py,sha256=fJAE-WVPoikZNaTlxmbFqsSNWbIOg-TL_9ePDrNzPeY,8400
 databricks/ml_features/utils/cosmosdb_type_utils.py,sha256=R8z0oFniD7T3f-6E6__bCpw-Bl3gT4Qs1yAKCMSk2eQ,7996
 databricks/ml_features/utils/cosmosdb_utils.py,sha256=nCXtCYWajY8gNweAEuuldiGgqS1D_E3Es3ghZNARycM,3888
 databricks/ml_features/utils/dynamodb_type_utils.py,sha256=nAiYLdG0dKtZ8bJwwLUjAGSHfxiZH8h5mVhfiwKG1YY,7375
 databricks/ml_features/utils/e2e_test_utils.py,sha256=F6zdi4T_Ml7n7T7BmrZNcPBqCKulkD_GuwoVOa3VdSw,11599
-databricks/ml_features/utils/feature_lookup_utils.py,sha256=9j_69-HCPX_NIihE7HM5xS9k3XD50fHJJrXu9I1aIrA,13779
+databricks/ml_features/utils/feature_lookup_utils.py,sha256=heXPE3ZLlDafyvy4PsSq43Qyl5smzX1gnqOmYrUqavk,14602
 databricks/ml_features/utils/feature_serving_endpoint_utils.py,sha256=j4YxYFuW9gj8jtntCrUdbq8z1R0dKuW4OvFq5wK70Ss,1588
 databricks/ml_features/utils/feature_utils.py,sha256=GiMPGb7CBXP8AjowqdVrGxZ4igatzaBZfER9zQDscC8,1897
 databricks/ml_features/utils/headers.yaml,sha256=0rWH0CVX6j6g7MiKhBqLOgWs_cZEO9BoJBkQKdxVGZM,1207
 databricks/ml_features/utils/logging_utils.py,sha256=1XIBF2NF_5ozbgHMSWso8qdyQGN3_BMWzYzpugCEt64,1609
 databricks/ml_features/utils/on_demand_utils.py,sha256=FcVEPa6_1Rv7VnZ30BGQF4Hwyj3unaCtH32f2l2E_Wc,4445
 databricks/ml_features/utils/publish_utils.py,sha256=ncNcp3v1Mm1RUfVDMPc6Blkt4nELKGRXPCwaM0pbZ_4,1915
 databricks/ml_features/utils/request_context.py,sha256=QZ7lDrGcFyiunB4haPkm4bwsJs-my9-aaTh7UUq65h0,12872
@@ -142,13 +143,13 @@
 databricks/ml_features_common/utils/dynamodb_utils.py,sha256=GPjNoFTfcEO-vQUq16sG3FzwAYgkYIWPMv-iNsGqv7E,5193
 databricks/ml_features_common/utils/feature_spec_test_utils.py,sha256=N8LQgtqo7YW_8hP7-3j0SPStbGILbLaKskGRU7QoM8I,2356
 databricks/ml_features_common/utils/feature_spec_utils.py,sha256=syr2Mvgf6fZ-I9oEAjoHklXGnzYMAp1qAXrAeKXcnSQ,11042
 databricks/ml_features_common/utils/test_utils_common.py,sha256=Db1Pv7gGQ7pdRSzBf5O0CzBG1HCW3H-JXmkKZrjAlt0,374
 databricks/ml_features_common/utils/topological_sort.py,sha256=KntAzpXoK2po_qoqniVEi2muRmNEQwqvTq6rsiYH_-0,5400
 databricks/ml_features_common/utils/uc_utils.py,sha256=LwjquzRjnCG7dBZPrEaS0SAXnj11uM7XzQusbsBO3WA,10298
 databricks/ml_features_common/utils/utils_common.py,sha256=4IG3BDswbe7OiDR7Vugpd6yvxGE9Z_d1K3i21v3PzWs,3802
-databricks_feature_engineering-0.3.0.dist-info/LICENSE.md,sha256=VlYiPV28DtYjKCQz5F3iskOvlNCMSXKQ8l5ggcRt28s,2414
-databricks_feature_engineering-0.3.0.dist-info/METADATA,sha256=1Kh5VrShhHKtabItECuXNFmQeCaFfj_SEUJFxoaF7OA,4276
-databricks_feature_engineering-0.3.0.dist-info/NOTICE.md,sha256=wVfwv01RGQ4XpE9OGGk4yLroOU37eICqyUwxxvlyqYo,515
-databricks_feature_engineering-0.3.0.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-databricks_feature_engineering-0.3.0.dist-info/top_level.txt,sha256=7kRdatoSgU0EUurRQJ_3F1Nv4EOSHWAr6ng25tJOJKU,11
-databricks_feature_engineering-0.3.0.dist-info/RECORD,,
+databricks_feature_engineering-0.4.0.dist-info/LICENSE.md,sha256=VlYiPV28DtYjKCQz5F3iskOvlNCMSXKQ8l5ggcRt28s,2414
+databricks_feature_engineering-0.4.0.dist-info/METADATA,sha256=VHc9WT16gZWy-VnmRNrpuMpW25fzJa8-PKC_Od6wzQ8,4242
+databricks_feature_engineering-0.4.0.dist-info/NOTICE.md,sha256=wVfwv01RGQ4XpE9OGGk4yLroOU37eICqyUwxxvlyqYo,515
+databricks_feature_engineering-0.4.0.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+databricks_feature_engineering-0.4.0.dist-info/top_level.txt,sha256=7kRdatoSgU0EUurRQJ_3F1Nv4EOSHWAr6ng25tJOJKU,11
+databricks_feature_engineering-0.4.0.dist-info/RECORD,,
```

