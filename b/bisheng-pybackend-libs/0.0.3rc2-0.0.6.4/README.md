# Comparing `tmp/bisheng_pybackend_libs-0.0.3rc2-py3-none-any.whl.zip` & `tmp/bisheng_pybackend_libs-0.0.6.4-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,71 +1,68 @@
-Zip file size: 5956568 bytes, number of entries: 69
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/framework/__init__.py
--rw-r--r--  2.0 unx     3185 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/framework/hf_model.py
--rw-r--r--  2.0 unx     1336 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/framework/onnx_graph.py
--rw-r--r--  2.0 unx     1455 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/framework/pt_graph.py
--rw-r--r--  2.0 unx     1756 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/framework/tf_graph.py
--rw-r--r--  2.0 unx     2419 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/__init__.py
--rw-r--r--  2.0 unx     2134 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/bge.py
--rw-r--r--  2.0 unx     4427 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/embedding.py
--rw-r--r--  2.0 unx     1823 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/gte.py
--rw-r--r--  2.0 unx     1070 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/jina.py
--rw-r--r--  2.0 unx    98683 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/jina_util.py
--rw-r--r--  2.0 unx     2203 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/me5.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/embedding/rocketqa_dual.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/layout/__init__.py
--rw-r--r--  2.0 unx     6815 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/layout/config.py
--rw-r--r--  2.0 unx     8766 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/layout/layout_mrcnn.py
--rw-r--r--  2.0 unx    41761 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/layout/mrcnn_pt.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llama_cpp/__init__.py
--rw-r--r--  2.0 unx     5079 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llama_cpp/lc_model.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/__init__.py
--rw-r--r--  2.0 unx     5735 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/baichuan.py
--rw-r--r--  2.0 unx     6267 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/chatglm2.py
--rw-r--r--  2.0 unx     1247 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/chatglm2_utils.py
--rw-r--r--  2.0 unx     8580 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/chatglm3.py
--rw-r--r--  2.0 unx     3931 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/code_geex2.py
--rw-r--r--  2.0 unx     3485 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/internlm.py
--rw-r--r--  2.0 unx     2664 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/llama2.py
--rw-r--r--  2.0 unx     3821 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/llama2_utils.py
--rw-r--r--  2.0 unx     7050 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/llm.py
--rw-r--r--  2.0 unx     7671 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/qwen.py
--rw-r--r--  2.0 unx     5299 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/qwen1_5.py
--rw-r--r--  2.0 unx    10836 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/qwen_utils.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/vicuna.py
--rw-r--r--  2.0 unx     2730 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/xverse.py
--rw-r--r--  2.0 unx     6005 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/yi.py
--rw-r--r--  2.0 unx     2827 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/llm/yuan.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/mmu/__init__.py
--rw-r--r--  2.0 unx     1915 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/mmu/visualglm.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/ocr/__init__.py
--rw-r--r--  2.0 unx    10251 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/ocr/latex_det.py
--rw-r--r--  2.0 unx    24911 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/ocr/latex_recog.py
--rw-r--r--  2.0 unx     1526 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/ocr/ocr_client.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/table/__init__.py
--rw-r--r--  2.0 unx    34931 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/table/table_app.py
--rw-r--r--  2.0 unx    17378 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/table/table_mrcnn.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/vllm/__init__.py
--rw-r--r--  2.0 unx    39282 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/vllm/conversation.py
--rw-r--r--  2.0 unx     8555 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/model/vllm/vllm_model.py
--rw-r--r--  2.0 unx      931 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/__init__.py
--rw-r--r--  2.0 unx    17867 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/curve2rect.py
--rw-r--r--  2.0 unx     8440 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/geometry.py
--rw-r--r--  2.0 unx    14840 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/html_to_excel.py
--rw-r--r--  2.0 unx      538 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/image_io.py
--rw-r--r--  2.0 unx     1316 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/lazy_loader.py
--rw-r--r--  2.0 unx     5816 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/registry.py
--rw-r--r--  2.0 unx 10500792 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/simsun.ttc
--rw-r--r--  2.0 unx    15600 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/square_seal_postprocess.py
--rw-r--r--  2.0 unx    26726 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/table_cell_post.py
--rw-r--r--  2.0 unx    46157 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/table_rowcol_post.py
--rw-r--r--  2.0 unx    11276 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/tf_utils.py
--rw-r--r--  2.0 unx      527 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/timer.py
--rw-r--r--  2.0 unx     6317 b- defN 24-Apr-24 15:25 pybackend_libs/dataelem/utils/visualization.py
--rw-r--r--  2.0 unx     1927 b- defN 24-Apr-24 15:26 bisheng_pybackend_libs-0.0.3rc2.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-24 15:26 bisheng_pybackend_libs-0.0.3rc2.dist-info/WHEEL
--rw-r--r--  2.0 unx       15 b- defN 24-Apr-24 15:26 bisheng_pybackend_libs-0.0.3rc2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     7007 b- defN 24-Apr-24 15:26 bisheng_pybackend_libs-0.0.3rc2.dist-info/RECORD
-69 files, 11065993 bytes uncompressed, 5944990 bytes compressed:  46.3%
+Zip file size: 5935969 bytes, number of entries: 66
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/framework/__init__.py
+-rw-r--r--  2.0 unx     3185 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/framework/hf_model.py
+-rw-r--r--  2.0 unx     1336 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/framework/onnx_graph.py
+-rw-r--r--  2.0 unx     1455 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/framework/pt_graph.py
+-rw-r--r--  2.0 unx     1756 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/framework/tf_graph.py
+-rw-r--r--  2.0 unx     2236 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/embedding/__init__.py
+-rw-r--r--  2.0 unx     2134 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/embedding/bge.py
+-rw-r--r--  2.0 unx     3655 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/embedding/embedding.py
+-rw-r--r--  2.0 unx     1823 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/embedding/gte.py
+-rw-r--r--  2.0 unx     2203 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/embedding/me5.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/embedding/rocketqa_dual.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/layout/__init__.py
+-rw-r--r--  2.0 unx     6815 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/layout/config.py
+-rw-r--r--  2.0 unx     8766 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/layout/layout_mrcnn.py
+-rw-r--r--  2.0 unx    41761 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/layout/mrcnn_pt.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llama_cpp/__init__.py
+-rw-r--r--  2.0 unx     5079 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llama_cpp/lc_model.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/__init__.py
+-rw-r--r--  2.0 unx     5735 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/baichuan.py
+-rw-r--r--  2.0 unx     6267 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/chatglm2.py
+-rw-r--r--  2.0 unx     1247 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/chatglm2_utils.py
+-rw-r--r--  2.0 unx     8580 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/chatglm3.py
+-rw-r--r--  2.0 unx     3931 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/code_geex2.py
+-rw-r--r--  2.0 unx     3485 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/internlm.py
+-rw-r--r--  2.0 unx     2664 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/llama2.py
+-rw-r--r--  2.0 unx     3821 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/llama2_utils.py
+-rw-r--r--  2.0 unx     6812 b- defN 24-Feb-26 10:41 pybackend_libs/dataelem/model/llm/llm.py
+-rw-r--r--  2.0 unx     7672 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/qwen.py
+-rw-r--r--  2.0 unx    10836 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/qwen_utils.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/vicuna.py
+-rw-r--r--  2.0 unx     2730 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/xverse.py
+-rw-r--r--  2.0 unx     6005 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/llm/yi.py
+-rw-r--r--  2.0 unx     2827 b- defN 24-Feb-26 10:41 pybackend_libs/dataelem/model/llm/yuan.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/mmu/__init__.py
+-rw-r--r--  2.0 unx     1915 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/mmu/visualglm.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/ocr/__init__.py
+-rw-r--r--  2.0 unx    10251 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/ocr/latex_det.py
+-rw-r--r--  2.0 unx    24911 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/ocr/latex_recog.py
+-rw-r--r--  2.0 unx     1526 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/ocr/ocr_client.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/table/__init__.py
+-rw-r--r--  2.0 unx    34931 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/table/table_app.py
+-rw-r--r--  2.0 unx    17378 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/table/table_mrcnn.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/vllm/__init__.py
+-rw-r--r--  2.0 unx    39282 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/vllm/conversation.py
+-rw-r--r--  2.0 unx     8409 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/model/vllm/vllm_model.py
+-rw-r--r--  2.0 unx      931 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/__init__.py
+-rw-r--r--  2.0 unx    17867 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/curve2rect.py
+-rw-r--r--  2.0 unx     8440 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/geometry.py
+-rw-r--r--  2.0 unx    14840 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/html_to_excel.py
+-rw-r--r--  2.0 unx      538 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/image_io.py
+-rw-r--r--  2.0 unx     1316 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/lazy_loader.py
+-rw-r--r--  2.0 unx     5816 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/registry.py
+-rw-r--r--  2.0 unx 10500792 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/simsun.ttc
+-rw-r--r--  2.0 unx    15600 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/square_seal_postprocess.py
+-rw-r--r--  2.0 unx    26726 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/table_cell_post.py
+-rw-r--r--  2.0 unx    46157 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/table_rowcol_post.py
+-rw-r--r--  2.0 unx    11276 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/tf_utils.py
+-rw-r--r--  2.0 unx      527 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/timer.py
+-rw-r--r--  2.0 unx     6317 b- defN 24-Feb-18 03:13 pybackend_libs/dataelem/utils/visualization.py
+-rw-r--r--  2.0 unx     2009 b- defN 24-Feb-26 10:44 bisheng_pybackend_libs-0.0.6.4.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Feb-26 10:44 bisheng_pybackend_libs-0.0.6.4.dist-info/WHEEL
+-rw-r--r--  2.0 unx       15 b- defN 24-Feb-26 10:44 bisheng_pybackend_libs-0.0.6.4.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6688 b- defN 24-Feb-26 10:44 bisheng_pybackend_libs-0.0.6.4.dist-info/RECORD
+66 files, 10959366 bytes uncompressed, 5924913 bytes compressed:  45.9%
```

## zipnote {}

```diff
@@ -30,20 +30,14 @@
 
 Filename: pybackend_libs/dataelem/model/embedding/embedding.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/model/embedding/gte.py
 Comment: 
 
-Filename: pybackend_libs/dataelem/model/embedding/jina.py
-Comment: 
-
-Filename: pybackend_libs/dataelem/model/embedding/jina_util.py
-Comment: 
-
 Filename: pybackend_libs/dataelem/model/embedding/me5.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/model/embedding/rocketqa_dual.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/model/layout/__init__.py
@@ -93,17 +87,14 @@
 
 Filename: pybackend_libs/dataelem/model/llm/llm.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/model/llm/qwen.py
 Comment: 
 
-Filename: pybackend_libs/dataelem/model/llm/qwen1_5.py
-Comment: 
-
 Filename: pybackend_libs/dataelem/model/llm/qwen_utils.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/model/llm/vicuna.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/model/llm/xverse.py
@@ -189,20 +180,20 @@
 
 Filename: pybackend_libs/dataelem/utils/timer.py
 Comment: 
 
 Filename: pybackend_libs/dataelem/utils/visualization.py
 Comment: 
 
-Filename: bisheng_pybackend_libs-0.0.3rc2.dist-info/METADATA
+Filename: bisheng_pybackend_libs-0.0.6.4.dist-info/METADATA
 Comment: 
 
-Filename: bisheng_pybackend_libs-0.0.3rc2.dist-info/WHEEL
+Filename: bisheng_pybackend_libs-0.0.6.4.dist-info/WHEEL
 Comment: 
 
-Filename: bisheng_pybackend_libs-0.0.3rc2.dist-info/top_level.txt
+Filename: bisheng_pybackend_libs-0.0.6.4.dist-info/top_level.txt
 Comment: 
 
-Filename: bisheng_pybackend_libs-0.0.3rc2.dist-info/RECORD
+Filename: bisheng_pybackend_libs-0.0.6.4.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## pybackend_libs/dataelem/model/__init__.py

```diff
@@ -1,21 +1,19 @@
 from pybackend_libs.dataelem.utils.lazy_loader import lazy
 
 bge = lazy('pybackend_libs.dataelem.model.embedding.bge')
 gte = lazy('pybackend_libs.dataelem.model.embedding.gte')
 me5 = lazy('pybackend_libs.dataelem.model.embedding.me5')
-jina = lazy('pybackend_libs.dataelem.model.embedding.jina')
 baichuan = lazy('pybackend_libs.dataelem.model.llm.baichuan')
 chatglm2 = lazy('pybackend_libs.dataelem.model.llm.chatglm2')
 chatglm3 = lazy('pybackend_libs.dataelem.model.llm.chatglm3')
 code_geex2 = lazy('pybackend_libs.dataelem.model.llm.code_geex2')
 internlm = lazy('pybackend_libs.dataelem.model.llm.internlm')
 llama2 = lazy('pybackend_libs.dataelem.model.llm.llama2')
 qwen = lazy('pybackend_libs.dataelem.model.llm.qwen')
-qwen1_5 = lazy('pybackend_libs.dataelem.model.llm.qwen1_5')
 xverse = lazy('pybackend_libs.dataelem.model.llm.xverse')
 visualglm = lazy('pybackend_libs.dataelem.model.mmu.visualglm')
 vllm_model = lazy('pybackend_libs.dataelem.model.vllm.vllm_model')
 layout_mrcnn = lazy('pybackend_libs.dataelem.model.layout.layout_mrcnn')
 table_mrcnn = lazy('pybackend_libs.dataelem.model.table.table_mrcnn')
 table_app = lazy('pybackend_libs.dataelem.model.table.table_app')
 yi_base = lazy('pybackend_libs.dataelem.model.llm.yi')
@@ -28,22 +26,20 @@
 
 def get_model(name: str):
     model_name_mapping = {
         'ChatGLM2': chatglm2,
         'ChatGLM3': chatglm3,
         'BaichuanChat': baichuan,
         'QwenChat': qwen,
-        'Qwen1_5Chat': qwen1_5,
         'Llama2Chat': llama2,
         'VisualGLM': visualglm,
         'XverseChat': xverse,
         'InternLMChat': internlm,
         'ME5Embedding': me5,
         'BGEZhEmbedding': bge,
-        'JINAEmbedding': jina,
         'GTEEmbedding': gte,
         'LayoutMrcnn': layout_mrcnn,
         'TableCellApp': table_app,
         'TableRowColApp': table_app,
         'MrcnnTableDetect': table_mrcnn,
         'VLLMModel': vllm_model,
         'YiBase': yi_base,
```

## pybackend_libs/dataelem/model/embedding/embedding.py

```diff
@@ -6,16 +6,14 @@
 from accelerate import infer_auto_device_map, init_empty_weights
 from pydantic import BaseModel, Field
 from torch import Tensor
 from transformers import AutoConfig, AutoModel, AutoTokenizer
 
 # from transformers.generation.utils import GenerationConfig
 
-from .jina_util import JinaBertConfig, JinaBertModel
-
 
 def average_pool(last_hidden_states: Tensor, attention_mask: Tensor) -> Tensor:
     last_hidden = last_hidden_states.masked_fill(
         ~attention_mask[..., None].bool(), 0.0)
     return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]
 
 
@@ -60,16 +58,15 @@
 
     def _load(self,
               pretrain_path,
               precision,
               devices,
               gpu_memory,
               use_safetensors=False,
-              use_sentence_transformers=False,
-              jina_mode=False):
+              use_sentence_transformers=False):
 
         torch_seed()
 
         if use_sentence_transformers:
             raise Exception('not support for sentence-transformers')
             # torch.cuda.set_device(int(devices[0]))
             # self.model = SentenceTransformer(pretrain_path)
@@ -80,47 +77,32 @@
         memory = f'{memory_per_device}GiB'
         max_memory = {int(device_id): memory for device_id in devices}
 
         self.tokenizer = AutoTokenizer.from_pretrained(pretrain_path,
                                                        use_fast=False,
                                                        trust_remote_code=True)
         with init_empty_weights():
-            if jina_mode is True:
-                config = JinaBertConfig()
-                config._name_or_path = pretrain_path
-            else:
-                config = AutoConfig.from_pretrained(pretrain_path,
+            config = AutoConfig.from_pretrained(pretrain_path,
                                                 trust_remote_code=True)
-            if jina_mode is True:
-                model = JinaBertModel(config)
-            else:
-                model = AutoModel.from_config(config,
+            model = AutoModel.from_config(config,
                                           torch_dtype=torch.float16,
                                           trust_remote_code=True)
 
         no_split_modules = model._no_split_modules
         device_map = infer_auto_device_map(
             model,
             max_memory=max_memory,
             no_split_module_classes=no_split_modules)
 
-        if jina_mode is True:
-            self.model = JinaBertModel.from_pretrained(pretrain_path,
-                                               device_map=device_map,
-                                               trust_remote_code=True,
-                                               use_safetensors=use_safetensors
-                                               )
-        else:
-            self.model = AutoModel.from_pretrained(pretrain_path,
+        self.model = AutoModel.from_pretrained(pretrain_path,
                                                device_map=device_map,
                                                torch_dtype=torch.float16,
                                                trust_remote_code=True,
-                                               use_safetensors=use_safetensors
-                                               )
+                                               use_safetensors=use_safetensors)
 
         self.model.eval()
 
 
 class EmbResponse(BaseModel):
     model: str
     embeddings: List[List[float]]
-    created: Optional[int] = Field(default_factory=lambda: int(time.time()))
+    created: Optional[int] = Field(default_factory=lambda: int(time.time()))
```

## pybackend_libs/dataelem/model/llm/llm.py

```diff
@@ -1,20 +1,18 @@
-# flake8: noqa
 import time
 from typing import Dict, List, Literal, Optional, Union
 
 import torch
 from accelerate import (dispatch_model, infer_auto_device_map,
                         init_empty_weights)
 from pydantic import BaseModel, Field
 from transformers import (AutoConfig, AutoModel, AutoModelForCausalLM,
                           AutoTokenizer, LlamaTokenizer)
 from transformers.generation.utils import GenerationConfig
 
-
 def torch_gc(devices):
     if torch.cuda.is_available():
         for device_id in devices:
             with torch.cuda.device(f'cuda:{device_id}'):
                 torch.cuda.empty_cache()
                 torch.cuda.ipc_collect()
 
@@ -62,21 +60,21 @@
 
         if not use_llamatokenizer:
             self.tokenizer = AutoTokenizer.from_pretrained(pretrain_path,
                                                        use_fast=False,
                                                        trust_remote_code=True)
         else:
             self.tokenizer = LlamaTokenizer.from_pretrained(pretrain_path,
-                                                        add_eos_token=False,
-                                                        add_bos_token=False,
+                                                        add_eos_token=False, 
+                                                        add_bos_token=False, 
                                                         eos_token='<eod>',
                                                         use_fast=False,
                                                         trust_remote_code=True)
-            self.tokenizer.add_tokens(['<sep>', '<pad>', '<mask>', '<predict>',
-                                       '<FIM_SUFFIX>', '<FIM_PREFIX>',
+            self.tokenizer.add_tokens(['<sep>', '<pad>', '<mask>', '<predict>', 
+                                       '<FIM_SUFFIX>', '<FIM_PREFIX>', 
                                        '<FIM_MIDDLE>','<commit_before>',
                                        '<commit_msg>','<commit_after>',
                                        '<jupyter_start>','<jupyter_text>',
                                        '<jupyter_code>','<jupyter_output>',
                                        '<empty_output>'], special_tokens=True)
 
         with init_empty_weights():
@@ -84,23 +82,21 @@
                                                 trust_remote_code=True)
             model = auto_model_cls.from_config(config,
                                                torch_dtype=torch.float16,
                                                trust_remote_code=True)
 
         model.tie_weights()
         no_split_modules = model._no_split_modules
-        torch_dtype = torch.float16
         if auto_configure_device_map is None:
             device_map = infer_auto_device_map(
                 model,
                 max_memory=max_memory,
                 no_split_module_classes=no_split_modules)
         elif auto_configure_device_map is True:
             device_map = 'auto'
-            torch_dtype = 'auto'
         else:
             device_map = auto_configure_device_map(
                 model,
                 max_memory=max_memory,
                 no_split_module_classes=no_split_modules)
 
         if use_dispatch:
@@ -110,15 +106,15 @@
                 use_safetensors=use_safetensors,
                 **kwargs).half()
             self.model = dispatch_model(model, device_map=device_map)
         else:
             self.model = auto_model_cls.from_pretrained(
                 pretrain_path,
                 device_map=device_map,
-                torch_dtype=torch_dtype,
+                torch_dtype=torch.float16,
                 trust_remote_code=True,
                 use_safetensors=use_safetensors,
                 **kwargs)
 
         self.model.eval()
 
 
@@ -158,27 +154,20 @@
 
 class ChatCompletionResponseStreamChoice(BaseModel):
     index: int
     delta: DeltaMessage
     finish_reason: Optional[Literal['stop', 'length']]
 
 
-class UsageInfo(BaseModel):
-    prompt_tokens: int = 0
-    total_tokens: int = 0
-    completion_tokens: Optional[int] = 0
-
-
 class ChatCompletionResponse(BaseModel):
     model: str
     object: Literal['chat.completion', 'chat.completion.chunk']
     choices: List[Union[ChatCompletionResponseChoice,
                         ChatCompletionResponseStreamChoice]]
     created: Optional[int] = Field(default_factory=lambda: int(time.time()))
-    usage: UsageInfo = UsageInfo()
 
 
 class CompletionRequest(BaseModel):
     model: str
     prompt: str
     temperature: Optional[float] = None
     top_p: Optional[float] = None
```

## pybackend_libs/dataelem/model/llm/qwen.py

```diff
@@ -114,15 +114,15 @@
         if precision == 'bf16':
             load_params = {'bf16': True}
 
         num_layers = int(kwargs.get('num_layers', '40'))
         device_map_func = partial(auto_configure_device_map2,
                                   num_trans_layers=num_layers,
                                   devices=devices)
-        use_safetensors = kwargs.get('use_safetensors', '1') == '1'
+        use_safetensors = kwargs .get('use_safetensors', '1') == '1'
         use_dispatch = kwargs.get('use_dispatch', '0') == '1'
 
         load_params.update(use_dispatch=use_dispatch)
 
         self._load(pretrain_path,
                    precision,
                    devices,
```

## pybackend_libs/dataelem/model/vllm/vllm_model.py

```diff
@@ -15,15 +15,14 @@
 
 
 class GenerateParams(BaseModel):
     n: int = 1
     best_of: Optional[int] = None
     presence_penalty: float = 0.0
     frequency_penalty: float = 0.0
-    repetition_penalty: float = 1.0
     temperature: float = 1.0
     top_p: float = 1.0
     top_k: int = -1
     use_beam_search: bool = False
     length_penalty: float = 1.0
     early_stopping: Union[bool, str] = False
     stop: Optional[Union[str, List[str]]] = None
@@ -113,15 +112,14 @@
         disable_log_requests = pymodel_params.pop('disable_log_requests',
                                                   'true')
         max_num_seqs = pymodel_params.pop('max_num_seqs', 256)
         max_num_batched_tokens = pymodel_params.pop('max_num_batched_tokens',
                                                     None)
         gpu_memory_utilization = pymodel_params.pop('gpu_memory_utilization',
                                                     0.9)
-        max_model_len = pymodel_params.pop('max_model_len', 2048)
         block_size = pymodel_params.pop('block_size', 16)
         swap_space = pymodel_params.pop('swap_space', 4)
 
         dtype = pymodel_params.pop('dtype', 'auto')
         tensor_parallel_size = len(devices.split(','))
 
         vllm_engine_config = {
@@ -132,15 +130,14 @@
             'max_num_seqs': max_num_seqs,
             'max_num_batched_tokens': max_num_batched_tokens,
             'tensor_parallel_size': tensor_parallel_size,
             'dtype': dtype,
             'trust_remote_code': True,
             'block_size': block_size,
             'swap_space': swap_space,
-            'max_model_len': max_model_len,
         }
         if self.verbose:
             print('vllm_engine_config', vllm_engine_config)
 
         model_type = model_type.replace('vLLM', '')
         self.messages_to_prompt = Messages2Prompt(model_type)
```

## Comparing `bisheng_pybackend_libs-0.0.3rc2.dist-info/METADATA` & `bisheng_pybackend_libs-0.0.6.4.dist-info/METADATA`

 * *Files 16% similar despite different names*

```diff
@@ -1,60 +1,58 @@
 Metadata-Version: 2.1
 Name: bisheng-pybackend-libs
-Version: 0.0.3rc2
+Version: 0.0.6.4
 Summary: libraries for bisheng rt pybackend
 Home-page: https://github.com/dataelement/bisheng-rt/python/pybackend_libs
 Author: DataElem Inc.
 Author-email: contact@dataelem.com
 License: Apache 2.0
-Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Operating System :: OS Independent
 Requires-Python: >=3.8
 Description-Content-Type: text/markdown
-Requires-Dist: lanms ==1.0.2
-Requires-Dist: tensorflow ==1.15.5+nv
-Requires-Dist: torch ==2.1.2
-Requires-Dist: torchvision ==0.16.2
-Requires-Dist: flash-attn ==2.3.6
-Requires-Dist: urllib3 ==1.25.4
-Requires-Dist: pydantic >=2
-Requires-Dist: tokenizers ==0.15.0
-Requires-Dist: tiktoken ==0.5.1
-Requires-Dist: sentencepiece ==0.1.99
-Requires-Dist: einops ==0.7.0
-Requires-Dist: huggingface-hub ==0.19.4
-Requires-Dist: transformers ==4.38.2
-Requires-Dist: transformers-stream-generator ==0.0.4
-Requires-Dist: SwissArmyTransformer ==0.4.8
-Requires-Dist: cpm-kernels ==1.0.11
-Requires-Dist: accelerate ==0.24.1
-Requires-Dist: anyio ==3.7.1
-Requires-Dist: starlette ==0.27.0
-Requires-Dist: sse-starlette ==1.6.5
-Requires-Dist: streamlit >=1.24.0
-Requires-Dist: mdtex2html ==1.2.0
-Requires-Dist: shapely ==2.0.2
-Requires-Dist: lxml ==4.9.3
-Requires-Dist: openpyxl ==3.1.2
-Requires-Dist: premailer ==3.10.0
-Requires-Dist: scipy ==1.10.1
-Requires-Dist: pillow ==10.2.0
-Requires-Dist: opencv-python ==4.5.5.64
-Requires-Dist: scikit-image ==0.21.0
-Requires-Dist: auto-gptq ==0.5.1
-Requires-Dist: optimum ==1.14.1
-Requires-Dist: llama-cpp-python ==0.2.25
-Requires-Dist: fsspec ==2023.10.0
-Requires-Dist: timm ==0.5.4
-Requires-Dist: albumentations ==1.3.1
-Requires-Dist: x-transformers ==0.15.0
+Requires-Dist: lanms (==1.0.2)
+Requires-Dist: tensorflow (==1.15.5+nv)
+Requires-Dist: torch (==2.1.2)
+Requires-Dist: torchvision (==0.16.2)
+Requires-Dist: flash-attn (==2.3.6)
+Requires-Dist: urllib3 (==1.25.4)
+Requires-Dist: pydantic (<2)
+Requires-Dist: tokenizers (==0.15.0)
+Requires-Dist: tiktoken (==0.5.1)
+Requires-Dist: sentencepiece (==0.1.99)
+Requires-Dist: einops (==0.7.0)
+Requires-Dist: huggingface-hub (==0.19.4)
+Requires-Dist: transformers (==4.36.2)
+Requires-Dist: transformers-stream-generator (==0.0.4)
+Requires-Dist: SwissArmyTransformer (==0.4.8)
+Requires-Dist: cpm-kernels (==1.0.11)
+Requires-Dist: accelerate (==0.24.1)
+Requires-Dist: vllm (==0.2.6)
+Requires-Dist: anyio (==3.7.1)
+Requires-Dist: starlette (==0.27.0)
+Requires-Dist: sse-starlette (==1.6.5)
+Requires-Dist: streamlit (>=1.24.0)
+Requires-Dist: mdtex2html (==1.2.0)
+Requires-Dist: shapely (==2.0.2)
+Requires-Dist: lxml (==4.9.3)
+Requires-Dist: openpyxl (==3.1.2)
+Requires-Dist: premailer (==3.10.0)
+Requires-Dist: scipy (==1.10.1)
+Requires-Dist: pillow (==10.2.0)
+Requires-Dist: opencv-python (==4.5.5.64)
+Requires-Dist: scikit-image (==0.21.0)
+Requires-Dist: auto-gptq (==0.5.1)
+Requires-Dist: optimum (==1.14.1)
+Requires-Dist: llama-cpp-python (==0.2.25)
+Requires-Dist: fsspec (==2023.10.0)
+Requires-Dist: timm (==0.5.4)
+Requires-Dist: albumentations (==1.3.1)
+Requires-Dist: x-transformers (==0.15.0)
 
 ## Repository for python backend's library
 
 
 ### Update the repository documentation
 
-
-
```

## Comparing `bisheng_pybackend_libs-0.0.3rc2.dist-info/RECORD` & `bisheng_pybackend_libs-0.0.6.4.dist-info/RECORD`

 * *Files 6% similar despite different names*

```diff
@@ -1,21 +1,19 @@
 pybackend_libs/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/framework/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/framework/hf_model.py,sha256=3Jszo9MrfvGayBwiKkQDtvxZa1NhFJaENONiZgNHUho,3185
 pybackend_libs/dataelem/framework/onnx_graph.py,sha256=DroLb8wcdRinx17G-XVxepLvq_sTvt8v4jxOOLCx2DE,1336
 pybackend_libs/dataelem/framework/pt_graph.py,sha256=1apt1Ux_ILYJK06qnv9Cq7N6AxOaXvEPzqdSzEc2FAY,1455
 pybackend_libs/dataelem/framework/tf_graph.py,sha256=29Zx-Mv_VmZPyvGdvNlJPSYhVLODtWmEv4fiCAaUFlo,1756
-pybackend_libs/dataelem/model/__init__.py,sha256=c9z4pcYsHD57zVsryTImiRPCX2yNRK2Cj-Eij4Nt1uQ,2419
+pybackend_libs/dataelem/model/__init__.py,sha256=kbITem1rKS2svKXXCPpEiGagXho7Ke6CoJTQdzKBHRg,2236
 pybackend_libs/dataelem/model/embedding/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/embedding/bge.py,sha256=sjyQveWTOUq7J6guq8-Xw1GuC6o7exAPC8AlS4CaReY,2134
-pybackend_libs/dataelem/model/embedding/embedding.py,sha256=1wcEuyyT9HGC1r9ZgDCexHdYbA8h_AIniQQ0rzbn7Kc,4427
+pybackend_libs/dataelem/model/embedding/embedding.py,sha256=3V4B_kkoTT6ggNv3yVutPKgLqnaKvUMwZded9Fgxz2M,3655
 pybackend_libs/dataelem/model/embedding/gte.py,sha256=besjBGuPBeIl7XT5Op42Hygs38V6PbWH9jCRQcFdGdQ,1823
-pybackend_libs/dataelem/model/embedding/jina.py,sha256=WKm0j_6NnCToMgO7oDdPCxNUcSFt2tv79_w6g_lXD10,1070
-pybackend_libs/dataelem/model/embedding/jina_util.py,sha256=sYImb5OM8dFbu0wFSLergxWB8yqnSfMFkBlMSL7fX9o,98683
 pybackend_libs/dataelem/model/embedding/me5.py,sha256=SNFZpKdSGj2WcS6Ga3_0TMjiGK8-pagWbg4xQNY-Msw,2203
 pybackend_libs/dataelem/model/embedding/rocketqa_dual.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/layout/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/layout/config.py,sha256=SxaSI85GaI3yY2UeO6r72GnDuzSkqOdn1LcKk5423gg,6815
 pybackend_libs/dataelem/model/layout/layout_mrcnn.py,sha256=N631jK751VwcQC0d_ngR5Rcmgjfy70BEauNFxNHTtkA,8766
 pybackend_libs/dataelem/model/layout/mrcnn_pt.py,sha256=w2IWsA9Gt-jvp5WBcGyDetwFFJXKk7xKpsBUg1rxQFU,41761
 pybackend_libs/dataelem/model/llama_cpp/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
@@ -25,17 +23,16 @@
 pybackend_libs/dataelem/model/llm/chatglm2.py,sha256=ErDMxUcR5vZ-PKOGcafRfSzpx7d_w7B4CC3nya92HxM,6267
 pybackend_libs/dataelem/model/llm/chatglm2_utils.py,sha256=2h90n9H8btWZhvUvesfvukLoW-Tf3RqAunrYlyRhvA8,1247
 pybackend_libs/dataelem/model/llm/chatglm3.py,sha256=hym81HKn_kCyij4lshpW5ILdIbjyyXXW3fQ21a4qNjY,8580
 pybackend_libs/dataelem/model/llm/code_geex2.py,sha256=MoUO07Rw9nZjakm9aGoNHTMl99H8BZE2ApTEPFlAdK4,3931
 pybackend_libs/dataelem/model/llm/internlm.py,sha256=2s_rcd9Orit5vXto44G6MVeeuvavYWYW6wjFCgA_XqU,3485
 pybackend_libs/dataelem/model/llm/llama2.py,sha256=wsvxa0c6PCTrHr3xRw6F4BoHvCSgeuTspr1mZRJwICY,2664
 pybackend_libs/dataelem/model/llm/llama2_utils.py,sha256=7ZS5d14BeAZ06-s06hM5lasrGf1GF0MW5ipuD_FDj8c,3821
-pybackend_libs/dataelem/model/llm/llm.py,sha256=tnDW2uUwqS9x8tLws6cCkdvVD8MCOcJ173PuZpxaC8Y,7050
-pybackend_libs/dataelem/model/llm/qwen.py,sha256=Z1TaShWJyb4wOxFrekdL6q9URi-j8t1lfLHUX7CgPoI,7671
-pybackend_libs/dataelem/model/llm/qwen1_5.py,sha256=dmxNcMF32iEO4BZpuX7QHrZMbu1Qqjz8AVy5k7ICtWY,5299
+pybackend_libs/dataelem/model/llm/llm.py,sha256=-5rVDdlcLb79cYUWRONfeGmtZ3twfBDknIflrzO8gzo,6812
+pybackend_libs/dataelem/model/llm/qwen.py,sha256=Z_dppTBrN2-AmPqKRdMFdgPzn8LzR_oUDMKYmZp5AW0,7672
 pybackend_libs/dataelem/model/llm/qwen_utils.py,sha256=uW2bpZBBxX6rwwhIQZuOmeFlNtvNivXrbSxN1eGKoQ8,10836
 pybackend_libs/dataelem/model/llm/vicuna.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/llm/xverse.py,sha256=F3OUOfLbAIAf0HJhn-VKd0nGDiQouSfMISwrbExvSUc,2730
 pybackend_libs/dataelem/model/llm/yi.py,sha256=o0Y3y7HbxQlj3p5x5EnRZCs74QfAb8yPtTq9GKRfZxc,6005
 pybackend_libs/dataelem/model/llm/yuan.py,sha256=V_06wae49-yPUOl4LQrfIIOlk7GcM7OvUZz9ir1w11Y,2827
 pybackend_libs/dataelem/model/mmu/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/mmu/visualglm.py,sha256=R_9knsdrtkrcopBxFGx7ZS46WJcAsa9lIVmhKJSDhEI,1915
@@ -44,26 +41,26 @@
 pybackend_libs/dataelem/model/ocr/latex_recog.py,sha256=fami46csl9ZsILfZBfvcDS7F8sbZ0ASYqXfw-YLjYLM,24911
 pybackend_libs/dataelem/model/ocr/ocr_client.py,sha256=ypA1QpTWXY3x8GdwXQ2gGw3XTupDjgGZBn7Hqc75das,1526
 pybackend_libs/dataelem/model/table/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/table/table_app.py,sha256=l4p2ovkPTsTOBYOQj_EuYewyvtxKTNJ5I0ydszour4E,34931
 pybackend_libs/dataelem/model/table/table_mrcnn.py,sha256=RfJQB84f4MHhvTQ2AHnL--Vpsl7_cJ8Hy6XQ2w7I6Go,17378
 pybackend_libs/dataelem/model/vllm/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 pybackend_libs/dataelem/model/vllm/conversation.py,sha256=GicFrfsWD2U-Ey8IYQK01iNaxtOQCX6YPAI8fQFa5VI,39282
-pybackend_libs/dataelem/model/vllm/vllm_model.py,sha256=Hgss7leyswUwOCzLUYX3gQlsF58LOxOxyvvGftgtclg,8555
+pybackend_libs/dataelem/model/vllm/vllm_model.py,sha256=Cftv_Xrb8HAHyM330kFnHlEc0ZsEZ8jHzAEiGzQQSAk,8409
 pybackend_libs/dataelem/utils/__init__.py,sha256=B2Blpjy-51LiJzD6r-djcZ0xT5Ik2LmUpDjNjvmio14,931
 pybackend_libs/dataelem/utils/curve2rect.py,sha256=Qpn0lf9auIo65CIDjpxO4XYhLCVGl2CE5tmx6BkBtaU,17867
 pybackend_libs/dataelem/utils/geometry.py,sha256=UVkEx5pjoF2fsEbJesNRdrDdZuVr_ETSLUI4Q2Nr7vc,8440
 pybackend_libs/dataelem/utils/html_to_excel.py,sha256=HudFHnJUe6lJ1UKajxpgAO10KzzkBSAxTFUHThkudvM,14840
 pybackend_libs/dataelem/utils/image_io.py,sha256=Mjlcy0SURxe-QNy8VCMvRrAsg9K0QpB1LeFU_7211lc,538
 pybackend_libs/dataelem/utils/lazy_loader.py,sha256=zhim2-vjLyeiXn1gOFr5KSAkugjf8-gj_UWDq_8kd9M,1316
 pybackend_libs/dataelem/utils/registry.py,sha256=_B7Si8oAFPmn265b1pycDdDZGURjZzyY0_nNu6xLjbk,5816
 pybackend_libs/dataelem/utils/simsun.ttc,sha256=ejaBE8NtUWqsGoJazEu7yZBsTRl_fGSef-D28x50dd0,10500792
 pybackend_libs/dataelem/utils/square_seal_postprocess.py,sha256=PCZPyzF7XHTZIkhZa-ENRajUETk_AMhIQiMVgpSko0E,15600
 pybackend_libs/dataelem/utils/table_cell_post.py,sha256=15lJTn3hhO0vvtugeDwriRlWIn62FVl9X5c7MH6Dwk0,26726
 pybackend_libs/dataelem/utils/table_rowcol_post.py,sha256=uimR1MNsTNrCudvThNXoEoSRykST-vZ4gFYmqwFjzmE,46157
 pybackend_libs/dataelem/utils/tf_utils.py,sha256=9lFzYjWjOZXIgN9Q3qF41b4Vvc_nwV-nueQvLRWayGA,11276
 pybackend_libs/dataelem/utils/timer.py,sha256=XG03fvbr_16M473eYr3Mgq32LofUcZRp4i31QzHwAn0,527
 pybackend_libs/dataelem/utils/visualization.py,sha256=zaSzaIC3Im10F5hqrHnaML-LwnSlhY-aHyqHDEQ657g,6317
-bisheng_pybackend_libs-0.0.3rc2.dist-info/METADATA,sha256=f1FFbioFzLhKQDHWU36AYYMd_lXeF9ILQu7nFs7aCnc,1927
-bisheng_pybackend_libs-0.0.3rc2.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-bisheng_pybackend_libs-0.0.3rc2.dist-info/top_level.txt,sha256=83jzUioEFUcWdyhD-26wWS1SubZ0pNR24x1hVXprp8M,15
-bisheng_pybackend_libs-0.0.3rc2.dist-info/RECORD,,
+bisheng_pybackend_libs-0.0.6.4.dist-info/METADATA,sha256=r11t8YIPGDTM8YnbYHNbGU9iTtUqL-FsQVE1yvSLAIg,2009
+bisheng_pybackend_libs-0.0.6.4.dist-info/WHEEL,sha256=2wepM1nk4DS4eFpYrW1TTqPcoGNfHhhO_i5m4cOimbo,92
+bisheng_pybackend_libs-0.0.6.4.dist-info/top_level.txt,sha256=83jzUioEFUcWdyhD-26wWS1SubZ0pNR24x1hVXprp8M,15
+bisheng_pybackend_libs-0.0.6.4.dist-info/RECORD,,
```

